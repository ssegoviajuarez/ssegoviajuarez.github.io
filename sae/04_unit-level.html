
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>4. Unit-level Models for Small Area Estimation &#8212; Guidelines to Small Area Estimation for Poverty Mapping</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="pygments.css" />
    <link rel="stylesheet" href="sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="copybutton.css" />
    <link rel="stylesheet" type="text/css" href="mystnb.css" />
    <link rel="stylesheet" type="text/css" href="sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <link rel="stylesheet" type="text/css" href="design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="documentation_options.js"></script>
    <script src="jquery.js"></script>
    <script src="underscore.js"></script>
    <script src="doctools.js"></script>
    <script src="clipboard.min.js"></script>
    <script src="copybutton.js"></script>
    <script src="sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="5. Poverty Mapping in Off-Census Years" href="05_off-census.html" />
    <link rel="prev" title="3. Area-level Models for Small Area Estimation" href="03_area-level.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Guidelines to Small Area Estimation for Poverty Mapping</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="00_welcome.html">
                    Welcome to Guidelines to SAE for Poverty Mapping
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  CHAPTERS
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_intro.html">
   1. Small Area Estimation for Poverty Mapping
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_direct.html">
   2. Direct Estimates
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_area-level.html">
   3. Area-level Models for Small Area Estimation
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   4. Unit-level Models for Small Area Estimation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05_off-census.html">
   5. Poverty Mapping in Off-Census Years
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06_diagnostics.html">
   6. Model Diagnostics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07_conclusion.html">
   7. Concluding Remarks
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Created by <a href="https://github.com/ssegoviajuarez"> Sandra Segovia </a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/04_unit-level.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="04_unit-level.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preparing-for-unit-level-small-area-estimation">
   4.1. Preparing for Unit-Level Small Area Estimation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-assumed-model">
     4.1.1. The Assumed Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conducting-your-first-sae-application-with-a-unit-level-model">
   4.2. Conducting Your First SAE Application with a Unit-Level Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-choice-considerations">
     4.2.1. Model Choice Considerations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-transformation">
     4.2.2. Data Transformation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-alpha-model">
     4.2.3. The Alpha Model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#producing-small-area-estimates">
     4.2.4. Producing Small Area Estimates
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pros-and-cons-of-unit-level-models">
   4.3. Pros and Cons of Unit-Level Models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ell">
     4.3.1. ELL
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#empirical-best-and-censuseb">
     4.3.2. Empirical Best and CensusEB
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#alternative-software-packages-for-unit-level-models-and-extensions">
     4.3.3. Alternative Software Packages for Unit-Level Models and Extensions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#unit-level-models-technical-annex">
   4.4. Unit-Level Models – Technical Annex
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#unit-level-annex-model">
     4.4.1. The Assumed Model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#monte-carlo-simulation-and-bootstrap-procedures-under-censuseb">
     4.4.2. Monte Carlo Simulation and Bootstrap Procedures Under CensusEB
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#molina-and-rao-s-2010-monte-carlo-simulation-procedure-for-point-estimates">
       4.4.2.1. Molina and Rao’s (2010) Monte Carlo Simulation Procedure for Point Estimates
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#parametric-bootstrap">
       4.4.2.2. Parametric Bootstrap
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#appendix">
   4.5. Appendix
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-selection-do-file">
     4.5.1. Model Selection Do-File
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sae-simulation-stage">
     4.5.2. SAE Simulation Stage
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   4.6. References
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#notes">
   4.7. Notes
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Unit-level Models for Small Area Estimation</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preparing-for-unit-level-small-area-estimation">
   4.1. Preparing for Unit-Level Small Area Estimation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-assumed-model">
     4.1.1. The Assumed Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conducting-your-first-sae-application-with-a-unit-level-model">
   4.2. Conducting Your First SAE Application with a Unit-Level Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-choice-considerations">
     4.2.1. Model Choice Considerations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-transformation">
     4.2.2. Data Transformation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-alpha-model">
     4.2.3. The Alpha Model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#producing-small-area-estimates">
     4.2.4. Producing Small Area Estimates
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pros-and-cons-of-unit-level-models">
   4.3. Pros and Cons of Unit-Level Models
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ell">
     4.3.1. ELL
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#empirical-best-and-censuseb">
     4.3.2. Empirical Best and CensusEB
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#alternative-software-packages-for-unit-level-models-and-extensions">
     4.3.3. Alternative Software Packages for Unit-Level Models and Extensions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#unit-level-models-technical-annex">
   4.4. Unit-Level Models – Technical Annex
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#unit-level-annex-model">
     4.4.1. The Assumed Model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#monte-carlo-simulation-and-bootstrap-procedures-under-censuseb">
     4.4.2. Monte Carlo Simulation and Bootstrap Procedures Under CensusEB
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#molina-and-rao-s-2010-monte-carlo-simulation-procedure-for-point-estimates">
       4.4.2.1. Molina and Rao’s (2010) Monte Carlo Simulation Procedure for Point Estimates
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#parametric-bootstrap">
       4.4.2.2. Parametric Bootstrap
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#appendix">
   4.5. Appendix
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-selection-do-file">
     4.5.1. Model Selection Do-File
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sae-simulation-stage">
     4.5.2. SAE Simulation Stage
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   4.6. References
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#notes">
   4.7. Notes
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="unit-level-models-for-small-area-estimation">
<span id="unit-level"></span><h1><span class="section-number">4. </span>Unit-level Models for Small Area Estimation<a class="headerlink" href="#unit-level-models-for-small-area-estimation" title="Permalink to this headline">#</a></h1>
<hr style="height:1px;border:none;color:#666;background-color:#666;" /><p>This chapter focuses on unit-level models for small area estimation of poverty, which typically rely on estimating the distribution of the household’s welfare, given a set of auxiliary variables or correlates.<a class="footnote-reference brackets" href="#id249" id="id1">1</a> The methods presented in this chapter use model-based techniques that “borrow strength” from other areas by using a larger data set with auxiliary information – usually the population census. The resulting indirect estimators sacrifice design bias, but often yield more precise estimates in terms of mean-squared errors (MSE). In software implementations of the method described in this chapter, model parameters are used to simulate multiple welfare vectors from the fitted distribution for all households in the census. This is done because the census often lacks a welfare measure for poverty measurement (<span id="id2">Elbers <em>et al.</em> [<a class="reference internal" href="#id150" title="Chris Elbers, Tomoki Fujii, Peter Lanjouw, Berk Ozler, Wesley Yin, and others. Poverty alleviation through geographic targeting: how much does disaggregation help? Journal of Development Economics, 83(1):198–213, 2007.">2007</a>]</span>). From the simulated census vectors, it is possible to obtain poverty rates or any other welfare indicator, for every area, including the non-sampled ones. This chapter serves as a guide for the production of unit-level small area estimates of poverty indicators, focusing on two of the most popular approaches – the one proposed by Elbers, Lanjouw, and Lanjouw (<span id="id3">Elbers <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id52" title="Chris Elbers, Jean O Lanjouw, and Peter Lanjouw. Micro–level estimation of poverty and inequality. Econometrica, 71(1):355–364, 2003.">2003</a>]</span>, ELL), and the Empirical Best (EB) approach by Molina and Rao (<span id="id4">Molina and Rao [<a class="reference internal" href="06_diagnostics.html#id67" title="Isabel Molina and JNK Rao. Small area estimation of poverty indicators. Canadian Journal of Statistics, 38(3):369–385, 2010.">2010</a>]</span>, MR).<a class="footnote-reference brackets" href="#id252" id="id5">2</a> It presents evidence on certain aspects of SAE and recommendations on what may be the preferred approach in some scenarios and offers advice for aspects where perhaps more research is needed.</p>
<p>The chapter begins by presenting some of the prerequisites that should be satisfied before commencing a SAE exercise. It provides insights that may help practitioners choose a unit-level SAE method that is adequate for their needs. It then presents considerations that practitioners may keep in mind when conducting SAE, such as data transformation and why ELL has fallen out of favor with many practitioners. Additionally, it presents the usual steps towards selecting a model and the production of small area estimates. The sections rely on real world and simulated data, and offer codes which readers may use to replicate some of the analysis; in other instances it pulls evidence from recent research.<a class="footnote-reference brackets" href="#id255" id="id6">3</a></p>
<section id="preparing-for-unit-level-small-area-estimation">
<span id="unit-level-prep"></span><h2><span class="section-number">4.1. </span>Preparing for Unit-Level Small Area Estimation<a class="headerlink" href="#preparing-for-unit-level-small-area-estimation" title="Permalink to this headline">#</a></h2>
<p>The basic ingredients for model-based unit-level small area estimation for poverty are a contemporaneous survey and census – ideally from the same year. Small area estimates rely on household-level data to obtain the conditional distribution of welfare given the observed correlates. This information is then used to generate welfare for all the census units. Thus, if characteristics in the two datasets differ considerably, or if the structure of the conditional distribution has changed between the two data sources, then the estimates could be biased and of little use.</p>
<p>Obtaining a pool of candidate variables for the analysis requires a thorough review of the survey and census data to ensure comparability. In the census and survey questionnaires, questions should be asked in a similarly, ideally worded in the same manner. Checks should then be conducted on the survey weights to understand how these are constructed. For example, in some countries where there is heavy migratory work, household expansion factors (usually the number of household members) may be adjusted by the number of days the individual is present in the dwelling. Such adjustments should also be possible in the census data; otherwise, the poverty estimates obtained from SAE methods will not be comparable to those obtained directly from the survey. Even if questions are asked in a similar fashion and weights are replicable, differences may still arise. Teams are strongly recommended to compare the mean and distribution the potential pool of covariates across the survey and the census – including whether it is possible to reproduce the direct estimates of poverty produced by the National Statistical Office. Ideally, the mean and distribution of the covariates should be comparable, at least at the aggregation level at which the survey is designed to be representative.</p>
<p>One of the first decisions that must be made is the level at which estimates must be produced. As noted afterward, this determines the level at which location effects are specified in the model in unit-level models. For reasons that will be apparent in the following sections, the locations in the survey must be matched to the locations in the census. Matching locations will also ensure that when using information from external sources, for example, administrative data or satellite imagery-derived data, these correspond to the correct location. Additionally, the use of hierarchical identifiers for the location variable is recommended (<span id="id7">Zhao [<a class="reference internal" href="#id155" title="Qinghua Zhao. User Manual for Povmap. 2006. URL: http://siteresources. worldbank. org/INTPGI/Resources/342674-1092157888460/Zhao_ ManualPovMap. pdf.">2006</a>]</span>). Under Stata’s <code class="docutils literal notranslate"><span class="pre">sae</span></code> package, these identifiers must be numeric and no longer than 16 digits,<a class="footnote-reference brackets" href="#id256" id="id8">4</a> and should have an equal number of digits for every area. For example, in the hierarchical identifier SSSMMMMPPP, the first 3 digits represent states (S), the next 4 digits represent municipalities (M), and the final 3 digits represent PSUs (P). The use of hierarchical identifiers is necessary for two-fold nested-error models. In the code syntax, the user needs to indicate the number of digits to remove (from the right) to arrive at the larger area’s identifier. For example, to go from PSU to municipality level, it is necessary to remove 3 digits, yielding SSSMMMM.</p>
<section id="the-assumed-model">
<span id="unit-level-prep-assumed"></span><h3><span class="section-number">4.1.1. </span>The Assumed Model<a class="headerlink" href="#the-assumed-model" title="Permalink to this headline">#</a></h3>
<p>The model-based small area estimation methods described in this chapter are dependent on an assumed model. The nested-error model used for small area estimation by ELL (<span id="id9">Elbers <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id52" title="Chris Elbers, Jean O Lanjouw, and Peter Lanjouw. Micro–level estimation of poverty and inequality. Econometrica, 71(1):355–364, 2003.">2003</a>]</span>) and MR (<span id="id10">[<a class="reference internal" href="06_diagnostics.html#id67" title="Isabel Molina and JNK Rao. Small area estimation of poverty indicators. Canadian Journal of Statistics, 38(3):369–385, 2010.">Molina and Rao, 2010</a>]</span>) was originally proposed by <span id="id11">Battese <em>et al.</em> [<a class="reference internal" href="#id190" title="George E. Battese, Rachel M. Harter, and Wayne A. Fuller. An error-components model for prediction of county crop areas using survey and satellite data. Journal of the American Statistical Association, 83(401):28–36, 1988. URL: http://www.jstor.org/stable/2288915.">1988</a>]</span> to produce county-level corn and soybean crop area estimates for the American state of Iowa. For the estimation of poverty and welfare, the ELL and MR methods assume that the transformed welfare <span class="math notranslate nohighlight">\(y_{ch}\)</span> for each household <span class="math notranslate nohighlight">\(h\)</span> within each location <span class="math notranslate nohighlight">\(c\)</span> in the population is linearly related to a <span class="math notranslate nohighlight">\(1\times K\)</span> vector of characteristics (or correlates) <span class="math notranslate nohighlight">\(x_{ch}\)</span> for that household, according to the nested-error model:</p>
<div class="math notranslate nohighlight" id="equation-eq-1-1-1">
<span class="eqno">(4.1)<a class="headerlink" href="#equation-eq-1-1-1" title="Permalink to this equation">#</a></span>\[$y_{ch}=x_{ch}\beta+\eta_{c}+e_{ch},\:h=1,\ldots,N_{c},\,c=1,\ldots,C,\]</div>
<p>where <span class="math notranslate nohighlight">\(\eta_{c}\)</span> and <span class="math notranslate nohighlight">\(e_{ch}\)</span> are respectively location and household-specific idiosyncratic errors, assumed to be independent from each other, following:</p>
<div class="math notranslate nohighlight">
\[\eta_{c}\stackrel{iid}{\sim}N\left(0,\sigma_{\eta}^{2}\right),\:e_{ch}\stackrel{iid}{\sim}N\left(0,\sigma_{e}^{2}\right)\]</div>
<p>where the variances <span class="math notranslate nohighlight">\(\sigma_{\eta}^{2}\)</span> and <span class="math notranslate nohighlight">\(\sigma_{e}^{2}\)</span> are unknown. Here, <span class="math notranslate nohighlight">\(C\)</span> is the number of locations in which the population is divided and <span class="math notranslate nohighlight">\(N_{c}\)</span> is the number of households in location <span class="math notranslate nohighlight">\(c\)</span>, for <span class="math notranslate nohighlight">\(c=1,\ldots,C\)</span>. Finally, <span class="math notranslate nohighlight">\(\beta\)</span> is the <span class="math notranslate nohighlight">\(K\times1\)</span> vector of regression coefficients.<a class="footnote-reference brackets" href="#id257" id="id12">5</a></p>
<p>One of the main assumptions is that errors are normally distributed. The assumption does not necessarily imply that the transformed welfare (the dependent variable) is normally distributed but instead implies that conditional on the observed characteristics the residuals are normally distributed. Under the assumed model, variation in welfare across the population is determined by three components: the variation in household characteristics, the variation in household-specific unobservables, and the variation in location-specific effects. Within any given area, the welfare distribution is determined by the variation in household specific characteristics and household specific errors.</p>
<figure class="align-default" id="bias-approx">
<a class="reference internal image-reference" href="approximating.png"><img alt="approximating.png" src="approximating.png" style="height: 350px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4.1 </span><span class="caption-text"><em>Empirical bias of two different models for unit-level small area estimation</em></span><a class="headerlink" href="#bias-approx" title="Permalink to this image">#</a></p>
<div class="legend">
<p>Source: Simulation based on 1,000 populations generated as described in this <strong><a class="reference internal" href="05_off-census.html#off-census-appendix-experiment1-validation"><span class="std std-numref">Section 5.5.1.1</span></a></strong>. Each line corresponds to one of the 100 areas of the population. The x-axis represents the percentile on which the poverty line falls on, and the y-axis is the empirical bias. The do-file to replicate these results can be found in <strong><a class="reference internal" href="05_off-census.html#off-census-appendix-experiment2"><span class="std std-numref">Section 5.5.2</span></a></strong>.</p>
</div>
</figcaption>
</figure>
<p>It is important to note that while the method’s goal may be to produce headcount poverty rates or other welfare indicators, these are not explicitly modeled in the sense that the dependent variable is welfare (or transformed welfare) and not the desired indicator (e.g. headcount poverty). The methodology relies on approximating as closely as possible the welfare distribution in each area. A model that approximates the welfare distribution poorly may yield a decent estimate for a given poverty line, yet when judged at a different poverty line the method may completely fail. This can be seen in <strong><a class="reference internal" href="#bias-approx"><span class="std std-numref">Fig. 4.1</span></a></strong>, where the headcount poverty estimates from the model on the left may work relatively well if the poverty threshold were set at the 70th percentile and yield completely biased estimates at most other thresholds. On the other hand, the model on the right approximates the welfare distribution well in all areas and yields poverty estimates with a small bias across all poverty thresholds and areas.</p>
</section>
</section>
<section id="conducting-your-first-sae-application-with-a-unit-level-model">
<span id="unit-level-first-sae"></span><h2><span class="section-number">4.2. </span>Conducting Your First SAE Application with a Unit-Level Model<a class="headerlink" href="#conducting-your-first-sae-application-with-a-unit-level-model" title="Permalink to this headline">#</a></h2>
<p>The focus of this section is on the process of producing small area estimates of monetary indicators using a census and a survey. For the exercise conducted in the following sections it is assumed that the data has already been prepared and all of the checks noted in <strong><a class="reference internal" href="#unit-level-prep"><span class="std std-numref">Section 4.1</span></a></strong> have been conducted. The section provides step-by-step processes for producing small area estimates of poverty using census and survey data. It also draws from existing evidence to make recommendations based on current best practices for conducting SAE applications.</p>
<section id="model-choice-considerations">
<span id="unit-level-first-sae-model"></span><h3><span class="section-number">4.2.1. </span>Model Choice Considerations<a class="headerlink" href="#model-choice-considerations" title="Permalink to this headline">#</a></h3>
<p>Ideally, the particular model to be used should be aligned to the specific SAE goals. One of the main considerations regarding the model to be used is the level at which poverty estimates will be reported. This will determine the level at which the random location effect should be specified (see <strong><a class="reference internal" href="#unit-level-annex"><span class="std std-numref">Section 4.4</span></a></strong> for details). Specifying the random effects at a lower level of aggregation than the level at which estimation is desired (e.g., for clusters nested within the areas of interest) will lead to noisier estimates (<span id="id13">Marhuenda <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id106" title="Yolanda Marhuenda, Isabel Molina, Domingo Morales, and JNK Rao. Poverty mapping in small areas under a twofold nested error regression model. Journal of the Royal Statistical Society: Series A (Statistics in Society), 180(4):1111-1136, 2017. doi:10.1111/rssa.12306.">2017</a>]</span>), albeit with little effect on bias (Corral et al. <span id="id14">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id112" title="Paul Corral, Kristen Himelein, Kevin McGee, and Isabel Molina. A map of the poor or a poor map? Mathematics, 2021. URL: https://www.mdpi.com/2227-7390/9/21/2780, doi:10.3390/math9212780.">2021</a>]</span>). The magnitude by which the MSE of the estimates based on a model with cluster effects instead of area effects will increase depends on the ratio between the variances of the random effects associated to the different locations. If the variance of the random effects of the clusters within areas, <span class="math notranslate nohighlight">\(\sigma_{ac}^{2}\)</span>, is larger than that of the area’s random effects, <span class="math notranslate nohighlight">\(\sigma_{a}^{2}\)</span>, then the MSE may not increase by much. On the other hand, when the variance of the area’s random effects is larger, the MSE of the estimates based on a model with only cluster effects worsens considerably. Thus, the random location effect should be at the same level for which estimates will be reported (see <strong><a class="reference internal" href="#empirical-mse-comparison"><span class="std std-numref">Fig. 4.2</span></a></strong>).</p>
<p>Additionally, under the latest edition of the Stata <code class="docutils literal notranslate"><span class="pre">sae</span></code> package, practitioners can apply two-fold nested-error models (<span id="id15">Marhuenda <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id106" title="Yolanda Marhuenda, Isabel Molina, Domingo Morales, and JNK Rao. Poverty mapping in small areas under a twofold nested error regression model. Journal of the Royal Statistical Society: Series A (Statistics in Society), 180(4):1111-1136, 2017. doi:10.1111/rssa.12306.">2017</a>]</span>), besides the traditional one-fold nested-error model. The drawback of the implemented two-fold nested-error model in the Stata <code class="docutils literal notranslate"><span class="pre">sae</span></code> package is that it does not consider survey weights, nor does it consider heteroskedasticity. The benefit from applying a two-fold nested-error model is that the resulting estimates are optimal at two levels of aggregation, because the MSEs of the estimates at both levels tend to be smaller under the assumed model than when using one-fold nested-error models with only cluster or area effects (see <strong><a class="reference internal" href="#empirical-mse-comparison"><span class="std std-numref">Fig. 4.2</span></a></strong>).</p>
<figure class="align-default">
<a class="reference internal image-reference" href="MSE_Sa05Sc1.png"><img alt="MSE_Sa05Sc1.png" src="MSE_Sa05Sc1.png" style="height: 350px;" /></a>
</figure>
<figure class="align-default" id="empirical-mse-comparison">
<a class="reference internal image-reference" href="MSE_Sa1Sc05.png"><img alt="MSE_Sa1Sc05.png" src="MSE_Sa1Sc05.png" style="height: 350px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4.2 </span><span class="caption-text"><em>Empirical MSE comparison considering only cluster effects and when aggregating the cluster level results to the area level versus specifying the random effects at the reporting level, area.</em></span><a class="headerlink" href="#empirical-mse-comparison" title="Permalink to this image">#</a></p>
<div class="legend">
<p>Source: Simulation based on populations generated as described in Corral et al. (<span id="id16">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id112" title="Paul Corral, Kristen Himelein, Kevin McGee, and Isabel Molina. A map of the poor or a poor map? Mathematics, 2021. URL: https://www.mdpi.com/2227-7390/9/21/2780, doi:10.3390/math9212780.">2021</a>]</span>) section 3. Notice how the empirical MSE of CensusEB one-fold nested-error models, where <span class="math notranslate nohighlight">\(\eta\)</span> is specified at the area level, are closely aligned to those under the two-fold nested-error model with cluster and area effects. On the other hand, CensusEB estimators based on one-fold nested-error models, where <span class="math notranslate nohighlight">\(\eta\)</span> is specified at the cluster level, have a considerably larger empirical MSE.</p>
</div>
</figcaption>
</figure>
<p>Two model fitting approaches are available under Stata’s <code class="docutils literal notranslate"><span class="pre">sae</span></code> package: restricted maximum likelihood (REML) and Generalized Least Squares (GLS), where the variance parameters are estimated using Henderson’s method III (<span id="id17">Henderson [<a class="reference internal" href="#id162" title="Charles R Henderson. Estimation of variance and covariance components. Biometrics, 9(2):226–252, 1953.">1953</a>]</span>, H3). Both approaches yield similar estimated regression coefficients when heteroskedasticity and survey weights are not considered (<span id="id18">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span> – Figure A4). Given the different available models implemented in Stata’s <code class="docutils literal notranslate"><span class="pre">sae</span></code> package, it is important to understand which options are available under each fitting method.</p>
<ol>
<li><p>Model fit by REML does not incorporate survey weights nor heteroskedasticity. Uses Stata’s <code class="docutils literal notranslate"><span class="pre">xtmixed</span> </code>command in the background to fit the model.<a class="footnote-reference brackets" href="#id258" id="id19">6</a></p>
<ol>
<li><p>When choosing this fitting method, the one-fold nested-error model considered is the same one used in Molina and Marhuenda’s (<span id="id20">Molina and Marhuenda [<a class="reference internal" href="06_diagnostics.html#id68" title="Isabel Molina and Yolanda Marhuenda. Sae: an R package for small area estimation. The R Journal, 7(1):81–98, 2015.">2015</a>]</span>) <code class="docutils literal notranslate"><span class="pre">sae</span></code> package in R. Stata’s <code class="docutils literal notranslate"><span class="pre">sae</span></code> package implements a similar REML fitting approach to Molina and Marhuenda’s <span id="id21">Molina and Marhuenda [<a class="reference internal" href="06_diagnostics.html#id68" title="Isabel Molina and Yolanda Marhuenda. Sae: an R package for small area estimation. The R Journal, 7(1):81–98, 2015.">2015</a>]</span> <code class="docutils literal notranslate"><span class="pre">sae</span></code> R package.<a class="footnote-reference brackets" href="#id259" id="id22">7</a></p>
<p><code class="docutils literal notranslate"><span class="pre">sae</span> <span class="pre">model</span> <span class="pre">reml</span> <span class="pre">``depvar</span> <span class="pre">indepvars``</span> <span class="pre">[if]</span> <span class="pre">[in],</span> <span class="pre">area(varname)</span></code></p>
<p>Beyond the model fitting method, it is also possible to approximate the original Molina and Marhuenda’s <span id="id23">Molina and Marhuenda [<a class="reference internal" href="06_diagnostics.html#id68" title="Isabel Molina and Yolanda Marhuenda. Sae: an R package for small area estimation. The R Journal, 7(1):81–98, 2015.">2015</a>]</span> EB estimates by Monte Carlo simulation (replace <code class="docutils literal notranslate"><span class="pre">model</span></code> by <code class="docutils literal notranslate"><span class="pre">sim</span></code>) by adding the option <code class="docutils literal notranslate"><span class="pre">appendsvy.</span></code> However, the default approach obtains CensusEB<a class="footnote-reference brackets" href="#id260" id="id24">8</a> estimates instead of the original EB ones.</p>
</li>
<li><p>Stata’s <code class="docutils literal notranslate"><span class="pre">sae</span></code> package also implements the two-fold nested-error model with cluster effects nested within area effects considered by <span id="id25">Marhuenda <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id106" title="Yolanda Marhuenda, Isabel Molina, Domingo Morales, and JNK Rao. Poverty mapping in small areas under a twofold nested error regression model. Journal of the Royal Statistical Society: Series A (Statistics in Society), 180(4):1111-1136, 2017. doi:10.1111/rssa.12306.">2017</a>]</span>. This model is appropriate when point estimates at two different levels of aggregation are desired. <strong><a class="reference internal" href="#unit-level-first-sae-estimates"><span class="std std-numref">Section 4.2.4</span></a></strong> presents the hierarchical identifiers needed for specifying two-fold nested-error models.<a class="footnote-reference brackets" href="#id263" id="id26">9</a></p>
<p><code class="docutils literal notranslate"><span class="pre">sae</span> <span class="pre">model</span> <span class="pre">reml2</span> <span class="pre">``depvar</span> <span class="pre">indepvars``</span> <span class="pre">[if]</span> <span class="pre">[in],</span> <span class="pre">area(#)</span> <span class="pre">subarea(varname)</span></code></p>
<p>Here the <code class="docutils literal notranslate"><span class="pre">subarea</span></code> option requires an identifier for sub-areas of an equal number of digits for every area. Under the <code class="docutils literal notranslate"><span class="pre">area</span></code> option, the user should specify the number of digits of the hierarchical ID to remove from the right to the left to arrive at an identifier for the areas. These identifiers are commonly referred to as hierarchical identifiers and are explained in <span id="id27">Nguyen <em>et al.</em> [<a class="reference internal" href="#id151" title="Minh Cong Nguyen, Paul Corral, João Pedro Azevedo, and Qinghua Zhao. Sae: a stata package for unit level small area estimation. World Bank Policy Research Working Paper, 2018.">2018</a>]</span> and <span id="id28">Zhao [<a class="reference internal" href="#id155" title="Qinghua Zhao. User Manual for Povmap. 2006. URL: http://siteresources. worldbank. org/INTPGI/Resources/342674-1092157888460/Zhao_ ManualPovMap. pdf.">2006</a>]</span> in greater detail. Through Monte Carlo simulation (replace <code class="docutils literal notranslate"><span class="pre">model</span></code> by <code class="docutils literal notranslate"><span class="pre">sim</span></code>) the approach yields CensusEB estimates based on the two-fold nested-error model.</p>
</li>
</ol>
</li>
<li><p>Model fit with GLS, where variance parameters, estimated under Henderson’s method III <span id="id29">Henderson [<a class="reference internal" href="#id162" title="Charles R Henderson. Estimation of variance and covariance components. Biometrics, 9(2):226–252, 1953.">1953</a>]</span>, do allow for the inclusion of heteroskedasticity and survey weights according to Van der Weide <span id="id30">Van der Weide [<a class="reference internal" href="#id156" title="Roy Van der Weide. GLS estimation and empirical bayes prediction for linear mixed models with heteroskedasticity and sampling weights: A background study for the POVMAP project. World Bank Policy Research Working Paper, 2014. URL: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2495175.">2014</a>]</span>.<a class="footnote-reference brackets" href="#id264" id="id31">10</a> However, this method has only been implemented for one-fold nested-error models.<a class="footnote-reference brackets" href="#id265" id="id32">11</a></p>
<p><code class="docutils literal notranslate"><span class="pre">sae</span> <span class="pre">model</span> <span class="pre">h3</span> <span class="pre">``depvar</span> <span class="pre">indepvars``</span> <span class="pre">[if]</span> <span class="pre">[in]</span> <span class="pre">[aw],</span> <span class="pre">area(varname)</span> <span class="pre">[zvar(varnames)</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">yhat(varnames)</span> <span class="pre">yhat2(varnames)</span> <span class="pre">alfatest(new</span> <span class="pre">varname)]</span></code></p>
<p>The method will obtain CensusEB estimates for areas present in the survey and the census. When weights and heteroskedasticity are not specified, results will be very close to those from <code class="docutils literal notranslate"><span class="pre">sae</span> <span class="pre">model</span> <span class="pre">reml</span> </code>(<span id="id33">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span>).</p>
<p>The <code class="docutils literal notranslate"><span class="pre">alfatest</span></code> option allows users to obtain the dependent variable for the alpha model, a model for heteroskedasticity introduced in <span id="id34">Elbers <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id64" title="Chris Elbers, Jean Olson Lanjouw, and Peter Lanjouw. Micro-level estimation of welfare. World Bank Policy Research Working Paper, 2002.">2002</a>]</span>.<a class="footnote-reference brackets" href="#id267" id="id35">12</a> The resulting dependent variable for the alpha model can facilitate the selection of a suitable model. The covariates for the alpha model are specified under <code class="docutils literal notranslate"><span class="pre">zvar</span> </code>and, when interactions with the main model’s linear fit <span class="math notranslate nohighlight">\(X\hat{\beta}\)</span> are desired, then users may specify covariates under the <code class="docutils literal notranslate"><span class="pre">yhat</span> </code>and <code class="docutils literal notranslate"><span class="pre">yhat2</span> </code>options for the interaction of covariates with <span class="math notranslate nohighlight">\(X\hat{\beta}\)</span> and <span class="math notranslate nohighlight">\((X\hat{\beta})^{2}\)</span>, respectively.</p>
</li>
<li><p>An updated GLS method with an adaptation of Henderson’s method III <span id="id36">Henderson [<a class="reference internal" href="#id162" title="Charles R Henderson. Estimation of variance and covariance components. Biometrics, 9(2):226–252, 1953.">1953</a>]</span> that incorporates the error decomposition to estimate <span class="math notranslate nohighlight">\(\sigma_{\eta}^{2}\)</span> and <span class="math notranslate nohighlight">\(\sigma_{e}^{2}\)</span> as described in <span id="id37">Elbers <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id64" title="Chris Elbers, Jean Olson Lanjouw, and Peter Lanjouw. Micro-level estimation of welfare. World Bank Policy Research Working Paper, 2002.">2002</a>]</span> and <span id="id38">Nguyen <em>et al.</em> [<a class="reference internal" href="#id151" title="Minh Cong Nguyen, Paul Corral, João Pedro Azevedo, and Qinghua Zhao. Sae: a stata package for unit level small area estimation. World Bank Policy Research Working Paper, 2018.">2018</a>]</span> is available.<a class="footnote-reference brackets" href="#id270" id="id39">13</a> When users select this fitting method it is not possible to obtain EB or CensusEB estimates and does not require linking between survey and census areas, and hence not recommended.<a class="footnote-reference brackets" href="#id273" id="id40">14</a> It is still available in Stata’s <code class="docutils literal notranslate"><span class="pre">sae</span></code> package to allow for comparisons and replicability.<a class="footnote-reference brackets" href="#id274" id="id41">15</a></p>
<p><code class="docutils literal notranslate"><span class="pre">sae</span> <span class="pre">model</span> <span class="pre">ell</span></code> <code class="docutils literal notranslate"><span class="pre">depvar</span> <span class="pre">indepvars``</span> <span class="pre">[if]</span> <span class="pre">[in]</span> <span class="pre">[aw],</span> <span class="pre">area(varname)</span> <span class="pre">[zvar(varnames)</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">yhat(varnames)</span> <span class="pre">yhat2(varnames)</span> <span class="pre">alfatest(new</span> <span class="pre">varname)]</span></code></p>
<p>The <code class="docutils literal notranslate"><span class="pre">alfatest,</span> <span class="pre">zvar,</span> <span class="pre">yhat,</span> </code>and<code class="docutils literal notranslate"> <span class="pre">yhat2</span></code> options are similar to those described under H3 fitting method.</p>
</li>
</ol>
<p>The most crucial difference between ELL and EB methods is that ELL estimators are obtained from the distribution of welfare without conditioning on the variable survey sample data, though other differences between the original ELL <span id="id42">Elbers <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id52" title="Chris Elbers, Jean O Lanjouw, and Peter Lanjouw. Micro–level estimation of poverty and inequality. Econometrica, 71(1):355–364, 2003.">2003</a>]</span> and MR (<span id="id43">Molina and Rao [<a class="reference internal" href="06_diagnostics.html#id67" title="Isabel Molina and JNK Rao. Small area estimation of poverty indicators. Canadian Journal of Statistics, 38(3):369–385, 2010.">2010</a>]</span>) exist. For example, though the underlying assumed model is the same, different model-fitting approaches are applied between ELL and MR approaches. Noise estimates of the small area estimators are also obtained differently. The implementation of ELL in <code class="docutils literal notranslate"><span class="pre">PovMap</span> </code>draws from the multiple imputation literature, where minimizing the MSE is not the primary goal, while MR’s method relies on the assumed model’s data generating process to estimate the noise of the small area estimators with a parametric bootstrap introduced by <span id="id44">González-Manteiga <em>et al.</em> [<a class="reference internal" href="05_off-census.html#id116" title="Wenceslao González-Manteiga, Maria J Lombardía, Isabel Molina, Domingo Morales, and Laureano Santamaría. Bootstrap mean squared error of a small-area EBLUP. Journal of Statistical Computation and Simulation, 78(5):443–462, 2008.">2008</a>]</span>.<a class="footnote-reference brackets" href="#id276" id="id45">16</a></p>
<p>Regardless of the model’s structure (one-fold or two-fold) and the model-fitting approach used (REML or H3 in Stata’s <code class="docutils literal notranslate"><span class="pre">sae</span></code> package), users are advised to obtain Empirical Best (EB) or CensusEB estimates rather than ELL estimates, because EB will yield more accurate and efficient estimates since EB conditions on the survey sample data and makes more efficient use of the information at hand - see <span id="id46">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span> for a detailed comparison, also see <strong><a class="reference internal" href="#unit-level-annex-model"><span class="std std-numref">Section 4.4.1</span></a></strong>.<a class="footnote-reference brackets" href="#id278" id="id47">17</a> The gains from EB can be quite considerable when the assumed model holds (<strong><a class="reference internal" href="#empirical-mse-ceb-ell"><span class="std std-numref">Fig. 4.3</span></a></strong>, left), but simulations based on real-world data, where the validity of the assumed model is in doubt, also show gains (<strong><a class="reference internal" href="#empirical-mse-ceb-ell"><span class="std std-numref">Fig. 4.3</span></a></strong>, right).<a class="footnote-reference brackets" href="#id279" id="id48">18</a> Thus, despite ELL being one of the optional approaches in the Stata <code class="docutils literal notranslate"><span class="pre">sae</span></code> package, it is not recommended because EB estimates will yield more accurate and efficient estimates, see <span id="id49">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span> and <strong><a class="reference internal" href="#unit-level-annex-model"><span class="std std-numref">Section 4.4.1</span></a></strong>.<a class="footnote-reference brackets" href="#id280" id="id50">19</a></p>
<figure class="align-default">
<a class="reference internal image-reference" href="MSE_model_ell_vs_eb.png"><img alt="MSE_model_ell_vs_eb.png" src="MSE_model_ell_vs_eb.png" style="height: 350px;" /></a>
</figure>
<figure class="align-default" id="empirical-mse-ceb-ell">
<a class="reference internal image-reference" href="MSE_design_ell_vs_eb.png"><img alt="MSE_design_ell_vs_eb.png" src="MSE_design_ell_vs_eb.png" style="height: 350px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4.3 </span><span class="caption-text"><em>Empirical MSE comparison between ELL and CensusEB</em></span><a class="headerlink" href="#empirical-mse-ceb-ell" title="Permalink to this image">#</a></p>
<div class="legend">
<p>Source: Simulation based on populations generated as described in <span id="id51">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id112" title="Paul Corral, Kristen Himelein, Kevin McGee, and Isabel Molina. A map of the poor or a poor map? Mathematics, 2021. URL: https://www.mdpi.com/2227-7390/9/21/2780, doi:10.3390/math9212780.">2021</a>]</span>, section 3 and 4. The simulations illustrate how the empirical MSE of ELL estimates is considerably larger than that of CensusEB under simulated data (left) and also under real world data (right).</p>
</div>
</figcaption>
</figure>
<p>The use of contextual variables in the unit-level model is also recommended as long as their regression coefficients are significant. ELL (<span id="id52">Elbers <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id64" title="Chris Elbers, Jean Olson Lanjouw, and Peter Lanjouw. Micro-level estimation of welfare. World Bank Policy Research Working Paper, 2002.">2002</a>]</span>) noted the importance of explaining the variation in welfare due to location and recommended the inclusion of location means of household-level characteristics, as well as covariates derived from Geographic Information Systems (GIS). Contextual level variables were also noted by Haslett (<span id="id53"></span>) as being essential in ELL to reduce area-specific bias and standard errors. Since contextual variables can help explain between-area variations, these reduce the portion of unexplained between-area variation and complement household-level information to produce more precise estimates. An example of the value that contextual variables may provide in SAE can be seen in <strong><a class="reference internal" href="#context"><span class="std std-numref">Fig. 4.4</span></a></strong>, obtained in simulations using real world data. Poverty estimates obtained without contextual variables present more bias and a considerably larger MSE, though specific results will depend on the chosen variables and the data at hand.</p>
<p>As noted, the Stata <code class="docutils literal notranslate"><span class="pre">sae</span></code> package offers practitioners the option to fit ELL, EB or CensusEB estimates. CensusEB estimates are similar to EB, except that households are not linked across Census and survey data. In practice, the sample size of a given area in the survey is typically much smaller than the actual population size. In these cases, the difference between CensusEB and EB is negligible. In <span id="id54">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span> simulation experiments, where the sample by area is 4 percent of the total population, the difference between EB and CensusEB’s empirical MSE is already indiscernible,
see <strong><a class="reference internal" href="#cebvseb"><span class="std std-numref">Fig. 4.5</span></a></strong>.</p>
<figure class="align-default">
<a class="reference internal image-reference" href="context_diff_bias.png"><img alt="context_diff_bias.png" src="context_diff_bias.png" style="height: 350px;" /></a>
</figure>
<figure class="align-default" id="context">
<a class="reference internal image-reference" href="context_diff_mse.png"><img alt="context_diff_mse.png" src="context_diff_mse.png" style="height: 350px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4.4 </span><span class="caption-text"><em>Empirical bias and MSE of Census EB estimators based on a nested-error model with and without contextual variables</em></span><a class="headerlink" href="#context" title="Permalink to this image">#</a></p>
<div class="legend">
<p>Source: Simulation based on populations generated as described in <span id="id55">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id112" title="Paul Corral, Kristen Himelein, Kevin McGee, and Isabel Molina. A map of the poor or a poor map? Mathematics, 2021. URL: https://www.mdpi.com/2227-7390/9/21/2780, doi:10.3390/math9212780.">2021</a>]</span> section 3 and 4. These design-based simulations provide an example of the possible gains in terms of bias and MSE, obtained from adding contextual variables to the nested-error model.</p>
</div>
</figcaption>
</figure>
<figure class="align-default" id="cebvseb">
<a class="reference internal image-reference" href="MSEdiff.png"><img alt="MSEdiff.png" src="MSEdiff.png" style="height: 350px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4.5 </span><span class="caption-text"><em>Empirical MSE difference between EB and CensusEB depending on sampling fraction</em></span><a class="headerlink" href="#cebvseb" title="Permalink to this image">#</a></p>
<div class="legend">
<p>Source: <span id="id56">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span>. Figure illustrates that the difference in empirical MSE of CensusEB and EB will be close to zero as the sample fraction of the population decreases.</p>
</div>
</figcaption>
</figure>
</section>
<section id="data-transformation">
<span id="unit-level-first-sae-data"></span><h3><span class="section-number">4.2.2. </span>Data Transformation<a class="headerlink" href="#data-transformation" title="Permalink to this headline">#</a></h3>
<p>Since the EB method of MR (<span id="id57">Molina and Rao [<a class="reference internal" href="06_diagnostics.html#id67" title="Isabel Molina and JNK Rao. Small area estimation of poverty indicators. Canadian Journal of Statistics, 38(3):369–385, 2010.">2010</a>]</span>) assumes that the errors are normally distributed, data transformation to get a distribution close to normal can lead to less biased and less noisy estimates (see <span id="id58">Rao and Molina [<a class="reference internal" href="06_diagnostics.html#id63" title="JNK Rao and Isabel Molina. Small Area Estimation. John Wiley &amp; Sons, 2nd edition, 2015.">2015</a>]</span>; <span id="id59">Rojas-Perilla <em>et al.</em> [<a class="reference internal" href="#id216" title="Natalia Rojas-Perilla, Sören Pannier, Timo Schmid, and Nikos Tzavidis. Data-driven transformations in small area estimation. Journal of the Royal Statistical Society: Series A (Statistics in Society), 183(1):121–148, 2020.">2020</a>]</span>; <span id="id60">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id112" title="Paul Corral, Kristen Himelein, Kevin McGee, and Isabel Molina. A map of the poor or a poor map? Mathematics, 2021. URL: https://www.mdpi.com/2227-7390/9/21/2780, doi:10.3390/math9212780.">2021</a>]</span>; and <span id="id61">Tzavidis <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id105" title="Nikos Tzavidis, Li-Chun Zhang, Angela Luna, Timo Schmid, and Natalia Rojas-Perilla. From start to finish: a framework for the production of small area official statistics. Journal of the Royal Statistical Society: Series A (Statistics in Society), 181(4):927–979, 2018.">2018</a>]</span>).<a class="footnote-reference brackets" href="#id281" id="id62">20</a> More generally, variable transformation to make the assumptions underlying the model hold is one of the main aspects of model-based small area estimation (see Technical Annex of this chapter, <strong><a class="reference internal" href="#unit-level-annex-model"><span class="std std-numref">Section 4.4.1</span></a></strong>). Specifically, since the SAE models used often assume normality in the errors, the goal in data transformation is to approximate normally distributed residuals.<a class="footnote-reference brackets" href="#id283" id="id63">21</a></p>
<p>Most software packages for small area estimation offer the possibility of data transformation. Perhaps the most popular transformation is the natural logarithm, although it is not always ideal as it can produce left skewed distributions for small values of welfare (see <strong><a class="reference internal" href="#lny"><span class="std std-numref">Fig. 4.7</span></a></strong>). Other options include transformation from the Box-Cox family (<span id="id64">Box and Cox [<a class="reference internal" href="#id186" title="GEP Box and DR Cox. An analysis of transformations. Journal of the Royal Statistical Society, Series B, 26:211–252, 1964.">1964</a>]</span>) and the log-shift transformations, which have the advantage that the transformation parameters may be driven by the specific data at hand (<span id="id65">Tzavidis <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id105" title="Nikos Tzavidis, Li-Chun Zhang, Angela Luna, Timo Schmid, and Natalia Rojas-Perilla. From start to finish: a framework for the production of small area official statistics. Journal of the Royal Statistical Society: Series A (Statistics in Society), 181(4):927–979, 2018.">2018</a>]</span>).The Box-Cox family’s transformation parameter, which is the power to be taken, is denoted by <span class="math notranslate nohighlight">\(\lambda\)</span>. When <span class="math notranslate nohighlight">\(\lambda=0\)</span>, it yields the natural logarithm; otherwise, <span class="math notranslate nohighlight">\(\lambda\)</span> is typically data-driven and chosen to minimize skewness in the dependent variable., which is the power to be taken, is denoted by <span class="math notranslate nohighlight">\(\lambda\)</span>. When <span class="math notranslate nohighlight">\(\lambda=0\)</span>, it yields the natural logarithm; otherwise, <span class="math notranslate nohighlight">\(\lambda\)</span> is typically data-driven and chosen to minimize skewness in the dependent variable.<a class="footnote-reference brackets" href="#id286" id="id66">22</a> A log-shift transformation adds a positive shift to the observed welfare values before taking the log to avoid the left skewness caused by taking the log of very small welfare values. Other options, such as the ordered quantile normalization (<span id="id67">Peterson and Cavanaugh [<a class="reference internal" href="#id213" title="Ryan A Peterson and Joseph E Cavanaugh. Ordered quantile normalization: a semiparametric transformation built for the cross-validation era. Journal of Applied Statistics, 47(13-15):2312-2327, 2019. URL: https://www.tandfonline.com/action/showCitFormats?doi=10.1080/02664763.2019.1630372, doi:10.1080/02664763.2019.1630372.">2019</a>]</span>), may generate reliable estimates of headcount poverty, but these transformations are not reversible and therefore they cannot be used to obtain other indicators such as mean welfare, poverty gap, poverty severity among others (<span id="id68">Masaki <em>et al.</em> [<a class="reference internal" href="05_off-census.html#id92" title="Takaaki Masaki, David Newhouse, Ani Rudra Silwal, Adane Bedada, and Ryan Engstrom. Small area estimation of non-monetary poverty with geospatial data. World Bank Policy Research Working Paper, 2020.">2020</a>]</span>; <span id="id69">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id112" title="Paul Corral, Kristen Himelein, Kevin McGee, and Isabel Molina. A map of the poor or a poor map? Mathematics, 2021. URL: https://www.mdpi.com/2227-7390/9/21/2780, doi:10.3390/math9212780.">2021</a>]</span>), limiting their applicability. Regardless of the transformation chosen, it is always recommended to check the residuals to determine if these follow the underlying model assumptions.</p>
<p>When working with real-world data, assumptions are often only approximately met (<span id="id70">Marhuenda <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id106" title="Yolanda Marhuenda, Isabel Molina, Domingo Morales, and JNK Rao. Poverty mapping in small areas under a twofold nested error regression model. Journal of the Royal Statistical Society: Series A (Statistics in Society), 180(4):1111-1136, 2017. doi:10.1111/rssa.12306.">2017</a>]</span>) and effort must be made to find one that approximates the normal distribution best. In simulation studies that seek to validate small area estimation methods based on actual data, data-driven transformations may reduce bias and the noise due to departures from normality (see <span id="id71">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id112" title="Paul Corral, Kristen Himelein, Kevin McGee, and Isabel Molina. A map of the poor or a poor map? Mathematics, 2021. URL: https://www.mdpi.com/2227-7390/9/21/2780, doi:10.3390/math9212780.">2021</a>]</span> and <span id="id72">Tzavidis <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id105" title="Nikos Tzavidis, Li-Chun Zhang, Angela Luna, Timo Schmid, and Natalia Rojas-Perilla. From start to finish: a framework for the production of small area official statistics. Journal of the Royal Statistical Society: Series A (Statistics in Society), 181(4):927–979, 2018.">2018</a>]</span> among others). Using the <em>Mexican Intercensal survey of 2015</em> as a 3.9 million household census data, <span id="id73">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id112" title="Paul Corral, Kristen Himelein, Kevin McGee, and Isabel Molina. A map of the poor or a poor map? Mathematics, 2021. URL: https://www.mdpi.com/2227-7390/9/21/2780, doi:10.3390/math9212780.">2021</a>]</span> note that the gains from a transformation of the dependent variable that minimizes skewness can be quite considerable. In the validation exercises conducted in that paper, bias and MSEs, are considerably reduced when using a Box-Cox or a log-shift transformation (see <strong><a class="reference internal" href="#trans-compare"><span class="std std-numref">Fig. 4.6</span></a></strong>).</p>
<figure class="align-default">
<a class="reference internal image-reference" href="trans_diff_bias.png"><img alt="trans_diff_bias.png" src="trans_diff_bias.png" style="height: 350px;" /></a>
</figure>
<figure class="align-default" id="trans-compare">
<a class="reference internal image-reference" href="trans_diff_mse.png"><img alt="trans_diff_mse.png" src="trans_diff_mse.png" style="height: 350px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4.6 </span><span class="caption-text"><em>Empirical Bias and MSE for CensusEB FGT0 estimates under different transformations</em></span><a class="headerlink" href="#trans-compare" title="Permalink to this image">#</a></p>
<div class="legend">
<p>Source: Based on samples generated as described in <span id="id74">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id112" title="Paul Corral, Kristen Himelein, Kevin McGee, and Isabel Molina. A map of the poor or a poor map? Mathematics, 2021. URL: https://www.mdpi.com/2227-7390/9/21/2780, doi:10.3390/math9212780.">2021</a>]</span> section 4. The figure illustrates the potential gains from a correct data transformation. Taking the natural logarithm of the dependent variable in this case is not enough and can lead to considerable deviations from normality and thus may yield larger empirical MSEs and biased predictors.</p>
</div>
</figcaption>
</figure>
<p>Implementation of a suitable data transformation in Stata is straightforward, since Stata offers commands for the Box-Cox and the zero-skewness log (log-shift) transformation.<a class="footnote-reference brackets" href="#id289" id="id75">23</a> The Stata <code class="docutils literal notranslate"><span class="pre">sae</span></code> package (<span id="id76">Nguyen <em>et al.</em> [<a class="reference internal" href="#id151" title="Minh Cong Nguyen, Paul Corral, João Pedro Azevedo, and Qinghua Zhao. Sae: a stata package for unit level small area estimation. World Bank Policy Research Working Paper, 2018.">2018</a>]</span>) also includes these transformations, in addition to the natural logarithm, as options and will apply the transformation for the model. The package will also reverse the transformation to calculate the indicators of interest in each Monte Carlo simulation. Prior to estimating the indicators, practitioners may wish to do model selection (e.g., by lasso or stepwise regression) using an already transformed dependent variable. Once the transformed dependent variable is obtained, practitioners can then conduct histograms and visually inspect the shape of the distribution of the dependent variable (see <strong><a class="reference internal" href="#lny"><span class="std std-numref">Fig. 4.7</span></a></strong>).</p>
<figure class="align-default" id="lny">
<a class="reference internal image-reference" href="ln_welfare.png"><img alt="ln_welfare.png" src="ln_welfare.png" style="height: 350px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4.7 </span><span class="caption-text"><em>Natural logarithm of welfare</em></span><a class="headerlink" href="#lny" title="Permalink to this image">#</a></p>
<div class="legend">
<p>Source: <span id="id77">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id112" title="Paul Corral, Kristen Himelein, Kevin McGee, and Isabel Molina. A map of the poor or a poor map? Mathematics, 2021. URL: https://www.mdpi.com/2227-7390/9/21/2780, doi:10.3390/math9212780.">2021</a>]</span> . The figure illustrates how, in this case, taking the natural logarithm of welfare leaves a left skewed distribution which may yield biased and noisier estimators.</p>
</div>
</figcaption>
</figure>
<p>Once a satisfactory transformation is obtained, the process of model selection of the covariates can occur. The model selection process consists of selecting the response variable and the most powerful set of covariates such that the assumptions underlying the chosen SAE method hold – primarily linearity and normality of the residuals. The consequences of deviations from the underlying model’s assumptions could lead to invalid inferences (<span id="id78">Rao and Molina [<a class="reference internal" href="06_diagnostics.html#id63" title="JNK Rao and Isabel Molina. Small Area Estimation. John Wiley &amp; Sons, 2nd edition, 2015.">2015</a>]</span>) or not too noisy but biased estimates (<span id="id79">Banerjee <em>et al.</em> [<a class="reference internal" href="05_off-census.html#id133" title="Abhijit V Banerjee, Angus Deaton, Nora Lustig, Kenneth Rogoff, and Edward Hsu. An evaluation of world bank research, 1998-2005. Available at SSRN 2950327, 2006.">2006</a>]</span>). The model selection procedure is further explored in <strong>Chapter 6: <a class="reference internal" href="06_diagnostics.html#diagnostics"><span class="std std-ref">Model Diagnostics</span></a></strong> in <strong><a class="reference internal" href="06_diagnostics.html#diagnostics-selection"><span class="std std-numref">Section 6.2</span></a></strong>.</p>
</section>
<section id="the-alpha-model">
<span id="unit-level-first-sae-alpha"></span><h3><span class="section-number">4.2.3. </span>The Alpha Model<a class="headerlink" href="#the-alpha-model" title="Permalink to this headline">#</a></h3>
<p>The alpha model proposed by ELL (<span id="id80">Elbers <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id64" title="Chris Elbers, Jean Olson Lanjouw, and Peter Lanjouw. Micro-level estimation of welfare. World Bank Policy Research Working Paper, 2002.">2002</a>]</span>) is a preliminary model for the variance of the idiosyncratic errors used for heteroskedasticity that resembles the one presented by <span id="id81">Harvey [<a class="reference internal" href="#id168" title="Andrew C Harvey. Estimating regression models with multiplicative heteroscedasticity. Econometrica: Journal of the Econometric Society, 44:461–465, 1976. URL: https://www.jstor.org/stable/1913974?casa_token=rLCctNWylroAAAAA:3-S22Hv84lze8TUU-3nyFgDGZsrxkAoCZHwUVKO99Qynn_zXmr8-3kmdqFxdLxRBJT8KiE-xYwfoI5-gzFA9RF3N-KHS3g7na1Soi8WbYp_QBcPfjU7m&amp;seq=1.">1976</a>]</span>.<a class="footnote-reference brackets" href="#id290" id="id82">24</a> Only limited research has been conducted on the impact of the alpha model for heteroskedasticity on the quality of the final small area estimates. In most applications, the adjusted <span class="math notranslate nohighlight">\(R^{2}\)</span> of the alpha model is relatively small, rarely above 0.05.</p>
<p>Nevertheless, the alpha model may play a considerable role in the bias and noise of the estimates. A simulation experiment based on the same data used for the validations conducted by <span id="id83">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id112" title="Paul Corral, Kristen Himelein, Kevin McGee, and Isabel Molina. A map of the poor or a poor map? Mathematics, 2021. URL: https://www.mdpi.com/2227-7390/9/21/2780, doi:10.3390/math9212780.">2021</a>]</span> shows that applying an alpha model to obtain CensusEB estimates might yield considerably less noisy and less biased estimates (see <strong><a class="reference internal" href="#compare-alfa"><span class="std std-numref">Fig. 4.8</span></a></strong>).<a class="footnote-reference brackets" href="#id292" id="id84">25</a> This result may not translate to other data sets, which might not suffer from heteroskedasticity, and thus, using the alpha model should not be considered a universal recommendation. Practitioners should carefully inspect their model’s residuals for signs of heteroskedasticity before deciding to use the alpha model.<a class="footnote-reference brackets" href="#id293" id="id85">26</a></p>
<figure class="align-default">
<a class="reference internal image-reference" href="bias_alfa1.png"><img alt="bias_alfa1.png" src="bias_alfa1.png" style="height: 350px;" /></a>
</figure>
<figure class="align-default" id="compare-alfa">
<a class="reference internal image-reference" href="mse_alfa1.png"><img alt="mse_alfa1.png" src="mse_alfa1.png" style="height: 350px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4.8 </span><span class="caption-text"><em>Empirical Bias and MSE for CensusEB FGT0 estimates with and without alpha model</em></span><a class="headerlink" href="#compare-alfa" title="Permalink to this image">#</a></p>
<div class="legend">
<p>Source: Based on samples of populations generated as described in <span id="id86">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id112" title="Paul Corral, Kristen Himelein, Kevin McGee, and Isabel Molina. A map of the poor or a poor map? Mathematics, 2021. URL: https://www.mdpi.com/2227-7390/9/21/2780, doi:10.3390/math9212780.">2021</a>]</span> section 4. The alpha model as specified by ELL (<span id="id87">Elbers <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id64" title="Chris Elbers, Jean Olson Lanjouw, and Peter Lanjouw. Micro-level estimation of welfare. World Bank Policy Research Working Paper, 2002.">2002</a>]</span>) can be applied using the sae Package in Stata. Under the Mexican data used by <span id="id88">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id112" title="Paul Corral, Kristen Himelein, Kevin McGee, and Isabel Molina. A map of the poor or a poor map? Mathematics, 2021. URL: https://www.mdpi.com/2227-7390/9/21/2780, doi:10.3390/math9212780.">2021</a>]</span> the alpha model appears to yield positive results in terms of bias and MSE. This should be interpreted with caution as it may not be the case in other scenarios.</p>
</div>
</figcaption>
</figure>
<p>In practice, the implementation of the alpha model may limit modeling options for practitioners since, though available in the <code class="docutils literal notranslate"><span class="pre">PovMap</span></code> software, it is not included in many of the newer software packages for SAE. For example, heteroskadasticity is also considered by <span id="id89">Molina and Rao [<a class="reference internal" href="06_diagnostics.html#id67" title="Isabel Molina and JNK Rao. Small area estimation of poverty indicators. Canadian Journal of Statistics, 38(3):369–385, 2010.">2010</a>]</span>, as well as <span id="id90">Marhuenda <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id106" title="Yolanda Marhuenda, Isabel Molina, Domingo Morales, and JNK Rao. Poverty mapping in small areas under a twofold nested error regression model. Journal of the Royal Statistical Society: Series A (Statistics in Society), 180(4):1111-1136, 2017. doi:10.1111/rssa.12306.">2017</a>]</span>. However, they do not specify the alpha model, and no software package implementation of their methods allows users to specify heteroskedasticity. The Stata <code class="docutils literal notranslate"><span class="pre">sae</span></code> package allows users to model heteroskedasticity for SAE, but only does so when using specific model fitting procedures such as the Henderson method III extension proposed by <span id="id91">Van der Weide [<a class="reference internal" href="#id156" title="Roy Van der Weide. GLS estimation and empirical bayes prediction for linear mixed models with heteroskedasticity and sampling weights: A background study for the POVMAP project. World Bank Policy Research Working Paper, 2014. URL: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2495175.">2014</a>]</span> or the traditional ELL fitting method.<a class="footnote-reference brackets" href="#id294" id="id92">27</a> When choosing to apply the alpha model, the Stata <code class="docutils literal notranslate"><span class="pre">sae</span></code> package has an option that automatically constructs the dependent variable. This dependent variable may be used to facilitate the selection of a suitable model for heteroskedasticity. A removal process of non-significant covariates may also be implemented for the alpha model, as shown in the script of <strong><a class="reference internal" href="#unit-level-appendix-selection"><span class="std std-numref">Section 4.5.1</span></a></strong>.</p>
</section>
<section id="producing-small-area-estimates">
<span id="unit-level-first-sae-estimates"></span><h3><span class="section-number">4.2.4. </span>Producing Small Area Estimates<a class="headerlink" href="#producing-small-area-estimates" title="Permalink to this headline">#</a></h3>
<p>Once the model selection stage is completed, the next step is to obtain estimates for small areas. Model selection and simulation stages may be separated in different scripts to avoid re-running unnecessary processes in case of errors in only one of the stages.<a class="footnote-reference brackets" href="#id296" id="id93">28</a> Model selection (see Stata script in <strong><a class="reference internal" href="#unit-level-appendix-selection"><span class="std std-numref">Section 4.5.1</span></a></strong>) is discussed in greater detail in <strong>Chapter 6: <a class="reference internal" href="06_diagnostics.html#diagnostics"><span class="std std-ref">Model Diagnostics</span></a></strong> where attention is given to the different steps involved.</p>
<p>The Monte Carlo simulation process can be seen in the Stata script of <strong><a class="reference internal" href="#unit-level-appendix-simulation"><span class="std std-numref">Section 4.5.2</span></a></strong> and follows the model selection stage. The production of small area estimates requires first importing the census data. In Stata, it is imported into a Mata (Stata’s matrix programming language) data file, which will allow users to work with larger data sets than what is usually possible.<a class="footnote-reference brackets" href="#id297" id="id94">29</a> The user must specify the vectors she wishes to import, including household expansion factors (typically household size) within the census data. The census data should have variable names equal to those in the survey. It is recommended to import only the necessary variables from the census to avoid creating larger data files than needed for the process.</p>
<p>The SAE process can be broken up into two steps. The first step entails producing the point estimates through Monte Carlo simulation. This step is relatively fast, and the recommended amount of simulations is at least 100. The estimation of the MSE is considerably more time-consuming and will usually take several hours, depending on the size of the census. Thus, it is recommended to first obtain small area estimates without specifying bootstrap simulations for MSE estimation. Once users have done their checks and determined the quality of their point estimates, the MSE can be estimated. It is recommended to use at least 200 bootstrap replications to estimate MSEs.</p>
</section>
</section>
<section id="pros-and-cons-of-unit-level-models">
<span id="unit-level-pros"></span><h2><span class="section-number">4.3. </span>Pros and Cons of Unit-Level Models<a class="headerlink" href="#pros-and-cons-of-unit-level-models" title="Permalink to this headline">#</a></h2>
<p>This section presents a convenient list of pros and cons for each method. It also notes the needs for each of the methods. The section borrows heavily and adds to the work presented in <span id="id95">Molina [<a class="reference internal" href="05_off-census.html#id115" title="Isabel Molina. Desagregación De Datos En Encuestas De Hogares: Metodologías De Estimación En áreas Pequeñas. CEPAL, 2019. URL: https://repositorio.cepal.org/handle/11362/44214.">2019</a>]</span>.</p>
<section id="ell">
<span id="unit-level-pros-ell"></span><h3><span class="section-number">4.3.1. </span>ELL<a class="headerlink" href="#ell" title="Permalink to this headline">#</a></h3>
<p>Model requirements:</p>
<ol class="simple">
<li><p>Microdata from a household survey and census at the household level, with variables measured and questions asked similarly.</p></li>
<li><p>A set of variables related to the welfare variable of interest. These variables should have similar distributions between the two data sources.</p></li>
<li><p>Areas in the survey and the census should have identifiers that can be linked across each other.</p></li>
</ol>
<p>Pros:</p>
<ol class="simple">
<li><p>The model is based on household-level data, which gives more detailed information than area-level data, and have a considerably larger sample size.</p></li>
<li><p>Can provide estimates for non-sampled areas.</p></li>
<li><p>Estimates from any indicator that is a function of welfare can be obtained without relying on different models.</p></li>
<li><p>The estimates are unbiased under the model if the model is true and the model parameters are known.</p></li>
<li><p>It is possible to get estimates at any level of aggregation.</p></li>
<li><p>Offers a software-implemented model for heteroskedasticity.</p></li>
</ol>
<p>Cons:</p>
<ol class="simple">
<li><p>The method, as is currently implemented, may yield rather noisy (inefficient) estimates and may even be worse than direct estimates (obtained using only the area-specific information from the survey), if heterogeneity between areas is not explained adequately.</p>
<ol class="simple">
<li><p>The noise of the traditional ELL estimates is large but it is also underestimated under the ELL bootstrap procedure (see <span id="id96">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span> for details).</p></li>
<li><p>To reduce the above noise to the largest possible extent, it is always recommendable to include all the potentially significant covariates that may affect welfare, including contextual covariates, which may be taken from data sources different from the census.</p></li>
</ol>
</li>
<li><p>Estimates are the outcome of a model and thus, the model needs to be appropriately checked.</p></li>
<li><p>The traditional ELL model specifies the location effects for the clusters (PSUs), typically nested within the areas where the estimation is desired. Estimations at higher aggregation levels than those at which the location effects are specified can underestimate noise if the area-level variables included in the model fail to explain the between-area heterogeneity.</p></li>
</ol>
</section>
<section id="empirical-best-and-censuseb">
<span id="unit-level-pros-eb"></span><h3><span class="section-number">4.3.2. </span>Empirical Best and CensusEB<a class="headerlink" href="#empirical-best-and-censuseb" title="Permalink to this headline">#</a></h3>
<p>Model requirements:</p>
<ol class="simple">
<li><p>Microdata from a household survey and census at the household level with variables measured and questions asked in a similar manner.</p></li>
<li><p>A set of variables related to the welfare variable of interest. These variables should have similar distributions between the two data sources.</p></li>
<li><p>Areas in the survey and the census should have identifiers that can be linked across each other.</p></li>
</ol>
<p>Pros:</p>
<ol class="simple">
<li><p>Based on household-level data which provide more detailed information than area-level data and have a considerably larger sample size.</p></li>
<li><p>Can provide estimates for non-sampled areas.</p></li>
<li><p>Estimates from any indicator that is a function of welfare can be obtained without relying on different models.</p></li>
<li><p>Unbiased under the model, if the model is true and model parameters are known.</p></li>
<li><p>Optimal in the sense that they minimize the MSE under the model.</p></li>
<li><p>Considerably less noisy than ELL when unexplained heterogeneity across areas is considerable. For non-sampled areas, ELL and EB estimators are similar.</p></li>
<li><p>Offers a software-implemented model for heteroskedasticity (choosing H3 CensusEB in the Stata <code class="docutils literal notranslate"><span class="pre">sae</span></code> package).</p></li>
</ol>
<p>Cons:</p>
<ol class="simple">
<li><p>They are the outcome of a model and thus the model needs to be properly checked.</p></li>
<li><p>It may be affected by deviations from the model’s assumptions. For example, deviation from normality or outliers can have detrimental effects on SAE - isolated unit-level outliers may not have much impact if the sample size is large.</p></li>
<li><p>Original EB estimates do not consider the sampling design and are not design-unbiased and hence may be affected by informative sampling designs (i.e., when the sample selection probabilities depend on the outcome values - Rao and Molina <span id="id97">Rao and Molina [<a class="reference internal" href="06_diagnostics.html#id63" title="JNK Rao and Isabel Molina. Small Area Estimation. John Wiley &amp; Sons, 2nd edition, 2015.">2015</a>]</span>).</p>
<ol class="simple">
<li><p>In the Stata <code class="docutils literal notranslate"><span class="pre">sae</span></code> package, the REML option obtains the original EB, but H3 CensusEB incorporates the sampling weights and should not be sensibly affected by informative sampling.</p></li>
</ol>
</li>
<li><p>The bootstrap method for MSE estimation is computationally intensive.</p></li>
</ol>
</section>
<section id="alternative-software-packages-for-unit-level-models-and-extensions">
<span id="unit-level-pros-alt"></span><h3><span class="section-number">4.3.3. </span>Alternative Software Packages for Unit-Level Models and Extensions<a class="headerlink" href="#alternative-software-packages-for-unit-level-models-and-extensions" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Packages that implement the one-fold nested-error model EB approach from <span id="id98">Molina and Rao [<a class="reference internal" href="06_diagnostics.html#id67" title="Isabel Molina and JNK Rao. Small area estimation of poverty indicators. Canadian Journal of Statistics, 38(3):369–385, 2010.">2010</a>]</span>:</p>
<ul>
<li><p>The<code class="docutils literal notranslate"> <span class="pre">sae</span></code> package in R (<span id="id99">Molina and Marhuenda [<a class="reference internal" href="06_diagnostics.html#id68" title="Isabel Molina and Yolanda Marhuenda. Sae: an R package for small area estimation. The R Journal, 7(1):81–98, 2015.">2015</a>]</span>).</p></li>
<li><p>After the updates presented in <span id="id100">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span> the <code class="docutils literal notranslate"><span class="pre">sae</span></code> package in Stata (<span id="id101">Nguyen <em>et al.</em> [<a class="reference internal" href="#id151" title="Minh Cong Nguyen, Paul Corral, João Pedro Azevedo, and Qinghua Zhao. Sae: a stata package for unit level small area estimation. World Bank Policy Research Working Paper, 2018.">2018</a>]</span>).</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">emdi</span></code> package in R (<span id="id102"></span>).</p></li>
</ul>
</li>
<li><p>Empirical best prediction that incorporates the survey weights (Pseudo EB):</p>
<ul>
<li><p>The <code class="docutils literal notranslate"><span class="pre">emdi</span></code> package in R (<span id="id103"></span>) has been extended to include the Pseudo EB method presented in <span id="id104">Guadarrama <em>et al.</em> [<a class="reference internal" href="#id149" title="María Guadarrama, Isabel Molina, and JNK Rao. Small area estimation of general parameters under complex sampling designs. Computational Statistics &amp; Data Analysis, 121:20–40, 2018.">2018</a>]</span>.</p></li>
<li><p>After the updates presented in <span id="id105">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span> the <code class="docutils literal notranslate"><span class="pre">sae</span></code> package in Stata (<span id="id106">Nguyen <em>et al.</em> [<a class="reference internal" href="#id151" title="Minh Cong Nguyen, Paul Corral, João Pedro Azevedo, and Qinghua Zhao. Sae: a stata package for unit level small area estimation. World Bank Policy Research Working Paper, 2018.">2018</a>]</span>) includes the model-fitting method that incorporates the survey weights presented in <span id="id107">Van der Weide [<a class="reference internal" href="#id156" title="Roy Van der Weide. GLS estimation and empirical bayes prediction for linear mixed models with heteroskedasticity and sampling weights: A background study for the POVMAP project. World Bank Policy Research Working Paper, 2014. URL: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2495175.">2014</a>]</span>.</p>
<ul>
<li><p>The implemented method only obtains CensusEB estimates.</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Two-fold nested-error model EB approach as presented in <span id="id108">Marhuenda <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id106" title="Yolanda Marhuenda, Isabel Molina, Domingo Morales, and JNK Rao. Poverty mapping in small areas under a twofold nested error regression model. Journal of the Royal Statistical Society: Series A (Statistics in Society), 180(4):1111-1136, 2017. doi:10.1111/rssa.12306.">2017</a>]</span>:</p>
<ul>
<li><p>After the updates presented in <span id="id109">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span>, the <code class="docutils literal notranslate"><span class="pre">sae</span></code> package in Stata (<span id="id110">Nguyen <em>et al.</em> [<a class="reference internal" href="#id151" title="Minh Cong Nguyen, Paul Corral, João Pedro Azevedo, and Qinghua Zhao. Sae: a stata package for unit level small area estimation. World Bank Policy Research Working Paper, 2018.">2018</a>]</span>).</p>
<ul>
<li><p>The implemented method only obtains CensusEB estimates.</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Estimation of area means (without transformation of welfare) based on Hierarchical Bayes unit-level models:</p>
<ul>
<li><p>The <code class="docutils literal notranslate"><span class="pre">hbsae</span></code> package in R (<span id="id111">Boonstra [<a class="reference internal" href="#id248" title="Harm Jan Boonstra. Package 'hbsae'. R Package Version, 2015.">2015</a>]</span>).</p></li>
</ul>
</li>
<li><p>ELL approach:</p>
<ul>
<li><p>The <code class="docutils literal notranslate"><span class="pre">sae</span></code> package in Stata (<span id="id112">Nguyen <em>et al.</em> [<a class="reference internal" href="#id151" title="Minh Cong Nguyen, Paul Corral, João Pedro Azevedo, and Qinghua Zhao. Sae: a stata package for unit level small area estimation. World Bank Policy Research Working Paper, 2018.">2018</a>]</span>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">PovMap</span></code>, which is a free stand-alone software (<span id="id113">Zhao [<a class="reference internal" href="#id155" title="Qinghua Zhao. User Manual for Povmap. 2006. URL: http://siteresources. worldbank. org/INTPGI/Resources/342674-1092157888460/Zhao_ ManualPovMap. pdf.">2006</a>]</span>).</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="unit-level-models-technical-annex">
<span id="unit-level-annex"></span><h2><span class="section-number">4.4. </span>Unit-Level Models – Technical Annex<a class="headerlink" href="#unit-level-models-technical-annex" title="Permalink to this headline">#</a></h2>
<section id="unit-level-annex-model">
<span id="id114"></span><h3><span class="section-number">4.4.1. </span>The Assumed Model<a class="headerlink" href="#unit-level-annex-model" title="Permalink to this headline">#</a></h3>
<p>The nested-error model used for small area estimation by ELL (<span id="id115">Elbers <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id52" title="Chris Elbers, Jean O Lanjouw, and Peter Lanjouw. Micro–level estimation of poverty and inequality. Econometrica, 71(1):355–364, 2003.">2003</a>]</span>) and <span id="id116">Molina and Rao [<a class="reference internal" href="06_diagnostics.html#id67" title="Isabel Molina and JNK Rao. Small area estimation of poverty indicators. Canadian Journal of Statistics, 38(3):369–385, 2010.">2010</a>]</span> was originally proposed by <span id="id117">Battese, Harter, and Fuller [<a class="reference internal" href="#id190" title="George E. Battese, Rachel M. Harter, and Wayne A. Fuller. An error-components model for prediction of county crop areas using survey and satellite data. Journal of the American Statistical Association, 83(401):28–36, 1988. URL: http://www.jstor.org/stable/2288915.">1988</a>]</span> to produce county-level corn and soybean crop area estimates for the American state of Iowa. For the estimation of poverty and welfare, the ELL and MR methods assume the transformed welfare <span class="math notranslate nohighlight">\(y_{ch}\)</span> for each household <span class="math notranslate nohighlight">\(h\)</span> in the population within each location <span class="math notranslate nohighlight">\(c\)</span> is linearly related to a <span class="math notranslate nohighlight">\(1\times K\)</span> vector of characteristics (or correlates) <span class="math notranslate nohighlight">\(x_{ch}\)</span> for that household, according to the nested-error model:</p>
<div class="math notranslate nohighlight" id="equation-eq-1-1">
<span class="eqno">(4.2)<a class="headerlink" href="#equation-eq-1-1" title="Permalink to this equation">#</a></span>\[y_{ch}=x_{ch}\beta+\eta_{c}+e_{ch},\:h=1,\ldots,N_{c},\,c=1,\ldots,C.\]</div>
<p>Here <span class="math notranslate nohighlight">\(\eta_{c}\)</span> and <span class="math notranslate nohighlight">\(e_{ch}\)</span> are respectively location and household-specific idiosyncratic errors, assumed to be independent from each other, satisfying: $<span class="math notranslate nohighlight">\(\eta_{c}\stackrel{iid}{\sim}N\left(0,\sigma_{\eta}^{2}\right),\:e_{ch}\stackrel{iid}{\sim}N\left(0,\sigma_{e}^{2}\right),\)</span>$</p>
<p>where the variances <span class="math notranslate nohighlight">\(\sigma_{\eta}^{2}\)</span> and <span class="math notranslate nohighlight">\(\sigma_{e}^{2}\)</span> are unknown. Here, <span class="math notranslate nohighlight">\(C\)</span> is the number of locations in which the population is divided and <span class="math notranslate nohighlight">\(N_{c}\)</span> is the number of households in location <span class="math notranslate nohighlight">\(c\)</span>, for <span class="math notranslate nohighlight">\(c=1,\ldots,C\)</span>. Finally, <span class="math notranslate nohighlight">\(\beta\)</span> is the <span class="math notranslate nohighlight">\(K\times1\)</span> vector of coefficients.</p>
<p>To illustrate the differences between the methods, understanding the model is essential. First, note that the random location effect is the same for all households within a given area. Second, note that the random location effect is not necessarily 0 for a given location, despite the random location effect being drawn from a normal distribution with mean 0. Consequently, for any given realization of the population, the random location effect is unlikely to be equal to 0, but its expected value is 0 across all the possible realizations. To see this, a simulation where the random location effects for 80 areas are drawn from a normal distribution <span class="math notranslate nohighlight">\(\eta_{c}\stackrel{iid}{\sim}N\left(0,0.15^{2}\right)\)</span>, is shown in the Stata code snippet below. This is repeated across 10,000 simulated populations.</p>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span><span class="c1">//Do file simulates random location effects for 80 areas</span>
<span class="k">set more</span> off<span class="k"></span>
<span class="k">clear</span> all<span class="k"></span>
<span class="k">version</span> <span class="m">14</span><span class="k"></span>
<span class="k">set</span> maxvar <span class="m">10100</span>

<span class="c1">//Seed for replicability</span>
<span class="k">set</span> seed <span class="m">232989</span>
<span class="c1">//Necessary macros</span>
<span class="k">local</span> sigmaeta = <span class="m">0.15</span>     <span class="c1">//Sigma eta</span>
<span class="k">local</span> Npop     = <span class="m">10000</span>    <span class="c1">//number of populations</span>
<span class="k">local</span> Narea    = <span class="m">80</span>
<span class="c1">//Create simulated data</span>
<span class="k">set</span> obs <span class="nv">`Narea&#39;</span>
<span class="c1">//Simulate random location effects for 80 areas, 10000 populations</span>
<span class="k">forval</span> z=<span class="m">1</span><span class="o">/</span><span class="nv">`Npop&#39;</span>{
<span class="k">	gen</span> double eta_<span class="nv">`z&#39;</span> = <span class="nf">rnormal</span>(<span class="m">0</span>,<span class="nv">`sigmaeta&#39;</span>)
}
<span class="c1">//Look at values for 1 population</span>
<span class="k">sum</span> eta_1,<span class="k"> d</span> <span class="c1">//very close to 0</span>
<span class="k">list</span> eta_1<span class="k"> if</span> _n<span class="o">==</span><span class="m">23</span> <span class="c1">//not 0</span>
<span class="c1">//The expected value of the random location effect across populations</span>
<span class="k">egen</span> double E_eta = rmean(eta_<span class="o">*</span>)<span class="k"></span>
<span class="k">sum</span> E_eta,d
<span class="c1">//The expected value for one area across all populations</span>
<span class="k">list</span> E_eta<span class="k"> if</span> _n<span class="o">==</span><span class="m">23</span> <span class="c1">//approximating 0</span>
</pre></div>
</div>
<p>Note how in the results, the value of the random location effect for a given area and population is not necessarily equal to 0. However, across all the generated populations, the mean value of the random location effect for all areas is very close to 0.</p>
<p>This aspect is important, because it highlights the key difference between the methodology from ELL (<span id="id118">Elbers <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id52" title="Chris Elbers, Jean O Lanjouw, and Peter Lanjouw. Micro–level estimation of poverty and inequality. Econometrica, 71(1):355–364, 2003.">2003</a>]</span>) and the EB approach from MR (<span id="id119">Molina and Rao [<a class="reference internal" href="06_diagnostics.html#id67" title="Isabel Molina and JNK Rao. Small area estimation of poverty indicators. Canadian Journal of Statistics, 38(3):369–385, 2010.">2010</a>]</span>). Under ELL, when simulating welfare for the census, the location effect is drawn exactly as assumed under the model, that is as, <span class="math notranslate nohighlight">\(\eta_{c}\stackrel{iid}{\sim}N\left(0,\sigma_{\eta}^{2}\right)\)</span>. In essence, under ELL, for any given area present in the sample, the ELL estimator of the census area mean <span class="math notranslate nohighlight">\(\bar{y}_{c}\)</span> is obtained by averaging the actual area means <span class="math notranslate nohighlight">\(\bar{y}_{c}^{*(m)}=\bar{X}_{c}'\beta+\eta_{c}^{*(m)}+\bar{e}_{c}^{*(m)}\)</span>, <span class="math notranslate nohighlight">\(m=1,\ldots,M\)</span>, across <span class="math notranslate nohighlight">\(M\)</span> simulated populations, that is, the ELL estimator is <span class="math notranslate nohighlight">\(\frac{1}{M}\sum_{m=1}^{M}\bar{y}_{c}^{*(m)}\)</span>, which approximates <span class="math notranslate nohighlight">\(E\left(\bar{y}_{c}\right)\)</span>. But note that <span class="math notranslate nohighlight">\(E[\eta_{c}]=0\)</span> and <span class="math notranslate nohighlight">\(E[e_{ch}]=0\)</span>. Hence, the ELL estimator reduces to the regression-synthetic estimator, <span class="math notranslate nohighlight">\(\bar{X}_{c}'\beta\)</span> (MR, <span id="id120">Molina and Rao [<a class="reference internal" href="06_diagnostics.html#id67" title="Isabel Molina and JNK Rao. Small area estimation of poverty indicators. Canadian Journal of Statistics, 38(3):369–385, 2010.">2010</a>]</span>). On the other hand, under MR (<span id="id121">Molina and Rao [<a class="reference internal" href="06_diagnostics.html#id67" title="Isabel Molina and JNK Rao. Small area estimation of poverty indicators. Canadian Journal of Statistics, 38(3):369–385, 2010.">2010</a>]</span>), conditioning on the survey sample ensures that the estimator includes the random location effect, since <span class="math notranslate nohighlight">\(E[\bar{y}_{c}|\eta_{c}]=\bar{X}_{c}'\beta+\eta_{c}\)</span>. <span id="id122"></span> suggests that the inclusion of contextual variables somewhat attenuates the issue. Nevertheless, unless the contextual variables together with the household-level ones fully explain the variation in welfare across areas, there will always be gains from using EB compared to ELL. Actually, the EB approach from <span id="id123">Molina and Rao [<a class="reference internal" href="06_diagnostics.html#id67" title="Isabel Molina and JNK Rao. Small area estimation of poverty indicators. Canadian Journal of Statistics, 38(3):369–385, 2010.">2010</a>]</span> gives approximately the <em>best</em> estimator in the sense that it yields the estimator with the minimum mean squared error (MSE) for target areas. Consequently, EB estimators are considerably more efficient than ELL (see <span id="id124">Molina and Rao [<a class="reference internal" href="06_diagnostics.html#id67" title="Isabel Molina and JNK Rao. Small area estimation of poverty indicators. Canadian Journal of Statistics, 38(3):369–385, 2010.">2010</a>]</span>; <span id="id125">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span>; and <span id="id126">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id112" title="Paul Corral, Kristen Himelein, Kevin McGee, and Isabel Molina. A map of the poor or a poor map? Mathematics, 2021. URL: https://www.mdpi.com/2227-7390/9/21/2780, doi:10.3390/math9212780.">2021</a>]</span>).</p>
<p>A census data set of <span class="math notranslate nohighlight">\(N=20,000\)</span> observations is created, similar to MR (<span id="id127">Molina and Rao [<a class="reference internal" href="06_diagnostics.html#id67" title="Isabel Molina and JNK Rao. Small area estimation of poverty indicators. Canadian Journal of Statistics, 38(3):369–385, 2010.">2010</a>]</span>), to observe how conditioning on the survey sample affects the resulting small area estimates. Under the created data, all observations are uniformly spread among <span class="math notranslate nohighlight">\(C=80\)</span> areas, labeled from 1 to 80. This means that every area consists of <span class="math notranslate nohighlight">\(N_{c}=250\)</span> observations. The location effects are simulated as <span class="math notranslate nohighlight">\(\eta_{c}\stackrel{iid}{\sim}N\left(0,0.15^{2}\right)\)</span>; note that every observation within a given area will have the same simulated effect. Then, values of two right-hand side binary variables are simulated. The first one, <span class="math notranslate nohighlight">\(x_{1}\)</span>, takes a value of 1 if a generated random uniform value between 0 and 1 is less than or equal to <span class="math notranslate nohighlight">\(0.3+0.5\frac{c}{80}\)</span>. This means that observations in areas with a higher label are more likely to get a value of 1. The next one, <span class="math notranslate nohighlight">\(x_{2}\)</span>, is not tied to the area’s label. This variable takes the value 1 if a simulated random uniform value between 0 and 1 is less than or equal to 0.2. The census welfare vectors <span class="math notranslate nohighlight">\(y_{c}=(y_{c,1},\ldots,y_{c,N_{c}})^{T}\)</span> for each area <span class="math notranslate nohighlight">\(c=1,\ldots,C\)</span>, are then created from the model as follows: <span class="math notranslate nohighlight">\(\ln(y_{ch})=3+0.03x_{1,ch}-0.04x_{2,ch}+\eta_{c}+e_{ch},\)</span> where household-level errors are generated under the homoskedastic setup, as <span class="math notranslate nohighlight">\(e_{ch}\overset{iid}N\left(0,0.5^{2}\right)\)</span>. The poverty line is fixed at <span class="math notranslate nohighlight">\(z=12\)</span>, corresponding to roughly 60 percent of the median welfare of a generated population. The steps to creating such a population in Stata are shown below:</p>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span><span class="k">set more</span> off<span class="k"></span>
<span class="k">clear</span> all<span class="k"></span>
<span class="k">version</span> <span class="m">14</span><span class="k"></span>
<span class="k">set</span> seed <span class="m">648743</span>

<span class="k">local</span> obsnum    = <span class="m">20000</span>  <span class="c1">//Number of observations in our &quot;census&quot;</span>
<span class="k">local</span> areasize  = <span class="m">250</span>    <span class="c1">//Number of observations by area</span>
<span class="k">local</span> outsample = <span class="m">20</span>	 <span class="c1">//Sample size from each area (%)</span>
<span class="k">local</span> sigmaeta = <span class="m">0.15</span>     <span class="c1">//Sigma eta</span>
<span class="k">local</span> sigmaeps = <span class="m">0.5</span>      <span class="c1">//Sigma eps</span>


<span class="c1">// Create area random effects</span>
<span class="k">set</span> obs <span class="nv">`=`obsnum&#39;/`areasize&#39;&#39;</span><span class="k"></span>
<span class="k">gen</span> area = _n	<span class="c1">// label areas 1 to C</span>
<span class="k">gen</span> eta  = <span class="nf">rnormal</span>(<span class="m">0</span>,<span class="nv">`sigmaeta&#39;</span>)  <span class="c1">//Generate random location effects</span>
<span class="k">expand</span> <span class="nv">`areasize&#39;</span> <span class="c1">//leaves us with 250 observations per area</span>
<span class="k">sort</span> area <span class="c1">//To ensure everything is ordered - this matters for replicability</span>
<span class="c1">//Household identifier</span>
<span class="k">gen</span> hhid = _n
<span class="c1">//Household expansion factors - assume all 1</span>
<span class="k">gen</span> hhsize = <span class="m">1</span>
<span class="c1">//Household specific residual	</span>
<span class="k">gen e</span> = <span class="nf">rnormal</span>(<span class="m">0</span>,<span class="nv">`sigmaeps&#39;</span>)
<span class="c1">//Covariates, some are corrlated to the area&#39;s label</span>
<span class="k">gen</span> x1=<span class="nf">runiform</span>()<span class="o">&lt;=</span>(<span class="m">0.3+.5</span><span class="o">*</span>area<span class="o">/</span><span class="nv">`=`obsnum&#39;/`areasize&#39;&#39;</span>)<span class="k"></span>
<span class="k">gen</span> x2=<span class="nf">runiform</span>()<span class="o">&lt;=</span>(<span class="m">0.2</span>)
<span class="c1">//Welfare vector</span>
<span class="k">gen</span> Y_B = <span class="m">3</span><span class="o">+</span> .<span class="m">03</span><span class="o">*</span> x1<span class="m">-.04</span><span class="o">*</span> x2 <span class="o">+</span> eta <span class="o">+</span><span class="k"> e</span>

<span class="k">preserve</span>
<span class="k">	sort</span> hhid
<span class="k">	sample</span> <span class="m">20</span>,<span class="k"> by</span>(area)
<span class="k">	keep</span> Y_B x1 x2 area hhid
<span class="k">	save</span> <span class="s">&quot;</span><span class="vg">$mdata</span><span class="s">\sample.dta&quot;</span>,<span class="k"> replace</span>
<span class="k">restore</span>

<span class="k">save</span> <span class="s">&quot;</span><span class="vg">$mdata</span><span class="s">\thepopulation.dta&quot;</span>,<span class="k"> replace</span>
</pre></div>
</div>
<p>The nested-error model is then fit to the population data using restricted maximum likelihood:</p>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span>mixed Y_B x1 x2 || area:, reml
</pre></div>
</div>
<p>Linear predictions, <span class="math notranslate nohighlight">\(X\hat{\beta}\)</span>, can also be obtained:</p>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span><span class="k">predict</span> double xb, xb
</pre></div>
</div>
<p>Predicted random location effects, <span class="math notranslate nohighlight">\(\hat{\eta}_{c}\)</span>, can also be obtained:</p>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span><span class="k">predict</span> double eta_pred, reffects<span class="k"></span>
<span class="k">sum</span> eta_pred
</pre></div>
</div>
<p>Stata can also produce the linear prediction, <span class="math notranslate nohighlight">\(X\hat{\beta}\)</span>, plus the estimated location effects, <span class="math notranslate nohighlight">\(\hat{\eta}_{c}\)</span>:</p>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span><span class="k">predict</span> double xb_eta, fitted
</pre></div>
</div>
<p>The expected values of the linear predictor <span class="math notranslate nohighlight">\(X\hat{\beta}\)</span>, and the linear predictor that includes the predicted location effects, <span class="math notranslate nohighlight">\(X\hat{\beta}+\hat{\eta}_{c}\)</span>, are the same. The difference between these is that <span class="math notranslate nohighlight">\(X\hat{\beta}+\hat{\eta}_{c}\)</span> includes the estimated location effect, and thus, a larger share of the variance is explained, which leads to minimized estimation errors for the areas.</p>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span><span class="k">sum</span> Y_B xb xb_eta
</pre></div>
</div>
<p>At the same time, the area-specific predictions are considerably closer to the observed values:</p>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span><span class="k">collapse</span> Y_B xb xb_eta,<span class="k"> by</span>(area)<span class="k"></span>
<span class="k">list</span> Y_B xb xb_eta<span class="k"> in</span> <span class="m">1</span><span class="o">/</span><span class="m">10</span>
</pre></div>
</div>
</section>
<section id="monte-carlo-simulation-and-bootstrap-procedures-under-censuseb">
<span id="unit-level-annex-montecarlo"></span><h3><span class="section-number">4.4.2. </span>Monte Carlo Simulation and Bootstrap Procedures Under CensusEB<a class="headerlink" href="#monte-carlo-simulation-and-bootstrap-procedures-under-censuseb" title="Permalink to this headline">#</a></h3>
<p>The best predictor is defined as a conditional expectation. For indicators with a complex shape, the conditional expectation defining the best predictor may not have a closed form. Regardless of the shape, the best predictor can be approximated by Monte Carlo simulation (<span id="id128">Molina [<a class="reference internal" href="05_off-census.html#id115" title="Isabel Molina. Desagregación De Datos En Encuestas De Hogares: Metodologías De Estimación En áreas Pequeñas. CEPAL, 2019. URL: https://repositorio.cepal.org/handle/11362/44214.">2019</a>]</span>). ELL and MR’s EB approach clearly differ in the computational procedures used to estimate the indicators of interest and their noise. On the other hand, the original implementation of EB in <code class="docutils literal notranslate"><span class="pre">PovMap</span></code> and the <code class="docutils literal notranslate"><span class="pre">sae</span></code> Stata command used a similar computational approach to ELL. Under ELL and the original EB implementation in <code class="docutils literal notranslate"><span class="pre">PovMap</span></code>, noise and indicator estimates are all obtained with a single computational procedure. <span id="id129">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span> show that the noise estimates of the original ELL (referred to as variance by the authors) underestimate the true MSE of the indicators, despite ELL estimates being much noisier. On the other hand, the parametric bootstrap procedure from <span id="id130">González-Manteiga <em>et al.</em> [<a class="reference internal" href="05_off-census.html#id116" title="Wenceslao González-Manteiga, Maria J Lombardía, Isabel Molina, Domingo Morales, and Laureano Santamaría. Bootstrap mean squared error of a small-area EBLUP. Journal of Statistical Computation and Simulation, 78(5):443–462, 2008.">2008</a>]</span> seems to estimate the noise (MSE) of EB estimators correctly.</p>
<p>For an in-depth discussion on how ELL and EB computational procedures differ, see <span id="id131">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span>. For easy interpretation, the expositions presented here do not consider survey weights or heteroskedasticity.<a class="footnote-reference brackets" href="#id298" id="id132">30</a></p>
<section id="molina-and-rao-s-2010-monte-carlo-simulation-procedure-for-point-estimates">
<span id="unit-level-annex-montecarlo-molina"></span><h4><span class="section-number">4.4.2.1. </span>Molina and Rao’s (2010) Monte Carlo Simulation Procedure for Point Estimates<a class="headerlink" href="#molina-and-rao-s-2010-monte-carlo-simulation-procedure-for-point-estimates" title="Permalink to this headline">#</a></h4>
<p>The EB method from MR (<span id="id133">Molina and Rao [<a class="reference internal" href="06_diagnostics.html#id67" title="Isabel Molina and JNK Rao. Small area estimation of poverty indicators. Canadian Journal of Statistics, 38(3):369–385, 2010.">2010</a>]</span>) conditions on the survey sample data and thus makes more efficient use of the survey data, which contains the only available (and hence precious) information on the actual welfare. Conditioning on the survey data requires matching households across the survey and census. Matching households was required in the original EB approach introduced in MR (<span id="id134">Molina and Rao [<a class="reference internal" href="06_diagnostics.html#id67" title="Isabel Molina and JNK Rao. Small area estimation of poverty indicators. Canadian Journal of Statistics, 38(3):369–385, 2010.">2010</a>]</span>). However, the census and sample households can not be matched in practice, except in some countries. When linking the two data sources is not possible, this sample may be appended to the population for areas where there is a sample. This is the approach taken in the original EB implementation in the <code class="docutils literal notranslate"><span class="pre">sae</span></code> R package by <span id="id135">Molina and Marhuenda [<a class="reference internal" href="06_diagnostics.html#id68" title="Isabel Molina and Yolanda Marhuenda. Sae: an R package for small area estimation. The R Journal, 7(1):81–98, 2015.">2015</a>]</span>. In order to obtain a Monte Carlo approximation to the EB estimates using this software, estimates are obtained as a weighted average between a simulated census poverty rate for the area and the direct estimate of poverty obtained using the area’s sample. When the sample size relative to the population size for a given area is considerable, for example, 20%, using the sample observations of welfare may yield to a considerable gain in MSE. However, as noted in <strong><a class="reference internal" href="#cebvseb"><span class="std std-numref">Fig. 4.5</span></a></strong> in <strong><a class="reference internal" href="#unit-level-first-sae-model"><span class="std std-numref">Section 4.2.1</span></a></strong> the gain in MSE of EB over CensusEB approximates 0 as the sample size by area shrinks. When the sample is 4% of the population per area, an already quite large sample rarely encountered in real-world scenarios, the difference between the approaches is nearly zero.</p>
<p>To illustrate how CensusEB estimates are implemented, a 20% sample by area of the data created in <strong><a class="reference internal" href="#unit-level-appendix-selection"><span class="std std-numref">Section 4.5.1</span></a></strong> is used as a survey to which the model <strong>Equation <a class="reference internal" href="#equation-eq-1-1">(4.2)</a></strong> is fit. To obtain point estimates under <span id="id136">Molina and Rao [<a class="reference internal" href="06_diagnostics.html#id67" title="Isabel Molina and JNK Rao. Small area estimation of poverty indicators. Canadian Journal of Statistics, 38(3):369–385, 2010.">2010</a>]</span>, the authors assume that the considered unit-level model is the one that generates the data. Thus, the estimates for <span class="math notranslate nohighlight">\(\beta,\)</span> <span class="math notranslate nohighlight">\(\sigma_{\eta}^{2}\)</span>, and <span class="math notranslate nohighlight">\(\sigma_{e}^{2}\)</span> obtained from the fitted model are kept fixed in the Monte Carlo simulation procedure used to obtain EB point estimates.<a class="footnote-reference brackets" href="#id300" id="id137">31</a> Additionally, the predicted random location effects, <span class="math notranslate nohighlight">\(\hat{\eta}_{c}\)</span>, are also kept fixed as a result of conditioning on the sample observations of welfare.</p>
<p>The first step consists in fitting the model and obtaining the parameter estimates, <span class="math notranslate nohighlight">\(\hat{\theta}_{0}=\left(\hat{\beta_{0}},\:\hat{\sigma}_{\eta0}^{2},\:\hat{\sigma}_{e0}^{2}\right)\)</span> which are later used to simulate vectors of welfare for all the population of households (a census of welfare).</p>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span><span class="c1">//MonteCarlo simulation to obtain CensusEB estimates</span>
<span class="k">use</span> <span class="s">&quot;</span><span class="vg">$mdata</span><span class="s">\sample.dta&quot;</span>,<span class="k"> clear</span>

	<span class="c1">//fit model on the sample</span>
	mixed Y_B x1 x2 || area:, reml

	<span class="c1">//Obtain the necessary parameters</span>
<span class="k">		local</span> sigma_eta2 =  (<span class="nf">exp</span>([lns1_1_1]_cons))<span class="o">^</span><span class="m">2</span>
<span class="k">		local</span> sigma_e2   =  (<span class="nf">exp</span>([lnsig_e]_cons))<span class="o">^</span><span class="m">2</span>
</pre></div>
</div>
<p>With these estimates in hand, it is possible to predict the random location effects, <span class="math notranslate nohighlight">\(\eta_{c}\)</span>, as well as the shrinkage parameter, <span class="math notranslate nohighlight">\(\gamma_{c}=\sigma_{\eta}^{2}\left(\sigma_{\eta}^{2}+\sigma_{e}^{2}/n_{c}\right)^{-1}\)</span> and the variance of the random location effect, <span class="math notranslate nohighlight">\(\sigma_{\eta}^{2}(1-\gamma_{c})\)</span>. Notice that <span class="math notranslate nohighlight">\(\gamma_{c}\)</span> will be between 0 and 1, hence the variance of the location effect will be smaller than <span class="math notranslate nohighlight">\(\sigma_{\eta}^{2}\)</span>, which is the variance of the location effect under ELL. These model parameter estimates will then be used as true values to simulate the welfare vectors for the whole population of households.</p>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span>	<span class="c1">//Let&#39;s calculate the linear fit</span>
<span class="k">	predict</span> xb, xb
	
	<span class="c1">//Get the residual to calculate the random location effect</span>
<span class="k">	gen</span> residual = Y_B <span class="o">-</span> xb
	
	<span class="c1">//Number of observations by area</span>
<span class="k">	gen</span> n_area = <span class="m">1</span> <span class="c1">//we&#39;ll add it later</span>
	
groupfunction,<span class="k"> mean</span>(residual)<span class="k"> sum</span>(n_area)<span class="k"> by</span>(area)
	<span class="c1">//Gamma or adjustment factor ()</span>
<span class="k">	gen</span> double<span class="k"> gamma</span>  = <span class="nv">`sigma_eta2&#39;</span><span class="o">/</span>(<span class="nv">`sigma_eta2&#39;</span><span class="o">+</span><span class="nv">`sigma_e2&#39;</span><span class="o">/</span>n_area) 
	<span class="c1">//Produce eta</span>
<span class="k">	gen</span> double eta =<span class="k"> gamma</span><span class="o">*</span>residual
	<span class="c1">//variance of random location effects</span>
<span class="k">	gen</span> double var_eta = <span class="nv">`sigma_eta2&#39;</span><span class="o">*</span>(<span class="m">1</span><span class="o">-</span>gamma)
<span class="k">	</span>
<span class="k">	keep</span> area eta var_eta

<span class="k">tempfile</span> mylocs<span class="k"></span>
<span class="k">save</span> <span class="nv">`mylocs&#39;</span>
</pre></div>
</div>
<p>The next step consists in applying the estimated parameters, <span class="math notranslate nohighlight">\(\hat{\theta}_{0},\)</span> to generate the population vectors of welfare. Note how the same <span class="math notranslate nohighlight">\(\hat{\beta}_{0}\)</span> are used to produce the linear fit in every Monte Carlo simulation. Notice that the location effects are predicted from the sample from the corresponding area; thus, it is necessary to match areas across the sample and population. The next step consists in generating 100 vectors of welfare for the population units (census of welfare). Notice that here, the natural logarithm of welfare is reversed. Additionally, welfare for each household, <span class="math notranslate nohighlight">\(h\)</span>, is drawn from <span class="math notranslate nohighlight">\(\ln\left(y_{ch}\right)\sim N\left(x_{ch}\hat{\beta}_{0}+\hat{\eta}_{c0},\:\hat{\sigma}_{\eta0}^{2}(1-\hat{\gamma}_{c})+\hat{\sigma}_{e0}^{2}\right)\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>```stata
//Set seed for replicability
set seed 9374

//Bring in the population
use x1 x2 area hhid using &quot;$mdata\thepopulation.dta&quot;, clear
	//obtain linear fit - e(b) is still in memory
	predict xb, xb
	
	//Include eta and var_eta
	merge m:1 area using `mylocs&#39;
		drop if _m==2
		drop _m
	//to ensure replicability	
	sort hhid
```

```stata
	//generate 100 vectors of welfare in the population
	forval z=1/100{
	    //Take the exponential to obtain welfare
	    gen double Y_`z&#39; = exp(rnormal(xb + eta, sqrt(`sigma_e2&#39;+var_eta)))
	}
    
```
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span>  Input In [1]
    merge m:1 area using `mylocs&#39;
                                ^
SyntaxError: unterminated string literal (detected at line 11)
</pre></div>
</div>
</div>
</div>
<p>Finally, FGT indicators (<span id="id138">Foster <em>et al.</em> [<a class="reference internal" href="#id164" title="James Foster, Joel Greer, and Erik Thorbecke. A class of decomposable poverty measures. Econometrica: Journal of the Econometric Society, 52:761–766, 1984.">1984</a>]</span>) are calculated for each area from the simulated census – this is done for the 100 simulated censuses. Then, the CensusEB estimate is obtained by averaging across the 100 FGT indicators obtained for the area.</p>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span>	<span class="c1">//Indicate poverty line</span>
<span class="k">	gen</span> povline = <span class="m">12</span>
	<span class="c1">//Obtain FGTs for each area under every simulated vector</span>
	sp_groupfunction, poverty(Y_<span class="o">*</span>) povertyline(povline)<span class="k"> by</span>(area)	
	<span class="c1">//Average over simulations to obtain the EB estimate</span>
	groupfunction,<span class="k"> mean</span>(value)<span class="k"> by</span>(measure area)
	<span class="c1">//Reshape to obtain wide data at the area level</span>
<span class="k">	qui</span>:reshape wide value, i(area) j(measure) string
<span class="c1">//Save CensusEB	</span>
<span class="k">save</span> <span class="s">&quot;</span><span class="vg">$mdata</span><span class="s">\CensusEBfgt.dta&quot;</span>,<span class="k"> replace</span>
</pre></div>
</div>
<p>Note that this is quite different from the method used for ELL, as implemented in <code class="docutils literal notranslate"><span class="pre">PovMap</span></code> and the Stata <code class="docutils literal notranslate"><span class="pre">sae</span></code> package.<a class="footnote-reference brackets" href="#id302" id="id139">32</a> The steps detailed above are aligned to those applied by the command <code class="docutils literal notranslate"><span class="pre">sae</span> <span class="pre">sim</span> <span class="pre">reml</span> </code>to obtain CensusEB estimates and are very similar to the approach under <code class="docutils literal notranslate"><span class="pre">sae</span> <span class="pre">sim</span> <span class="pre">h3</span></code>.</p>
</section>
<section id="parametric-bootstrap">
<span id="unit-level-annex-montecarlo-bootstrap"></span><h4><span class="section-number">4.4.2.2. </span>Parametric Bootstrap<a class="headerlink" href="#parametric-bootstrap" title="Permalink to this headline">#</a></h4>
<p>The parametric bootstrap used to estimate the MSE of the EB estimates was introduced by <span id="id140">González-Manteiga <em>et al.</em> [<a class="reference internal" href="05_off-census.html#id116" title="Wenceslao González-Manteiga, Maria J Lombardía, Isabel Molina, Domingo Morales, and Laureano Santamaría. Bootstrap mean squared error of a small-area EBLUP. Journal of Statistical Computation and Simulation, 78(5):443–462, 2008.">2008</a>]</span>. It is the approach used by <span id="id141">Molina and Rao [<a class="reference internal" href="06_diagnostics.html#id67" title="Isabel Molina and JNK Rao. Small area estimation of poverty indicators. Canadian Journal of Statistics, 38(3):369–385, 2010.">2010</a>]</span> and the one used in the <code class="docutils literal notranslate"><span class="pre">sae</span></code> R package from <span id="id142">Molina and Marhuenda [<a class="reference internal" href="06_diagnostics.html#id68" title="Isabel Molina and Yolanda Marhuenda. Sae: an R package for small area estimation. The R Journal, 7(1):81–98, 2015.">2015</a>]</span>, as well as in the updated Stata <code class="docutils literal notranslate"><span class="pre">sae</span></code> package.<a class="footnote-reference brackets" href="#id304" id="id143">33</a> The procedure is computationally more demanding than the bootstrap procedure used in <code class="docutils literal notranslate"><span class="pre">PovMap</span> </code>which was inspired by the MI literature. However, the parametric bootstrap procedure from <span id="id144">González-Manteiga <em>et al.</em> [<a class="reference internal" href="05_off-census.html#id116" title="Wenceslao González-Manteiga, Maria J Lombardía, Isabel Molina, Domingo Morales, and Laureano Santamaría. Bootstrap mean squared error of a small-area EBLUP. Journal of Statistical Computation and Simulation, 78(5):443–462, 2008.">2008</a>]</span> tracks the real MSE values.</p>
<p>The process consists in, first, creating a population vector of welfare (i.e. census) using <span class="math notranslate nohighlight">\(\hat{\theta}_{0}=\left(\hat{\beta_{0}},\:\hat{\sigma}_{\eta0}^{2},\:\hat{\sigma}_{e0}^{2}\right)\)</span>. Note that <span class="math notranslate nohighlight">\(\hat{\theta}_{0}=\left(\hat{\beta_{0}},\:\hat{\sigma}_{\eta0}^{2},\:\hat{\sigma}_{e0}^{2}\right)\)</span> are obtained from the original sample and match those from the ones used in the previous step for computing CensusEB point estimates.</p>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span><span class="c1">//Macros used below</span>
<span class="k">global</span> povline = <span class="m">12</span><span class="k"></span>
<span class="k">global bs</span> = <span class="m">1</span> <span class="c1">//Bootstrap replicates</span>


<span class="c1">//Gonzales-Manteiga et al. (2008) Bootstrap for estimating MSE</span>
<span class="k">use</span> <span class="s">&quot;</span><span class="vg">$mdata</span><span class="s">\sample.dta&quot;</span>,<span class="k"> clear</span>

	<span class="c1">//fit model on the sample</span>
	mixed Y_B x1 x2 || area:, reml
	
	<span class="c1">//Obtain the necessary parameters</span>
<span class="k">		local</span> sigma_eta2 =  (<span class="nf">exp</span>([lns1_1_1]_cons))<span class="o">^</span><span class="m">2</span>
<span class="k">		local</span> sigma_e2   =  (<span class="nf">exp</span>([lnsig_e]_cons))<span class="o">^</span><span class="m">2</span>
	<span class="c1">//Let&#39;s calculate the linear fit</span>
<span class="k">	predict</span> xb, xb
<span class="k">	dis</span> <span class="nf">sqrt</span>(<span class="nv">`sigma_eta2&#39;</span>)
<span class="k">	dis</span> <span class="nf">sqrt</span>(<span class="nv">`sigma_e2&#39;</span>)
<span class="k">	</span>
<span class="k">tempfile sample</span>
<span class="k">save</span> <span class="nv">`sample&#39;</span>
</pre></div>
</div>
<p>Using <span class="math notranslate nohighlight">\(\hat{\theta}_{0}=\left(\hat{\beta_{0}},\:\hat{\sigma}_{\eta0}^{2},\:\hat{\sigma}_{e0}^{2}\right)\)</span> as the vector of true values, <span class="math notranslate nohighlight">\(B\)</span> population vectors of welfare are created following the DGP from <strong>Equation <a class="reference internal" href="#equation-eq-1-1">(4.2)</a></strong>. Each area’s desired set of indicators is obtained from each population vector. These indicators are regarded as the true values in each bootstrap replicate and the benchmark to which CensusEB estimates for that generated population will be compared to. The estimate of the MSE is the mean across the <span class="math notranslate nohighlight">\(B\)</span> replicates of the squared differences between the bootstrap replicate’s estimate and the bootstrap replicate’s “true” value. In the code below, the steps for the first bootstrap replicate, <span class="math notranslate nohighlight">\(b=1,\)</span> in this parametric bootstrap procedure are shown.</p>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span><span class="c1">//We import the population/census data to a mata file for obtaining CensusEB </span>
<span class="c1">//estimates for each bootstrap replicate with sae command</span>
<span class="k">preserve</span>
	sae data import, datain(<span class="s">&quot;</span><span class="vg">$mdata</span><span class="s">\thepopulation.dta&quot;</span>) <span class="cs">///</span>
<span class="k">	varlist</span>(x1 x2 hhsize) area(area) uniqid(hhid) <span class="cs">///</span>
	dataout(<span class="s">&quot;</span><span class="vg">$mdata</span><span class="s">\mypop_mata&quot;</span>)<span class="k"></span>
<span class="k">restore</span> 
</pre></div>
</div>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span><span class="c1">//Set seed for replicability</span>
<span class="k">set</span> seed <span class="m">9374</span>

<span class="k">local bs</span>=<span class="m">1</span>	
	<span class="c1">//Now we generate the eta vector of our population </span>
<span class="k">	clear</span>
<span class="k">	set</span> obs <span class="m">80</span> <span class="c1">//80 areas</span>
<span class="k">		gen</span> area = _n
<span class="k">		gen</span> eta_1 = <span class="nf">rnormal</span>(<span class="m">0</span>,<span class="nf">sqrt</span>(<span class="nv">`sigma_eta2&#39;</span>))
<span class="k">	tempfile</span> etas
<span class="k">	save</span> <span class="nv">`etas&#39;</span>
	
	<span class="c1">//Bring in the entire population (i.e. census)</span>
<span class="k">	use</span> x1 x2 area hhid hhsize using <span class="s">&quot;</span><span class="vg">$mdata</span><span class="s">\thepopulation.dta&quot;</span>,<span class="k"> clear</span>
		<span class="c1">//obtain linear fit - e(b) is still in memory</span>
<span class="k">		predict</span> xb, xb
		<span class="c1">//Include the etas</span>
<span class="k">		merge m</span>:<span class="m">1</span> area using <span class="nv">`etas&#39;</span>
<span class="k">			drop</span> _m
		
		<span class="c1">//generate welfare vector, by adding linear fit and location effect</span>
		<span class="c1">// and adding the idiosyncratic errors</span>
		<span class="c1">//Take the exponential to obtain welfare</span>
<span class="k">		gen</span> double Y_1 = <span class="nf">exp</span>(<span class="nf">rnormal</span>(xb <span class="o">+</span> eta_1,<span class="nf">sqrt</span>(<span class="nv">`sigma_e2&#39;</span>)))		
		
		<span class="c1">//From this simulated population, which follows exactly the model&#39;s </span>
		<span class="c1">// assumptions the true poverty rate for the population is obtained</span>
<span class="k">		gen</span> povline = <span class="vg">$povline</span>
		<span class="c1">//Obtain FGTs for each area under every simulated vector</span>
		<span class="c1">// This yields 200 FGTs per area</span>
		sp_groupfunction, poverty(Y_1) povertyline(povline)<span class="k"> by</span>(area)
<span class="k">		qui</span>:reshape wide value, i(area) j(measure) string
<span class="k">	tempfile</span> true
<span class="k">	save</span> <span class="nv">`true&#39;</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The part above was ommited in guidelines*</p>
</div>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span><span class="c1">*===============================================================================</span>
<span class="c1">//The second stage consists in &quot;extracting the sample&quot; and obtaining estimates </span>
<span class="c1">// via MonteCarlo simulation. For each bootstrap replicate...this is b=1</span>
<span class="c1">*===============================================================================</span>
<span class="k">	use</span> x1 x2 xb hhid area using <span class="nv">`sample&#39;</span>,<span class="k"> clear</span>
		<span class="c1">//Include the etas</span>
		<span class="c1">//note that these are the same used in the population</span>
<span class="k">		merge m</span>:<span class="m">1</span> area using <span class="nv">`etas&#39;</span> 
<span class="k">			drop</span> _m	
<span class="k">		sort</span> hhid
		<span class="c1">//Generate the welfare vector, in exactly the same manner as in the </span>
		<span class="c1">//population</span>
<span class="k">		gen</span> lny = <span class="nf">rnormal</span>(xb <span class="o">+</span> eta_1,<span class="nf">sqrt</span>(<span class="nv">`sigma_e2&#39;</span>))
<span class="k">	</span>
<span class="k">	local</span> seedstage  <span class="nv">`c(rngstate)&#39;</span>
		
	<span class="c1">// Now with the new welfare vector we can obtain CensusEB estimates </span>
	<span class="c1">//for the bootstrap replicate using sae</span>
	sae sim reml lny x1 x2,  area(area)  mcrep(<span class="m">50</span>) bsrep(<span class="m">0</span>) lny <span class="cs">///</span>
	seed(<span class="nv">`seedstage&#39;</span>) pwcensus(hhsize) indicators(FGT0 FGT1 FGT2) <span class="cs">///</span>
	aggids(<span class="m">0</span>) uniq(hhid) plines(<span class="vg">$povline</span>) matin(<span class="s">&quot;</span><span class="vg">$mdata</span><span class="s">\mypop_mata&quot;</span>)
	
	<span class="c1">//MSE is calculated as squared difference between the true and CensusEB.</span>
	<span class="c1">//Bring in the true poverty for this bootstrap replicate</span>
<span class="k">	rename</span> Unit area
<span class="k">	merge</span> <span class="m">1</span>:<span class="m">1</span> area using <span class="nv">`true&#39;</span>
<span class="k">		drop</span> _m
	<span class="c1">//Get squared difference, after B bootstrap replicates the sum of these</span>
	<span class="c1">// squared differences is our MSE estimate</span>
<span class="k">	forval</span> a = <span class="m">0</span><span class="o">/</span><span class="m">2</span>{
<span class="k">	    gen</span> sq_diff_fgt<span class="nv">`a&#39;</span> = ((avg_fgt<span class="nv">`a&#39;</span> <span class="o">-</span> valuefgt<span class="nv">`a&#39;</span>)<span class="o">^</span><span class="m">2</span>)<span class="o">/</span><span class="vg">$bs</span>
	}
</pre></div>
</div>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span><span class="cm">/*	</span>
<span class="cm">	keep area sq_diff_fgt*</span>
<span class="cm">	</span>
<span class="cm">	if (`bs&#39;==1){</span>
<span class="cm">		rename  sq_diff_fgt* MSE_fgt*	</span>
<span class="cm">		tempfile mse</span>
<span class="cm">		save `mse&#39;</span>
<span class="cm">	}</span>
<span class="cm">	else{</span>
<span class="cm">	    merge 1:1 area using `mse&#39;</span>
<span class="cm">			drop _m</span>
<span class="cm">		forval a = 0/2{</span>
<span class="cm">			replace MSE_fgt`a&#39; = MSE_fgt`a&#39; + sq_diff_fgt`a&#39;</span>
<span class="cm">		}</span>
<span class="cm">		tempfile mse</span>
<span class="cm">		save `mse&#39;		</span>
<span class="cm">	}</span>

<span class="cm">use `mse&#39;, clear</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The second part above was ommited in guidelines*</p>
</div>
</section>
</section>
</section>
<section id="appendix">
<span id="unit-level-appendix"></span><h2><span class="section-number">4.5. </span>Appendix<a class="headerlink" href="#appendix" title="Permalink to this headline">#</a></h2>
<section id="model-selection-do-file">
<span id="unit-level-appendix-selection"></span><h3><span class="section-number">4.5.1. </span>Model Selection Do-File<a class="headerlink" href="#model-selection-do-file" title="Permalink to this headline">#</a></h3>
<p>This do-file provides an example of the steps that may be followed to select a model for SAE, according to the discussion from <strong><a class="reference internal" href="#unit-level-first-sae"><span class="std std-numref">Section 4.2</span></a></strong>. The steps for model checking follow those illustrated by UCLA’s Statistical Consulting Group (<span id="id145"></span>).</p>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span><span class="k">clear</span> all <span class="k"></span>
<span class="k">set more</span> off

<span class="cm">/*===============================================================================</span>
<span class="cm">Do-file prepared for SAE Guidelines</span>
<span class="cm">- Real world data application</span>
<span class="cm">- authors Paul Corral &amp; Minh Nguyen</span>
<span class="cm">*==============================================================================*/</span>

<span class="k">global</span> main     <span class="s">&quot;C:\Users</span><span class="se">\\</span><span class="nv">`c(username)&#39;</span><span class="s">\OneDrive\SAE Guidelines 2021</span><span class="se">\&quot;</span><span class="k"></span>
<span class="k">global</span> section  <span class="s">&quot;</span><span class="vg">$main</span><span class="s">\3_Unit_level</span><span class="se">\&quot;</span><span class="k"></span>
<span class="k">global</span> mdata    <span class="s">&quot;</span><span class="vg">$section</span><span class="s">\1_data</span><span class="se">\&quot;</span><span class="k"></span>
<span class="k">global</span> survey <span class="s">&quot;</span><span class="vg">$mdata</span><span class="s">\survey_public.dta&quot;</span><span class="k"></span>
<span class="k">global</span> census <span class="s">&quot;</span><span class="vg">$mdata</span><span class="s">\census_public.dta&quot;</span>

<span class="c1">//global with candidate variables.</span>
<span class="k">global</span> myvar rural  lnhhsize age_hh male_hh  piped_water no_piped_water <span class="cs">///</span>
no_sewage sewage_pub sewage_priv electricity telephone cellphone internet <span class="cs">///</span>
computer washmachine fridge television share_under15 share_elderly <span class="cs">///</span>
share_adult max_tertiary max_secondary HID_<span class="o">*</span> mun_<span class="o">*</span> state_<span class="o">*</span>


<span class="k">version</span> <span class="m">15</span><span class="k"></span>
<span class="k">set</span> seed <span class="m">648743</span>

<span class="c1">*===============================================================================</span>
<span class="c1">// End of preamble</span>
<span class="c1">*===============================================================================</span>
<span class="c1">//load in survey data</span>
<span class="k">use</span> <span class="s">&quot;</span><span class="vg">$survey</span><span class="s">&quot;</span>,<span class="k"> clear</span>
	<span class="c1">//Remove small incomes affecting model</span>
<span class="k">	drop if</span> e_y<span class="o">&lt;</span><span class="m">1</span>
	<span class="c1">//Log shift transformation to approximate normality</span>
<span class="k">	lnskew0</span> double bcy = <span class="nf">exp</span>(lny)
	<span class="c1">//removes skeweness from distribution</span>
<span class="k">	sum</span> lny,<span class="k"> d</span> 
<span class="k">	sum</span> bcy,<span class="k"> d</span>
	
	<span class="c1">//Data has already been cleaned and prepared. Data preparation and the creation</span>
	<span class="c1">// of eligible covariates is of extreme importance. </span>
	<span class="c1">// In this instance, we skip these comparison steps because the sample is </span>
	<span class="c1">// literally a subsample of the census.</span>
<span class="k">	codebook</span> HID <span class="c1">//10 digits, every single one</span>
<span class="k">	codebook</span> HID_mun <span class="c1">//7 digits every single one</span>
	
	<span class="c1">//We rename HID_mun</span>
<span class="k">	rename</span> HID_mun MUN
	<span class="c1">//Drop automobile, it is missing</span>
<span class="k">	drop</span> <span class="o">*</span>automobile<span class="o">*</span> <span class="c1">//all these are missing</span>
	
	<span class="c1">//Check to see if lassoregress is installed, if not install</span>
<span class="k">	cap which</span> lassoregress
<span class="k">	if</span> (_rc)<span class="k"> ssc</span> install elasticregress
	
	<span class="c1">//Model selection - with Lasso	</span>
<span class="k">	gen</span> lnhhsize = <span class="nf">ln</span>(hhsize)
	lassoregress bcy  <span class="vg">$myvar</span> [aw=Whh], lambda1se epsilon(<span class="m">1e-10</span>) numfolds(<span class="m">10</span>)
<span class="k">	local</span> hhvars =<span class="k"> e</span>(varlist_nonzero)
<span class="k">	global</span> postlasso  <span class="nv">`hhvars&#39;</span>
	
	<span class="c1">//Try Henderson III GLS</span>
	sae model h3 bcy <span class="vg">$postlasso</span> [aw=Whh], area(MUN) 
	
	<span class="c1">//Rename HID_mun</span>
<span class="k">	rename</span> MUN HID_mun
	
	<span class="c1">//Loop designed to remove non-significant covariates sequentially</span>
<span class="k">	forval</span> z= <span class="m">0.5</span>(<span class="o">-</span><span class="m">0.05</span>)<span class="m">0.05</span>{
<span class="k">		qui</span>:sae model h3 bcy <span class="nv">`hhvars&#39;</span> [aw=Whh], area(HID_mun) 
<span class="k">		mata</span>: bb=st_matrix(<span class="s">&quot;e(b_gls)&quot;</span>)
<span class="k">		mata</span>:<span class="k"> se</span>=<span class="nf">sqrt</span>(diagonal(st_matrix(<span class="s">&quot;e(V_gls)&quot;</span>)))
<span class="k">		mata</span>: zvals = bb&#39;:<span class="o">/</span>se
<span class="k">		mata</span>: st_matrix(<span class="s">&quot;min&quot;</span>,<span class="nf">min</span>(<span class="nf">abs</span>(zvals)))
<span class="k">		local</span> zv = (<span class="o">-</span>min[<span class="m">1</span>,<span class="m">1</span>])
<span class="k">		if</span> (<span class="m">2</span><span class="o">*</span><span class="nf">normal</span>(<span class="nv">`zv&#39;</span>)<span class="o">&lt;</span><span class="nv">`z&#39;</span>)<span class="k"> exit</span>
<span class="k">	</span>
<span class="k">		foreach</span> x of<span class="k"> varlist</span> <span class="nv">`hhvars&#39;</span>{
<span class="k">			local</span> hhvars1
<span class="k">			qui</span>: sae model h3 bcy <span class="nv">`hhvars&#39;</span> [aw=Whh], area(HID_mun)
<span class="k">			qui</span>:<span class="k"> test</span> <span class="nv">`x&#39;</span> 
<span class="k">			if</span> (<span class="nf">r</span>(p)<span class="o">&gt;</span><span class="nv">`z&#39;</span>){
<span class="k">				local</span> hhvars1
<span class="k">				foreach</span> yy of<span class="k"> local</span> hhvars{
<span class="k">					if</span> (<span class="s">&quot;</span><span class="nv">`yy&#39;</span><span class="s">&quot;</span><span class="o">==</span><span class="s">&quot;</span><span class="nv">`x&#39;</span><span class="s">&quot;</span>)<span class="k"> dis</span> <span class="s">&quot;&quot;</span>
<span class="k">					else local</span> hhvars1 <span class="nv">`hhvars1&#39;</span> <span class="nv">`yy&#39;</span>
				}
			}
<span class="k">			else local</span> hhvars1 <span class="nv">`hhvars&#39;</span>
<span class="k">			local</span> hhvars <span class="nv">`hhvars1&#39;</span>		
		}
	}	
<span class="k">	</span>
<span class="k">	global</span> postsign <span class="nv">`hhvars&#39;</span>
	
	<span class="c1">//Henderson III GLS - model post removal of non-significant</span>
	sae model h3 bcy <span class="vg">$postsign</span> [aw=Whh], area(HID_mun) 
	
	<span class="c1">//Check for multicollinearity, and remove highly collinear (VIF&gt;3)</span>
<span class="k">	reg</span> bcy <span class="vg">$postsign</span> [aw=Whh],r
<span class="k">	cap drop</span> touse 	<span class="c1">//remove vector if it is present to avoid error in next step</span>
<span class="k">	gen</span> touse =<span class="k"> e</span>(sample) 		<span class="c1">//Indicates the observations used</span>
<span class="k">	vif</span> 						<span class="c1">//Variance inflation factor</span>
<span class="k">	local</span> hhvars <span class="vg">$postsign</span>
	<span class="c1">//Remove covariates with VIF greater than 3</span>
<span class="k">	mata</span>:<span class="k"> ds</span> = _f_stepvif(<span class="s">&quot;</span><span class="nv">`hhvars&#39;</span><span class="s">&quot;</span>,<span class="s">&quot;Whh&quot;</span>,<span class="m">3</span>,<span class="s">&quot;touse&quot;</span>) 
<span class="k">	global</span> postvif <span class="nv">`vifvar&#39;</span>
	
	<span class="c1">//VIF check</span>
<span class="k">	reg</span> bcy <span class="vg">$postvif</span> [aw=Whh], r
<span class="k">	vif</span>
	
	<span class="c1">//Henderson III GLS - model post removal of non-significant</span>
	sae model h3 bcy <span class="vg">$postvif</span> [aw=Whh], area(HID_mun) 
<span class="c1">	</span>
<span class="c1">*===============================================================================</span>
<span class="c1">// 2.5 Model checks</span>
<span class="c1">*===============================================================================</span>

<span class="k">	reg</span> bcy <span class="vg">$postvif</span>	
<span class="k">	predict</span> cdist, cooksd
<span class="k">	predict</span> rstud, rstudent
<span class="k">	</span>
<span class="k">	reg</span> bcy <span class="vg">$postvif</span> [aw=Whh]
<span class="k">	local</span> KK =<span class="k"> e</span>(df_m)
<span class="k">	predict</span> lev,<span class="k"> leverage</span>
<span class="k">	predict</span> eps, resid
<span class="k">	predict</span> bc_yhat, xb
	
	<span class="c1">//Let&#39;s take a look at our residuals</span>
	<span class="c1">//Notice there is a downward sloping line,which seems to be the smallest eps for that xb</span>
<span class="k">	scatter</span> eps bc_yhat
	<span class="c1">//so we can see what the figure looks like</span>
<span class="k">	sleep</span> <span class="m">15000</span>
	<span class="c1">// so there&#39;s a bunch of small incomes that may be affecting our model!</span>
<span class="k">	scatter</span> eps bc_yhat<span class="k"> if</span> <span class="nf">exp</span>(lny)<span class="o">&gt;</span><span class="m">1</span> 	

<span class="cm">/* https://stats.idre.ucla.edu/stata/dae/robust-regression/</span>
<span class="cm">Residual:  The difference between the predicted value (based on the regression ///</span>
<span class="cm">equation) and the actual, observed value.</span>

<span class="cm">Outlier:  In linear regression, an outlier is an observation with large ///</span>
<span class="cm">residual.  In other words, it is an observation whose dependent-variable ///</span>
<span class="cm">value is unusual given its value on the predictor variables.  An outlier may ///</span>
<span class="cm">indicate a sample peculiarity or may indicate a data entry error or ///</span>
<span class="cm">other problem.</span>
<span class="cm">	</span>
<span class="cm">Leverage:  An observation with an extreme value on a predictor variable is a ///</span>
<span class="cm">point with high leverage.  Leverage is a measure of how far an independent ///</span>
<span class="cm">variable deviates from its mean.  High leverage points can have a great ///</span>
<span class="cm">amount of effect on the estimate of regression coefficients.</span>
<span class="cm">	</span>
<span class="cm">Influence:  An observation is said to be influential if removing the ///</span>
<span class="cm">substantially changes the estimate of the regression coefficients.  ///</span>
<span class="cm">Influence can be thought of as the product of leverage and outlierness. </span>
<span class="cm">	</span>
<span class="cm">Cook’s distance (or Cook’s D): A measure that combines the information of ///</span>
<span class="cm">leverage and residual of the observation</span>
<span class="cm">*/</span>
	
<span class="cm">/* Rules of thumb:</span>
<span class="cm">Cooks -&gt; &gt;4/N, also according to &quot;Regression Diagnostics: An Expository ///</span>
<span class="cm">Treatment of Outliers and Influential Cases, values over 1...</span>
<span class="cm">	</span>
<span class="cm">Abs(rstu) -&gt; &gt;2 We should pay attention to studentized residuals that exceed ///</span>
<span class="cm">+2 or -2, and get even more concerned about residuals that exceed +2.5 or ///</span>
<span class="cm">-2.5 and even yet more concerned about residuals that exceed +3 or -3.  ///</span>

<span class="cm">leverage -&gt;	&gt;(2k+2)/n	</span>
<span class="cm">*/</span>
<span class="k">	hist</span> cdist, name(diag_cooksd,<span class="k"> replace</span>)
<span class="k">	hist</span> lev, name(diag_leverage,<span class="k"> replace</span>)
<span class="k">	hist</span> rstud, name(diag_rstudent,<span class="k"> replace</span>)
<span class="k">	twoway scatter</span> cdist lev, name(diag_cooksd_lev,<span class="k"> replace</span>)
<span class="k">	</span>
<span class="k">	lvr2plot</span>, name(lvr2)
<span class="k">	rvfplot</span>, name(rvf)
<span class="k">	</span>
<span class="k">	sum</span> cdist,<span class="k"> d</span>
<span class="k">	local</span> max = <span class="nf">r</span>(max)
<span class="k">	local</span> p99 = <span class="nf">r</span>(p99)		
<span class="k">	</span>
<span class="k">	reg</span> lny <span class="vg">$postvif</span> [aw=Whh]
<span class="k">	local</span> myN=<span class="nf">e</span>(N)
<span class="k">	local</span> myK=<span class="nf">e</span>(rank)
	
	<span class="c1">//We have influential data points...</span>
<span class="k">	reg</span> lny <span class="vg">$postvif</span><span class="k"> if</span> cdist<span class="o">&lt;</span><span class="m">4</span><span class="o">/</span><span class="nv">`myN&#39;</span> [aw=Whh]
<span class="k">	reg</span> lny <span class="vg">$postvif</span><span class="k"> if</span> cdist<span class="o">&lt;</span><span class="nv">`max&#39;</span>   [aw=Whh]
<span class="k">	reg</span> lny <span class="vg">$postvif</span><span class="k"> if</span> cdist<span class="o">&lt;</span><span class="nv">`p99&#39;</span>   [aw=Whh]
<span class="k">	gen</span> nogo = <span class="nf">abs</span>(rstud)<span class="o">&gt;</span><span class="m">2</span> <span class="o">&amp;</span> cdist<span class="o">&gt;</span><span class="m">4</span><span class="o">/</span><span class="nv">`myN&#39;</span> <span class="o">&amp;</span> lev<span class="o">&gt;</span>(<span class="m">2</span><span class="o">*</span><span class="nv">`myK&#39;</span><span class="o">+</span><span class="m">2</span>)<span class="o">/</span><span class="nv">`myN&#39;</span>
<span class="c1">	</span>

<span class="c1">*===============================================================================</span>
<span class="c1">// Selecting the Alpha model</span>
<span class="c1">*===============================================================================	</span>
	<span class="c1">//Rename HID_mun</span>
<span class="k">	cap rename</span> HID_mun MUN
	<span class="c1">//Henderson III GLS - add alfa model</span>
	sae model h3 bcy <span class="vg">$postvif</span><span class="k"> if</span> nogo<span class="o">==</span><span class="m">0</span> [aw=Whh], area(MUN) <span class="cs">///</span>
	alfatest(residual) zvar(hhsize)
<span class="k">	</span>
<span class="k">	des</span> residual_alfa <span class="c1">//The dependent variable for the alfa model</span>
	
	<span class="c1">// Macro holding all eligible vars</span>
<span class="k">	unab</span> allvars : <span class="vg">$myvar</span>
	<span class="c1">//Macro with current variables</span>
<span class="k">	local</span> nogo <span class="vg">$postvif</span>
	
	<span class="c1">//We want to only use variables not used</span>
<span class="k">	foreach</span> x of<span class="k"> local</span> allvars{
<span class="k">		local in</span> = <span class="m">0</span>
<span class="k">		foreach</span> y of<span class="k"> local</span> nogo{
<span class="k">			if</span> (<span class="s">&quot;</span><span class="nv">`x&#39;</span><span class="s">&quot;</span><span class="o">==</span><span class="s">&quot;</span><span class="nv">`y&#39;</span><span class="s">&quot;</span>)<span class="k">	local in</span>=<span class="m">1</span>
		}
<span class="k">		if</span> (<span class="nv">`in&#39;</span><span class="o">==</span><span class="m">0</span>)<span class="k"> local</span> A <span class="nv">`A&#39;</span> <span class="nv">`x&#39;</span>
	}	
<span class="k">	</span>
<span class="k">	global</span> A <span class="nv">`A&#39;</span> <span class="c1">//macro holding eligible variables for alpha model</span>
	
	lassoregress residual_alfa <span class="nv">`A&#39;</span><span class="k"> if</span> nogo<span class="o">==</span><span class="m">0</span> [aw=Whh]
<span class="k">	</span>
<span class="k">	local</span> alfa =<span class="k"> e</span>(varlist_nonzero)
<span class="k">	global</span> alfa <span class="nv">`alfa&#39;</span>
<span class="k">	</span>
<span class="k">	reg</span> residual_alfa <span class="vg">$alfa</span><span class="k"> if</span> nogo<span class="o">==</span><span class="m">0</span> [aw=Whh],r
<span class="k">	gen</span> tousealfa =<span class="k"> e</span>(sample)
	
	<span class="c1">//Remove vif vars</span>
<span class="k">	mata</span>:<span class="k"> ds</span> = _f_stepvif(<span class="s">&quot;</span><span class="vg">$alfa</span><span class="s">&quot;</span>,<span class="s">&quot;Whh&quot;</span>,<span class="m">5</span>,<span class="s">&quot;tousealfa&quot;</span>)
<span class="k">	</span>
<span class="k">	global</span> alfa <span class="nv">`vifvar&#39;</span>
	
	<span class="c1">//Alfa vars before removal of non-significant vars</span>
<span class="k">	global</span> beforealfa <span class="nv">`alfa&#39;</span>
<span class="k">	</span>
<span class="k">	local</span> hhvars <span class="vg">$alfa</span>
<span class="k">	</span>
<span class="k">	forval</span> z= <span class="m">0.9</span>(<span class="o">-</span><span class="m">0.1</span>)<span class="m">0.1</span>{
<span class="k">		foreach</span> x of<span class="k"> varlist</span> <span class="nv">`hhvars&#39;</span>{
<span class="k">			local</span> hhvars1
<span class="k">			qui</span>:<span class="k"> reg</span> residual_alfa <span class="nv">`hhvars&#39;</span> [aw=Whh], r
<span class="k">			qui</span>:<span class="k"> test</span> <span class="nv">`x&#39;</span> 
<span class="k">			if</span> (<span class="nf">r</span>(p)<span class="o">&gt;</span><span class="nv">`z&#39;</span>){
<span class="k">				local</span> hhvars1
<span class="k">				foreach</span> yy of<span class="k"> local</span> hhvars{
<span class="k">					if</span> (<span class="s">&quot;</span><span class="nv">`yy&#39;</span><span class="s">&quot;</span><span class="o">==</span><span class="s">&quot;</span><span class="nv">`x&#39;</span><span class="s">&quot;</span>)<span class="k"> dis</span> <span class="s">&quot;&quot;</span>
<span class="k">					else local</span> hhvars1 <span class="nv">`hhvars1&#39;</span> <span class="nv">`yy&#39;</span>
				}
			}
<span class="k">			else local</span> hhvars1 <span class="nv">`hhvars&#39;</span>
<span class="k">			local</span> hhvars <span class="nv">`hhvars1&#39;</span>
		
		}
	}
<span class="k">	global</span> alfavars <span class="nv">`hhvars&#39;</span>
	
	<span class="c1">//Henderson III Model with alpha model</span>
	sae model h3 bcy <span class="vg">$postvif</span><span class="k"> if</span> nogo<span class="o">==</span><span class="m">0</span> [aw=Whh], area(MUN) zvar(<span class="vg">$alfavars</span>)
<span class="c1">	</span>
<span class="c1">*===============================================================================</span>
<span class="c1">// GLS model, one final removal of non-significant variables</span>
<span class="c1">*===============================================================================</span>
	<span class="c1">//Loop designed to remove non-significant covariates sequentially</span>
<span class="k">	local</span> hhvars <span class="vg">$postvif</span>
<span class="k">	forval</span> z= <span class="m">0.5</span>(<span class="o">-</span><span class="m">0.05</span>)<span class="m">0.05</span>{
<span class="k">		qui</span>:sae model h3 bcy <span class="nv">`hhvars&#39;</span><span class="k"> if</span> nogo<span class="o">==</span><span class="m">0</span> [aw=Whh], area(MUN) <span class="cs">///</span>
		zvar(<span class="vg">$alfavars</span>)
<span class="k">		mata</span>: bb=st_matrix(<span class="s">&quot;e(b_gls)&quot;</span>)
<span class="k">		mata</span>:<span class="k"> se</span>=<span class="nf">sqrt</span>(diagonal(st_matrix(<span class="s">&quot;e(V_gls)&quot;</span>)))
<span class="k">		mata</span>: zvals = bb&#39;:<span class="o">/</span>se
<span class="k">		mata</span>: st_matrix(<span class="s">&quot;min&quot;</span>,<span class="nf">min</span>(<span class="nf">abs</span>(zvals)))
<span class="k">		local</span> zv = (<span class="o">-</span>min[<span class="m">1</span>,<span class="m">1</span>])
<span class="k">		if</span> (<span class="m">2</span><span class="o">*</span><span class="nf">normal</span>(<span class="nv">`zv&#39;</span>)<span class="o">&lt;</span><span class="nv">`z&#39;</span>)<span class="k"> exit</span>
<span class="k">	</span>
<span class="k">		foreach</span> x of<span class="k"> varlist</span> <span class="nv">`hhvars&#39;</span>{
<span class="k">			local</span> hhvars1
<span class="k">			qui</span>:sae model h3 bcy <span class="nv">`hhvars&#39;</span><span class="k"> if</span> nogo<span class="o">==</span><span class="m">0</span> [aw=Whh], area(MUN) <span class="cs">///</span>
			zvar(<span class="vg">$alfavars</span>)
<span class="k">			qui</span>:<span class="k"> test</span> <span class="nv">`x&#39;</span> 
<span class="k">			if</span> (<span class="nf">r</span>(p)<span class="o">&gt;</span><span class="nv">`z&#39;</span>){
<span class="k">				local</span> hhvars1
<span class="k">				foreach</span> yy of<span class="k"> local</span> hhvars{
<span class="k">					if</span> (<span class="s">&quot;</span><span class="nv">`yy&#39;</span><span class="s">&quot;</span><span class="o">==</span><span class="s">&quot;</span><span class="nv">`x&#39;</span><span class="s">&quot;</span>)<span class="k"> dis</span> <span class="s">&quot;&quot;</span>
<span class="k">					else local</span> hhvars1 <span class="nv">`hhvars1&#39;</span> <span class="nv">`yy&#39;</span>
				}
			}
<span class="k">			else local</span> hhvars1 <span class="nv">`hhvars&#39;</span>
<span class="k">			local</span> hhvars <span class="nv">`hhvars1&#39;</span>		
		}
	}	
<span class="k">	</span>
<span class="k">	global</span> postalfa <span class="nv">`hhvars&#39;</span>
<span class="c1">	</span>
<span class="c1">*===============================================================================</span>
<span class="c1">// SAVE the data with the pertinent covariates and other info	</span>
<span class="c1">*===============================================================================</span>
sae model h3 bcy <span class="vg">$postalfa</span><span class="k"> if</span> nogo<span class="o">==</span><span class="m">0</span> [aw=Whh], area(MUN) zvar(<span class="vg">$alfavars</span>)

<span class="k">char</span> _dta[rhs]   <span class="vg">$postalfa</span><span class="k"></span>
<span class="k">char</span> _dta[alpha] <span class="vg">$alfavars</span><span class="k"></span>
<span class="k">char</span> _dta[sel]   nogo

<span class="k">save</span> <span class="s">&quot;</span><span class="vg">$mdata</span><span class="s">\mysvy.dta&quot;</span>,<span class="k"> replace</span>
</pre></div>
</div>
</section>
<section id="sae-simulation-stage">
<span id="unit-level-appendix-simulation"></span><h3><span class="section-number">4.5.2. </span>SAE Simulation Stage<a class="headerlink" href="#sae-simulation-stage" title="Permalink to this headline">#</a></h3>
<p>This do-file provides an example of the steps commonly followed to produce the final CensusEB small area estimates. It follows the discussion from <strong><a class="reference internal" href="#unit-level-first-sae-estimates"><span class="std std-numref">Section 4.2.4</span></a></strong>.</p>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span><span class="k">clear</span> all <span class="k"></span>
<span class="k">set more</span> off

<span class="cm">/*===============================================================================</span>
<span class="cm">Do-file prepared for SAE Guidelines</span>
<span class="cm">- Real world data application</span>
<span class="cm">- authors Paul Corral &amp; Minh Nguyen</span>
<span class="cm">*==============================================================================*/</span>

<span class="k">global</span> main     <span class="s">&quot;C:\Users</span><span class="se">\\</span><span class="nv">`c(username)&#39;</span><span class="s">\OneDrive\SAE Guidelines 2021</span><span class="se">\&quot;</span><span class="k"></span>
<span class="k">global</span> section  <span class="s">&quot;</span><span class="vg">$main</span><span class="s">\3_Unit_level</span><span class="se">\&quot;</span><span class="k"></span>
<span class="k">global</span> mdata    <span class="s">&quot;</span><span class="vg">$section</span><span class="s">\1_data</span><span class="se">\&quot;</span><span class="k"></span>
<span class="k">global</span> survey <span class="s">&quot;</span><span class="vg">$mdata</span><span class="s">\survey_public.dta&quot;</span><span class="k"></span>
<span class="k">global</span> census <span class="s">&quot;</span><span class="vg">$mdata</span><span class="s">\census_public.dta&quot;</span>

<span class="k">version</span> <span class="m">15</span><span class="k"></span>
<span class="k">local</span> seed <span class="m">648743</span>

<span class="c1">*===============================================================================</span>
<span class="c1">// End of preamble</span>
<span class="c1">*===============================================================================</span><span class="k"></span>
<span class="k">use</span> <span class="s">&quot;</span><span class="vg">$mdata</span><span class="s">\mysvy.dta&quot;</span>,<span class="k"> clear</span>
<span class="k">	char list</span>
<span class="k">	</span>
<span class="k">	global</span> hhmodel :<span class="k"> char</span> _dta[rhs]
<span class="k">	global alpha</span>   :<span class="k"> char</span> _dta[alpha]
<span class="k">	global</span> sel     :<span class="k"> char</span> _dta[sel]

<span class="c1">//Add lnhhsize</span>
<span class="k">use</span> <span class="s">&quot;</span><span class="vg">$census</span><span class="s">&quot;</span><span class="k"></span>
<span class="k">gen</span> lnhhsize = <span class="nf">ln</span>(hhsize)

<span class="k">tempfile</span> census1<span class="k"></span>
<span class="k">save</span> <span class="nv">`census1&#39;</span>

<span class="c1">// Create data ready for SAE - optimized dataset</span>
sae data import, datain(<span class="nv">`census1&#39;</span>)<span class="k"> varlist</span>(<span class="vg">$hhmodel</span> <span class="vg">$alpha</span> hhsize) <span class="cs">///</span>
area(HID_mun) uniqid(hhid) dataout(<span class="s">&quot;</span><span class="vg">$mdata</span><span class="s">\census_mata&quot;</span>)

<span class="c1">*===============================================================================</span>
<span class="c1">// Simulation -&gt; Obtain point estimates</span>
<span class="c1">*===============================================================================	</span><span class="k"></span>
<span class="k">use</span> <span class="s">&quot;</span><span class="vg">$mdata</span><span class="s">\mysvy.dta&quot;</span>,<span class="k"> clear</span>
<span class="k">	drop if</span> e_y<span class="o">&lt;</span><span class="m">1</span>
<span class="k">	drop if</span> <span class="vg">$sel</span><span class="o">==</span><span class="m">1</span>
<span class="k">	rename</span> MUN HID_mun
sae sim h3 e_y <span class="vg">$hhmodel</span>, area(HID_mun) zvar(<span class="vg">$alpha</span>) mcrep(<span class="m">100</span>) bsrep(<span class="m">0</span>) <span class="cs">///</span>
lnskew matin(<span class="s">&quot;</span><span class="vg">$mdata</span><span class="s">\census_mata&quot;</span>) seed(<span class="nv">`seed&#39;</span>) pwcensus(hhsize) <span class="cs">///</span>
indicators(fgt0 fgt1 fgt2) aggids(<span class="m">0</span> <span class="m">4</span>) uniqid(hhid) plines(<span class="m">715</span>)

<span class="c1">*===============================================================================</span>
<span class="c1">// Simulation -&gt; Obtain MSE estimates</span>
<span class="c1">*===============================================================================	</span>

<span class="k">use</span> <span class="s">&quot;</span><span class="vg">$mdata</span><span class="s">\mysvy.dta&quot;</span>,<span class="k"> clear</span>
<span class="k">	drop if</span> e_y<span class="o">&lt;</span><span class="m">1</span>
<span class="k">	drop if</span> <span class="vg">$sel</span><span class="o">==</span><span class="m">1</span>
<span class="k">	rename</span> MUN HID_mun
sae sim h3 e_y <span class="vg">$hhmodel</span>, area(HID_mun) zvar(<span class="vg">$alpha</span>) mcrep(<span class="m">100</span>) bsrep(<span class="m">0</span>) <span class="cs">///</span>
lnskew matin(<span class="s">&quot;</span><span class="vg">$mdata</span><span class="s">\census_mata&quot;</span>) seed(<span class="nv">`seed&#39;</span>) pwcensus(hhsize) <span class="cs">///</span>
indicators(fgt0 fgt1 fgt2) aggids(<span class="m">0</span> <span class="m">4</span>) uniqid(hhid) plines(<span class="m">715</span>)

<span class="k">save</span> <span class="s">&quot;</span><span class="vg">$mdata</span><span class="s">\mySAE.dta&quot;</span>,<span class="k"> replace</span> 
</pre></div>
</div>
</section>
</section>
<section id="references">
<span id="unit-level-ref"></span><h2><span class="section-number">4.6. </span>References<a class="headerlink" href="#references" title="Permalink to this headline">#</a></h2>
<div class="docutils container" id="id146">
<dl class="citation">
<dt class="label" id="id193"><span class="brackets"><a class="fn-backref" href="#id79">BDL+06</a></span></dt>
<dd><p>Abhijit V Banerjee, Angus Deaton, Nora Lustig, Kenneth Rogoff, and Edward Hsu. An evaluation of world bank research, 1998-2005. <em>Available at SSRN 2950327</em>, 2006.</p>
</dd>
<dt class="label" id="id190"><span class="brackets">BHF88</span><span class="fn-backref">(<a href="#id11">1</a>,<a href="#id117">2</a>)</span></dt>
<dd><p>George E. Battese, Rachel M. Harter, and Wayne A. Fuller. An error-components model for prediction of county crop areas using survey and satellite data. <em>Journal of the American Statistical Association</em>, 83(401):28–36, 1988. URL: <a class="reference external" href="http://www.jstor.org/stable/2288915">http://www.jstor.org/stable/2288915</a>.</p>
</dd>
<dt class="label" id="id248"><span class="brackets"><a class="fn-backref" href="#id111">Boo15</a></span></dt>
<dd><p>Harm Jan Boonstra. Package 'hbsae'. <em>R Package Version</em>, 2015.</p>
</dd>
<dt class="label" id="id186"><span class="brackets"><a class="fn-backref" href="#id64">BC64</a></span></dt>
<dd><p>GEP Box and DR Cox. An analysis of transformations. <em>Journal of the Royal Statistical Society, Series B</em>, 26:211–252, 1964.</p>
</dd>
<dt class="label" id="id214"><span class="brackets">CHMM21</span><span class="fn-backref">(<a href="#id14">1</a>,<a href="#id16">2</a>,<a href="#id51">3</a>,<a href="#id55">4</a>,<a href="#id60">5</a>,<a href="#id69">6</a>,<a href="#id71">7</a>,<a href="#id73">8</a>,<a href="#id74">9</a>,<a href="#id77">10</a>,<a href="#id83">11</a>,<a href="#id86">12</a>,<a href="#id88">13</a>,<a href="#id126">14</a>,<a href="#id251">15</a>)</span></dt>
<dd><p>Paul Corral, Kristen Himelein, Kevin McGee, and Isabel Molina. A map of the poor or a poor map? <em>Mathematics</em>, 2021. URL: <a class="reference external" href="https://www.mdpi.com/2227-7390/9/21/2780">https://www.mdpi.com/2227-7390/9/21/2780</a>, <a class="reference external" href="https://doi.org/10.3390/math9212780">doi:10.3390/math9212780</a>.</p>
</dd>
<dt class="label" id="id192"><span class="brackets">CMN21</span><span class="fn-backref">(<a href="#id18">1</a>,<a href="#id33">2</a>,<a href="#id46">3</a>,<a href="#id49">4</a>,<a href="#id54">5</a>,<a href="#id56">6</a>,<a href="#id96">7</a>,<a href="#id100">8</a>,<a href="#id105">9</a>,<a href="#id109">10</a>,<a href="#id125">11</a>,<a href="#id129">12</a>,<a href="#id131">13</a>,<a href="#id250">14</a>,<a href="#id262">15</a>,<a href="#id277">16</a>,<a href="#id282">17</a>,<a href="#id299">18</a>,<a href="#id301">19</a>,<a href="#id303">20</a>,<a href="#id305">21</a>)</span></dt>
<dd><p>Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. <em>Journal of Statistical Computation and Simulation</em>, 91(16):3304–3357, 2021. URL: <a class="reference external" href="https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460">https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460</a>, <a class="reference external" href="https://doi.org/10.1080/00949655.2021.1926460">doi:10.1080/00949655.2021.1926460</a>.</p>
</dd>
<dt class="label" id="id150"><span class="brackets"><a class="fn-backref" href="#id2">EFL+07</a></span></dt>
<dd><p>Chris Elbers, Tomoki Fujii, Peter Lanjouw, Berk Ozler, Wesley Yin, and others. Poverty alleviation through geographic targeting: how much does disaggregation help? <em>Journal of Development Economics</em>, 83(1):198–213, 2007.</p>
</dd>
<dt class="label" id="id154"><span class="brackets">ELL03</span><span class="fn-backref">(<a href="#id3">1</a>,<a href="#id9">2</a>,<a href="#id42">3</a>,<a href="#id115">4</a>,<a href="#id118">5</a>)</span></dt>
<dd><p>Chris Elbers, Jean O Lanjouw, and Peter Lanjouw. Micro–level estimation of poverty and inequality. <em>Econometrica</em>, 71(1):355–364, 2003.</p>
</dd>
<dt class="label" id="id166"><span class="brackets">ELL02</span><span class="fn-backref">(<a href="#id34">1</a>,<a href="#id37">2</a>,<a href="#id52">3</a>,<a href="#id80">4</a>,<a href="#id87">5</a>,<a href="#id268">6</a>,<a href="#id271">7</a>)</span></dt>
<dd><p>Chris Elbers, Jean Olson Lanjouw, and Peter Lanjouw. Micro-level estimation of welfare. <em>World Bank Policy Research Working Paper</em>, 2002.</p>
</dd>
<dt class="label" id="id164"><span class="brackets"><a class="fn-backref" href="#id138">FGT84</a></span></dt>
<dd><p>James Foster, Joel Greer, and Erik Thorbecke. A class of decomposable poverty measures. <em>Econometrica: Journal of the Econometric Society</em>, 52:761–766, 1984.</p>
</dd>
<dt class="label" id="id176"><span class="brackets">GonzalezMLombardiaM+08</span><span class="fn-backref">(<a href="#id44">1</a>,<a href="#id130">2</a>,<a href="#id140">3</a>,<a href="#id144">4</a>)</span></dt>
<dd><p>Wenceslao González-Manteiga, Maria J Lombardía, Isabel Molina, Domingo Morales, and Laureano Santamaría. Bootstrap mean squared error of a small-area EBLUP. <em>Journal of Statistical Computation and Simulation</em>, 78(5):443–462, 2008.</p>
</dd>
<dt class="label" id="id149"><span class="brackets"><a class="fn-backref" href="#id104">GMR18</a></span></dt>
<dd><p>María Guadarrama, Isabel Molina, and JNK Rao. Small area estimation of general parameters under complex sampling designs. <em>Computational Statistics &amp; Data Analysis</em>, 121:20–40, 2018.</p>
</dd>
<dt class="label" id="id168"><span class="brackets"><a class="fn-backref" href="#id81">Har76</a></span></dt>
<dd><p>Andrew C Harvey. Estimating regression models with multiplicative heteroscedasticity. <em>Econometrica: Journal of the Econometric Society</em>, 44:461–465, 1976. URL: <a class="reference external" href="https://www.jstor.org/stable/1913974?casa_token=rLCctNWylroAAAAA:3-S22Hv84lze8TUU-3nyFgDGZsrxkAoCZHwUVKO99Qynn_zXmr8-3kmdqFxdLxRBJT8KiE-xYwfoI5-gzFA9RF3N-KHS3g7na1Soi8WbYp_QBcPfjU7m&amp;seq=1">https://www.jstor.org/stable/1913974?casa_token=rLCctNWylroAAAAA:3-S22Hv84lze8TUU-3nyFgDGZsrxkAoCZHwUVKO99Qynn_zXmr8-3kmdqFxdLxRBJT8KiE-xYwfoI5-gzFA9RF3N-KHS3g7na1Soi8WbYp_QBcPfjU7m&amp;seq=1</a>.</p>
</dd>
<dt class="label" id="id162"><span class="brackets">Hen53</span><span class="fn-backref">(<a href="#id17">1</a>,<a href="#id29">2</a>,<a href="#id36">3</a>)</span></dt>
<dd><p>Charles R Henderson. Estimation of variance and covariance components. <em>Biometrics</em>, 9(2):226–252, 1953.</p>
</dd>
<dt class="label" id="id208"><span class="brackets">MMMR17</span><span class="fn-backref">(<a href="#id13">1</a>,<a href="#id15">2</a>,<a href="#id25">3</a>,<a href="#id70">4</a>,<a href="#id90">5</a>,<a href="#id108">6</a>)</span></dt>
<dd><p>Yolanda Marhuenda, Isabel Molina, Domingo Morales, and JNK Rao. Poverty mapping in small areas under a twofold nested error regression model. <em>Journal of the Royal Statistical Society: Series A (Statistics in Society)</em>, 180(4):1111–1136, 2017. <a class="reference external" href="https://doi.org/10.1111/rssa.12306">doi:10.1111/rssa.12306</a>.</p>
</dd>
<dt class="label" id="id152"><span class="brackets"><a class="fn-backref" href="#id68">MNS+20</a></span></dt>
<dd><p>Takaaki Masaki, David Newhouse, Ani Rudra Silwal, Adane Bedada, and Ryan Engstrom. Small area estimation of non-monetary poverty with geospatial data. <em>World Bank Policy Research Working Paper</em>, 2020.</p>
</dd>
<dt class="label" id="id175"><span class="brackets">Mol19</span><span class="fn-backref">(<a href="#id95">1</a>,<a href="#id128">2</a>,<a href="#id261">3</a>)</span></dt>
<dd><p>Isabel Molina. <em>Desagregación De Datos En Encuestas De Hogares: Metodologías De Estimación En áreas Pequeñas</em>. CEPAL, 2019. URL: <a class="reference external" href="https://repositorio.cepal.org/handle/11362/44214">https://repositorio.cepal.org/handle/11362/44214</a>.</p>
</dd>
<dt class="label" id="id170"><span class="brackets">MM15</span><span class="fn-backref">(<a href="#id20">1</a>,<a href="#id21">2</a>,<a href="#id23">3</a>,<a href="#id99">4</a>,<a href="#id135">5</a>,<a href="#id142">6</a>,<a href="#id254">7</a>,<a href="#id287">8</a>)</span></dt>
<dd><p>Isabel Molina and Yolanda Marhuenda. Sae: an R package for small area estimation. <em>The R Journal</em>, 7(1):81–98, 2015.</p>
</dd>
<dt class="label" id="id169"><span class="brackets">MR10</span><span class="fn-backref">(<a href="#id4">1</a>,<a href="#id10">2</a>,<a href="#id43">3</a>,<a href="#id57">4</a>,<a href="#id89">5</a>,<a href="#id98">6</a>,<a href="#id116">7</a>,<a href="#id119">8</a>,<a href="#id120">9</a>,<a href="#id121">10</a>,<a href="#id123">11</a>,<a href="#id124">12</a>,<a href="#id127">13</a>,<a href="#id133">14</a>,<a href="#id134">15</a>,<a href="#id136">16</a>,<a href="#id141">17</a>)</span></dt>
<dd><p>Isabel Molina and JNK Rao. Small area estimation of poverty indicators. <em>Canadian Journal of Statistics</em>, 38(3):369–385, 2010.</p>
</dd>
<dt class="label" id="id151"><span class="brackets">NCAZ18</span><span class="fn-backref">(<a href="#id27">1</a>,<a href="#id38">2</a>,<a href="#id76">3</a>,<a href="#id101">4</a>,<a href="#id106">5</a>,<a href="#id110">6</a>,<a href="#id112">7</a>,<a href="#id269">8</a>,<a href="#id272">9</a>)</span></dt>
<dd><p>Minh Cong Nguyen, Paul Corral, João Pedro Azevedo, and Qinghua Zhao. Sae: a stata package for unit level small area estimation. <em>World Bank Policy Research Working Paper</em>, 2018.</p>
</dd>
<dt class="label" id="id213"><span class="brackets"><a class="fn-backref" href="#id67">PC19</a></span></dt>
<dd><p>Ryan A Peterson and Joseph E Cavanaugh. Ordered quantile normalization: a semiparametric transformation built for the cross-validation era. <em>Journal of Applied Statistics</em>, 47(13-15):2312–2327, 2019. URL: <a class="reference external" href="https://www.tandfonline.com/action/showCitFormats?doi=10.1080/02664763.2019.1630372">https://www.tandfonline.com/action/showCitFormats?doi=10.1080/02664763.2019.1630372</a>, <a class="reference external" href="https://doi.org/10.1080/02664763.2019.1630372">doi:10.1080/02664763.2019.1630372</a>.</p>
</dd>
<dt class="label" id="id165"><span class="brackets">RM15</span><span class="fn-backref">(<a href="#id58">1</a>,<a href="#id78">2</a>,<a href="#id97">3</a>)</span></dt>
<dd><p>JNK Rao and Isabel Molina. <em>Small Area Estimation</em>. John Wiley &amp; Sons, 2nd edition, 2015.</p>
</dd>
<dt class="label" id="id216"><span class="brackets"><a class="fn-backref" href="#id59">RPPST20</a></span></dt>
<dd><p>Natalia Rojas-Perilla, Sören Pannier, Timo Schmid, and Nikos Tzavidis. Data-driven transformations in small area estimation. <em>Journal of the Royal Statistical Society: Series A (Statistics in Society)</em>, 183(1):121–148, 2020.</p>
</dd>
<dt class="label" id="id207"><span class="brackets">TZL+18</span><span class="fn-backref">(<a href="#id61">1</a>,<a href="#id65">2</a>,<a href="#id72">3</a>)</span></dt>
<dd><p>Nikos Tzavidis, Li-Chun Zhang, Angela Luna, Timo Schmid, and Natalia Rojas-Perilla. From start to finish: a framework for the production of small area official statistics. <em>Journal of the Royal Statistical Society: Series A (Statistics in Society)</em>, 181(4):927–979, 2018.</p>
</dd>
<dt class="label" id="id156"><span class="brackets">VdW14</span><span class="fn-backref">(<a href="#id30">1</a>,<a href="#id91">2</a>,<a href="#id107">3</a>,<a href="#id266">4</a>,<a href="#id275">5</a>)</span></dt>
<dd><p>Roy Van der Weide. GLS estimation and empirical bayes prediction for linear mixed models with heteroskedasticity and sampling weights: A background study for the POVMAP project. <em>World Bank Policy Research Working Paper</em>, 2014. URL: <a class="reference external" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2495175">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2495175</a>.</p>
</dd>
<dt class="label" id="id155"><span class="brackets">Zha06</span><span class="fn-backref">(<a href="#id7">1</a>,<a href="#id28">2</a>,<a href="#id113">3</a>,<a href="#id253">4</a>)</span></dt>
<dd><p>Qinghua Zhao. <em>User Manual for Povmap</em>. 2006. URL: <a class="reference external" href="http://siteresources. worldbank. org/INTPGI/Resources/342674-1092157888460/Zhao_ ManualPovMap. pdf">http://siteresources. worldbank. org/INTPGI/Resources/342674-1092157888460/Zhao_ ManualPovMap. pdf</a>.</p>
</dd>
</dl>
</div>
</section>
<section id="notes">
<span id="unit-level-notes"></span><h2><span class="section-number">4.7. </span>Notes<a class="headerlink" href="#notes" title="Permalink to this headline">#</a></h2>
<hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="id249"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>This section draws from the background papers for these guidelines. See <span id="id250">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span> and <span id="id251">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id112" title="Paul Corral, Kristen Himelein, Kevin McGee, and Isabel Molina. A map of the poor or a poor map? Mathematics, 2021. URL: https://www.mdpi.com/2227-7390/9/21/2780, doi:10.3390/math9212780.">2021</a>]</span>.</p>
</dd>
<dt class="label" id="id252"><span class="brackets"><a class="fn-backref" href="#id5">2</a></span></dt>
<dd><p>A factor that likely contributed to the expansion of these methods is the availability of software, which can be easily used to apply these approaches; <code class="docutils literal notranslate"><span class="pre">PovMap</span></code> (<span id="id253">Zhao [<a class="reference internal" href="#id155" title="Qinghua Zhao. User Manual for Povmap. 2006. URL: http://siteresources. worldbank. org/INTPGI/Resources/342674-1092157888460/Zhao_ ManualPovMap. pdf.">2006</a>]</span>) for ELL and R’s <code class="docutils literal notranslate"><span class="pre">sae</span></code> package (<span id="id254">Molina and Marhuenda [<a class="reference internal" href="06_diagnostics.html#id68" title="Isabel Molina and Yolanda Marhuenda. Sae: an R package for small area estimation. The R Journal, 7(1):81–98, 2015.">2015</a>]</span>). While other methods exist, for the purposes of this section, attention is given to the methods noted.</p>
</dd>
<dt class="label" id="id255"><span class="brackets"><a class="fn-backref" href="#id6">3</a></span></dt>
<dd><p>It is highly recommended that novice practitioners start by reading <strong><a class="reference internal" href="#unit-level-prep-assumed"><span class="std std-numref">Section 4.1.1</span></a></strong>.</p>
</dd>
<dt class="label" id="id256"><span class="brackets"><a class="fn-backref" href="#id8">4</a></span></dt>
<dd><p>Stata’s double-precision only goes up to 16 digits.</p>
</dd>
<dt class="label" id="id257"><span class="brackets"><a class="fn-backref" href="#id12">5</a></span></dt>
<dd><p>Additional information is provided in the technical annex <strong><a class="reference internal" href="#unit-level-annex"><span class="std std-numref">Section 4.4</span></a></strong>.</p>
</dd>
<dt class="label" id="id258"><span class="brackets"><a class="fn-backref" href="#id19">6</a></span></dt>
<dd><p>Interested readers can refer to Stata’s documentation to learn more about mixed models.</p>
</dd>
<dt class="label" id="id259"><span class="brackets"><a class="fn-backref" href="#id22">7</a></span></dt>
<dd><p>To see the help file in Stata type: <code class="docutils literal notranslate"><span class="pre">help</span> <span class="pre">sae_ebp</span> </code>for the one-fold nested-error model.</p>
</dd>
<dt class="label" id="id260"><span class="brackets"><a class="fn-backref" href="#id24">8</a></span></dt>
<dd><p>CensusEB estimates are similar to EB estimates, but do not include survey observations when calculating small area estimates. See <span id="id261">Molina [<a class="reference internal" href="05_off-census.html#id115" title="Isabel Molina. Desagregación De Datos En Encuestas De Hogares: Metodologías De Estimación En áreas Pequeñas. CEPAL, 2019. URL: https://repositorio.cepal.org/handle/11362/44214.">2019</a>]</span> or <span id="id262">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span> for more details.</p>
</dd>
<dt class="label" id="id263"><span class="brackets"><a class="fn-backref" href="#id26">9</a></span></dt>
<dd><p>To see help file in Stata type: <code class="docutils literal notranslate"><span class="pre">help</span> <span class="pre">sae_ebp2</span> </code>for the two-fold nested-error model.</p>
</dd>
<dt class="label" id="id264"><span class="brackets"><a class="fn-backref" href="#id31">10</a></span></dt>
<dd><p>Methods that do not consider the survey sampling weights may in turn include covariates that capture the sampling/response mechanism, trying to correctly model their relationship to the target variable.</p>
</dd>
<dt class="label" id="id265"><span class="brackets"><a class="fn-backref" href="#id32">11</a></span></dt>
<dd><p>To see help file in Stata type: <code class="docutils literal notranslate"><span class="pre">help</span> <span class="pre">sae_mc_bs</span> </code>for the one-fold nested-error model fit with Henderson’s method III heteroskedasticity and survey weights (see <span id="id266">Van der Weide [<a class="reference internal" href="#id156" title="Roy Van der Weide. GLS estimation and empirical bayes prediction for linear mixed models with heteroskedasticity and sampling weights: A background study for the POVMAP project. World Bank Policy Research Working Paper, 2014. URL: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2495175.">2014</a>]</span>).</p>
</dd>
<dt class="label" id="id267"><span class="brackets"><a class="fn-backref" href="#id35">12</a></span></dt>
<dd><p>Readers may refer to <span id="id268">Elbers <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id64" title="Chris Elbers, Jean Olson Lanjouw, and Peter Lanjouw. Micro-level estimation of welfare. World Bank Policy Research Working Paper, 2002.">2002</a>]</span> or <span id="id269">Nguyen <em>et al.</em> [<a class="reference internal" href="#id151" title="Minh Cong Nguyen, Paul Corral, João Pedro Azevedo, and Qinghua Zhao. Sae: a stata package for unit level small area estimation. World Bank Policy Research Working Paper, 2018.">2018</a>]</span> for a full exposition of the alpha model for heteroskedasticity.</p>
</dd>
<dt class="label" id="id270"><span class="brackets"><a class="fn-backref" href="#id39">13</a></span></dt>
<dd><p>The adaptation was made in light of criticism regarding the fitting method described in ELL (<span id="id271">Elbers <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id64" title="Chris Elbers, Jean Olson Lanjouw, and Peter Lanjouw. Micro-level estimation of welfare. World Bank Policy Research Working Paper, 2002.">2002</a>]</span>). See <span id="id272">Nguyen <em>et al.</em> [<a class="reference internal" href="#id151" title="Minh Cong Nguyen, Paul Corral, João Pedro Azevedo, and Qinghua Zhao. Sae: a stata package for unit level small area estimation. World Bank Policy Research Working Paper, 2018.">2018</a>]</span> for more details.</p>
</dd>
<dt class="label" id="id273"><span class="brackets"><a class="fn-backref" href="#id40">14</a></span></dt>
<dd><p>Ensuring the use of same area identifiers is still recommended for the inclusion of area-level variables.</p>
</dd>
<dt class="label" id="id274"><span class="brackets"><a class="fn-backref" href="#id41">15</a></span></dt>
<dd><p>To see help file in Stata type: <code class="docutils literal notranslate"><span class="pre">help</span> <span class="pre">sae_ell</span> </code>for the one-fold nested-error model fit with heteroskedasticity and survey weights (see <span id="id275">Van der Weide [<a class="reference internal" href="#id156" title="Roy Van der Weide. GLS estimation and empirical bayes prediction for linear mixed models with heteroskedasticity and sampling weights: A background study for the POVMAP project. World Bank Policy Research Working Paper, 2014. URL: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2495175.">2014</a>]</span>).</p>
</dd>
<dt class="label" id="id276"><span class="brackets"><a class="fn-backref" href="#id45">16</a></span></dt>
<dd><p><span id="id277">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span> discuss the differences between the methods used for noise estimation and how the methods fare when applied to simulated data.</p>
</dd>
<dt class="label" id="id278"><span class="brackets"><a class="fn-backref" href="#id47">17</a></span></dt>
<dd><p><strong><a class="reference internal" href="#unit-level-annex"><span class="std std-numref">Section 4.4</span></a></strong> gives a more detailed explanation on the differences.</p>
</dd>
<dt class="label" id="id279"><span class="brackets"><a class="fn-backref" href="#id48">18</a></span></dt>
<dd><p>Empirical MSE are obtained from multiple samples. Under model-based simulations, the sample is kept fixed, and across populations the only difference is in the errors. Under design-based simulations, multiple samples are taken from a single (fixed) population.</p>
</dd>
<dt class="label" id="id280"><span class="brackets"><a class="fn-backref" href="#id50">19</a></span></dt>
<dd><p>In areas with no information (areas not sampled), EB and ELL estimates are similar.</p>
</dd>
<dt class="label" id="id281"><span class="brackets"><a class="fn-backref" href="#id62">20</a></span></dt>
<dd><p>The implementation of the ELL method in PovMap allowed practitioners to draw errors from the empirical distribution, which in principle may benefit the method when normality does not hold. Nevertheless, when comparing CensusEB method (assuming normal errors) and ELL method (drawing errors from the empirical distribution) in a model-based simulation experiment, where the model errors used to generate the populations were drawn from a Student’s t-distribution, CensusEB outperformed ELL by a considerable margin (see <span id="id282">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span>).</p>
</dd>
<dt class="label" id="id283"><span class="brackets"><a class="fn-backref" href="#id63">21</a></span></dt>
<dd><p>In cases where, even after transformation, the deviation is apparent only in isolated observations or isolated areas, models based on mixtures of normal distributions may be used. To estimate poverty and inequality indicators, a mixture may be specified as done by <span id="id284"></span>. <span id="id285"></span> extend the EB procedure to a multivariate mixture model that incorporates heterogeneity in the regression coefficients apart from the variance components. The proposed model was used to estimate FGT0 and FGT1 by gender in West Bank and Gaza.</p>
</dd>
<dt class="label" id="id286"><span class="brackets"><a class="fn-backref" href="#id66">22</a></span></dt>
<dd><p>R packages <code class="docutils literal notranslate"><span class="pre">sae</span></code> (<span id="id287">Molina and Marhuenda [<a class="reference internal" href="06_diagnostics.html#id68" title="Isabel Molina and Yolanda Marhuenda. Sae: an R package for small area estimation. The R Journal, 7(1):81–98, 2015.">2015</a>]</span>) and <code class="docutils literal notranslate"><span class="pre">emdi</span></code> (<span id="id288"></span>) also incorporate transformations.</p>
</dd>
<dt class="label" id="id289"><span class="brackets"><a class="fn-backref" href="#id75">23</a></span></dt>
<dd><p>Refer to the help files for <code class="docutils literal notranslate"><span class="pre">bcskew0</span></code> and <code class="docutils literal notranslate"><span class="pre">lnskew0</span></code> to learn more about the transformation.</p>
</dd>
<dt class="label" id="id290"><span class="brackets"><a class="fn-backref" href="#id82">24</a></span></dt>
<dd><p>An alternative approach to modeling heteroskedasticity is to consider a random coefficient model similar to the one studied in <span id="id291"></span> and applied to the estimation of mean income. However, the method has not been implemented in any software.</p>
</dd>
<dt class="label" id="id292"><span class="brackets"><a class="fn-backref" href="#id84">25</a></span></dt>
<dd><p>The example shows lower bias and a smaller MSE for a particular data set and could not translate equally to other data sets.</p>
</dd>
<dt class="label" id="id293"><span class="brackets"><a class="fn-backref" href="#id85">26</a></span></dt>
<dd><p>Heteroskedasticity may be checked by plotting residuals against predicted values.</p>
</dd>
<dt class="label" id="id294"><span class="brackets"><a class="fn-backref" href="#id92">27</a></span></dt>
<dd><p>In terms of alternatives, the R package <code class="docutils literal notranslate"><span class="pre">mcmcsae</span></code> (<span id="id295"></span>) can also model heteroskedasticity in terms of covariates.</p>
</dd>
<dt class="label" id="id296"><span class="brackets"><a class="fn-backref" href="#id93">28</a></span></dt>
<dd><p>It is advisable to split the processes across multiple do files, because model selection, as well as simulating welfare in the cesus and obtaining small area estimates for all areas is not computationally negligible.</p>
</dd>
<dt class="label" id="id297"><span class="brackets"><a class="fn-backref" href="#id94">29</a></span></dt>
<dd><p>Note Stata cannot open this data file as a regular dta file.</p>
</dd>
<dt class="label" id="id298"><span class="brackets"><a class="fn-backref" href="#id132">30</a></span></dt>
<dd><p>For the full exposition, see <span id="id299">Corral, Molina, and Nguyen [<a class="reference internal" href="06_diagnostics.html#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span>.</p>
</dd>
<dt class="label" id="id300"><span class="brackets"><a class="fn-backref" href="#id137">31</a></span></dt>
<dd><p>Note that this is considerably different from the approach that was implemented in <code class="docutils literal notranslate"><span class="pre">PovMap</span></code> <span id="id301">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span>.</p>
</dd>
<dt class="label" id="id302"><span class="brackets"><a class="fn-backref" href="#id139">32</a></span></dt>
<dd><p>See <span id="id303">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span> for more details.</p>
</dd>
<dt class="label" id="id304"><span class="brackets"><a class="fn-backref" href="#id143">33</a></span></dt>
<dd><p>See <span id="id305">Corral <em>et al.</em> [<a class="reference internal" href="06_diagnostics.html#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span> for more details.</p>
</dd>
</dl>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="03_area-level.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">3. </span>Area-level Models for Small Area Estimation</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="05_off-census.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">5. </span>Poverty Mapping in Off-Census Years</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Paul Corral, Isabel Molina, Alexandru Cojocaru, and Sandra Segovia<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>