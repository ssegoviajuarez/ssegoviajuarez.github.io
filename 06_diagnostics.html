
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>6. Model Diagnostics &#8212; Guidelines to Small Area Estimation for Poverty Mapping</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/style.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="7. Concluding Remarks" href="07_conclusion.html" />
    <link rel="prev" title="5. Poverty Mapping in Off-Census Years" href="05_off-census.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Guidelines to Small Area Estimation for Poverty Mapping</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="00_welcome.html">
                    Welcome to Guidelines to SAE for Poverty Mapping
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  CHAPTERS
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01_intro.html">
   1. Small Area Estimation for Poverty Mapping
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02_direct.html">
   2. Direct Estimates
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03_area-level.html">
   3. Area-level Models for Small Area Estimation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_unit-level.html">
   4. Unit-level Models for Small Area Estimation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05_off-census.html">
   5. Poverty Mapping in Off-Census Years
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   6. Model Diagnostics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07_conclusion.html">
   7. Concluding Remarks
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Created by <a href="https://github.com/ssegoviajuarez"> Sandra Segovia </a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/06_diagnostics.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/06_diagnostics.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-nested-error-model">
   6.1. The nested-error model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-and-variable-selection">
   6.2. Model and variable selection
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regression-diagnostics">
   6.3. Regression diagnostics
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multicollinearity">
     6.3.1. Multicollinearity
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-1">
       6.3.1.1. Example 1
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#influence-analysis">
     6.3.2. Influence analysis
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-2">
       6.3.2.1. Example 2
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#residual-analysis">
     6.3.3. Residual analysis
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#linearity">
       6.3.3.1. Linearity
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tests-for-normality-of-residuals-and-random-effects">
       6.3.3.2. Tests for normality of residuals and random effects
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#appendix">
   6.4. Appendix
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#useful-definitions-and-concepts">
     6.4.1. Useful definitions and concepts
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regression-diagnostics-do-file">
     6.4.2. Regression diagnostics do-file
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   6.5. References
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#notes">
   6.6. Notes
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Model Diagnostics</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-nested-error-model">
   6.1. The nested-error model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-and-variable-selection">
   6.2. Model and variable selection
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regression-diagnostics">
   6.3. Regression diagnostics
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multicollinearity">
     6.3.1. Multicollinearity
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-1">
       6.3.1.1. Example 1
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#influence-analysis">
     6.3.2. Influence analysis
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-2">
       6.3.2.1. Example 2
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#residual-analysis">
     6.3.3. Residual analysis
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#linearity">
       6.3.3.1. Linearity
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#tests-for-normality-of-residuals-and-random-effects">
       6.3.3.2. Tests for normality of residuals and random effects
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#appendix">
   6.4. Appendix
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#useful-definitions-and-concepts">
     6.4.1. Useful definitions and concepts
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regression-diagnostics-do-file">
     6.4.2. Regression diagnostics do-file
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   6.5. References
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#notes">
   6.6. Notes
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="model-diagnostics">
<span id="diagnostics"></span><h1><span class="section-number">6. </span>Model Diagnostics<a class="headerlink" href="#model-diagnostics" title="Permalink to this headline">#</a></h1>
<hr style="height:1px;border:none;color:#666;background-color:#666;" /><p>Small area estimation models used in <strong>Chapter 3: <a class="reference internal" href="03_area-level.html#area-level"><span class="std std-ref">Area-level Models for Small Area Estimation</span></a></strong> and <strong>Chapter 4: <a class="reference internal" href="04_unit-level.html#unit-level"><span class="std std-ref">Unit-level Models for Small Area Estimation</span></a></strong> are particular cases of linear mixed models.<a class="footnote-reference brackets" href="#id147" id="id1">1</a> Under model-based SAE, using either unit-level (<strong>Chapter 3: <a class="reference internal" href="03_area-level.html#area-level"><span class="std std-ref">Area-level Models for Small Area Estimation</span></a></strong>) or area-level (<strong>Chapter 3: <a class="reference internal" href="03_area-level.html#area-level"><span class="std std-ref">Area-level Models for Small Area Estimation</span></a></strong>) models, a series of useful model diagnostics can help verify model assumptions and assess model fit. These checks also include residual analysis to detect deviations from the assumed model and detection of influential observations <span id="id2">Rao and Molina [<a class="reference internal" href="#id63" title="JNK Rao and Isabel Molina. Small Area Estimation. John Wiley &amp; Sons, 2nd edition, 2015.">2015</a>]</span>. Performing thorough and rigorous model diagnostics as part of the SAE exercise is crucial to ensure the validity of small area estimates.</p>
<p>This chapter describes the underlying model considered in <strong><a class="reference internal" href="#diagnostics-nested-error"><span class="std std-numref">Section 6.1</span></a></strong>. Then it provides brief recommendations for model and variable selection in <strong><a class="reference internal" href="#diagnostics-selection"><span class="std std-numref">Section 6.2</span></a></strong> and concludes with regression diagnosis in <strong><a class="reference internal" href="#diagnostics-regression"><span class="std std-numref">Section 6.3</span></a></strong>.</p>
<section id="the-nested-error-model">
<span id="diagnostics-nested-error"></span><h2><span class="section-number">6.1. </span>The nested-error model<a class="headerlink" href="#the-nested-error-model" title="Permalink to this headline">#</a></h2>
<p>The model used for small area estimation of poverty and welfare, such as the ones proposed by <span id="id3">Elbers, Lanjouw, and Lanjouw [<a class="reference internal" href="#id52" title="Chris Elbers, Jean O Lanjouw, and Peter Lanjouw. Micro–level estimation of poverty and inequality. Econometrica, 71(1):355–364, 2003.">2003</a>]</span> and <span id="id4">Molina and Rao [<a class="reference internal" href="#id67" title="Isabel Molina and JNK Rao. Small area estimation of poverty indicators. Canadian Journal of Statistics, 38(3):369–385, 2010.">2010</a>]</span>, assume that the transformed welfare <span class="math notranslate nohighlight">\(y_{ch}\)</span>, for each household <span class="math notranslate nohighlight">\(h\)</span> within each location <span class="math notranslate nohighlight">\(c\)</span> in the population is linearly related to a <span class="math notranslate nohighlight">\(1\times K\)</span> vector of characteristics (or correlates) <span class="math notranslate nohighlight">\(x_{ch}\)</span> for that household, according to the nested-error model:</p>
<div class="math notranslate nohighlight" id="equation-eq-1-1-1-1">
<span class="eqno">(6.1)<a class="headerlink" href="#equation-eq-1-1-1-1" title="Permalink to this equation">#</a></span>\[y_{ch}=x_{ch}\beta+\eta_{c}+e_{ch},\:h=1,\ldots,N_{c},\,c=1,\ldots,C,\]</div>
<p>where <span class="math notranslate nohighlight">\(\eta_{c}\)</span> and <span class="math notranslate nohighlight">\(e_{ch}\)</span> are respectively location and household-specific idiosyncratic errors, assumed to be independent from each other, following:</p>
<div class="math notranslate nohighlight">
\[\eta_{c}\stackrel{iid}{\sim}N\left(0,\sigma_{\eta}^{2}\right),\:e_{ch}\stackrel{iid}{\sim}N\left(0,\sigma_{e}^{2}\right),\]</div>
<p>where the variances <span class="math notranslate nohighlight">\(\sigma_{\eta}^{2}\)</span> and <span class="math notranslate nohighlight">\(\sigma_{e}^{2}\)</span> are unknown. Here, <span class="math notranslate nohighlight">\(C\)</span> is the number of locations in which the population is divided and <span class="math notranslate nohighlight">\(N_{c}\)</span> is the number of households in location <span class="math notranslate nohighlight">\(c\)</span>, for <span class="math notranslate nohighlight">\(c=1,\ldots,C\)</span>. Finally, <span class="math notranslate nohighlight">\(\beta\)</span> is the <span class="math notranslate nohighlight">\(K\times1\)</span> vector of coefficients.</p>
<p>As illustrated in <strong>Chapter 4: <a class="reference internal" href="04_unit-level.html#unit-level"><span class="std std-ref">Unit-level Models for Small Area Estimation</span></a></strong>, the assumption of normality plays a considerable in EB methods. Deviations from this assumption may lead to biased and noisier estimates, as shown in <span id="id5">Corral <em>et al.</em> [<a class="reference internal" href="#id112" title="Paul Corral, Kristen Himelein, Kevin McGee, and Isabel Molina. A map of the poor or a poor map? Mathematics, 2021. URL: https://www.mdpi.com/2227-7390/9/21/2780, doi:10.3390/math9212780.">2021</a>]</span>. Isolated deviations from the model (outliers) and influential observations or even outlying locations may also exist. Thus, the following sections provide some insights towards selecting a suitable model, as well as checks that may be done to ensure that the chosen model for SAE is adequate.</p>
</section>
<section id="model-and-variable-selection">
<span id="diagnostics-selection"></span><h2><span class="section-number">6.2. </span>Model and variable selection<a class="headerlink" href="#model-and-variable-selection" title="Permalink to this headline">#</a></h2>
<p>The objective of model selection is to determine the relevant covariates out of a pool of candidate model variables such that the resulting SAE model generates the most precise estimates possible, noting that it must be possible to measure this precision accurately. Classic approaches to model selection include lasso or stepwise regression. Other literature on the subject includes the fence method, described in <span id="id6">Pfeffermann [<a class="reference internal" href="#id137" title="Danny Pfeffermann. New important developments in small area estimation. Statistical Science, 28(1):40–68, 2013.">2013</a>]</span>, which involves selecting a model out of a subgroup of correct models that fulfill specific criteria. <span id="id7">Rao and Molina [<a class="reference internal" href="#id63" title="JNK Rao and Isabel Molina. Small Area Estimation. John Wiley &amp; Sons, 2nd edition, 2015.">2015</a>]</span> also elaborate on other methods such as Akaike Information Criteria (AIC) type methods, which rely on the marginal restricted log likelihood based on normality of the random effects and the errors. For variable selection under area-level models, particularly Fay-Herriot models, <span id="id8">Lahiri and Suntornchost [<a class="reference internal" href="#id143" title="Partha Lahiri and Jiraphan Suntornchost. Variable selection for linear mixed models with applications in small area estimation. Sankhya B, 77(2):312–320, 2015.">2015</a>]</span> propose a method where the approximation error converges to zero in probability for large sample sizes.<a class="footnote-reference brackets" href="#id148" id="id9">2</a></p>
<p>Since the aim is to arrive at the “true” model, removing all non-significant covariates from the model is recommended as these may introduce noise. It is important not to confuse the estimated noise and the true noise of a given small area estimate. The most common uncertainty measure for an area-specific prediction is the MSE (<span id="id10">Tzavidis <em>et al.</em> [<a class="reference internal" href="#id105" title="Nikos Tzavidis, Li-Chun Zhang, Angela Luna, Timo Schmid, and Natalia Rojas-Perilla. From start to finish: a framework for the production of small area official statistics. Journal of the Royal Statistical Society: Series A (Statistics in Society), 181(4):927–979, 2018.">2018</a>]</span>). In applications of SAE, such as those illustrated for unit-level models, an estimate of the MSE for the small area estimator is obtained through a parametric bootstrap procedure (see <strong><a class="reference internal" href="04_unit-level.html#unit-level-annex-montecarlo-bootstrap"><span class="std std-numref">Section 4.4.2.2</span></a></strong>). This method differs considerably from the method used in the ELL method, where a single computational algorithm is used to obtain predictors and assess uncertainty. <span id="id11">Corral <em>et al.</em> [<a class="reference internal" href="#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span>, through model-based simulations, present evidence of the fact that the single computational algorithm to estimate noise used in ELL could underestimate the actual MSE of the method.<a class="footnote-reference brackets" href="#id149" id="id12">3</a></p>
<p>The script example provided in <strong><a class="reference internal" href="04_unit-level.html#unit-level-appendix-selection"><span class="std std-numref">Section 4.5.1</span></a></strong> uses a lasso approach for model selection that initially includes all suitable covariates and uses 10 fold cross-validation with a shrinkage parameter <span class="math notranslate nohighlight">\(\lambda\)</span> that is within one standard error of the one that minimizes the cross-validated average prediction squared error. The lasso approach employed here does not consider the nested-error structure of the model; that is, it is done with the corresponding linear model without the random area effects. Practitioners who are comfortable with R may rely on the <code class="docutils literal notranslate"><span class="pre">glmmlasso</span></code> R package, which may be used for model selection in the model with the assumed nested-error structure (see <span id="id13"></span> and <span id="id14"></span>).</p>
<p>The lasso selection process yields a selected set of covariates, although some of the included covariates may be non-significant. Consequently, the next step is to remove all the non-significant covariates sequentially. The process starts by removing the most non-significant covariates, one by one. When a covariate is removed, the significance of other covariates may change; thus, after removing each covariate, the model is fit again to determine which covariate to remove next until the remaining ones are all significant. Note that the process used here ignores the magnitude of the coefficients and thus could be further improved.</p>
<p>Finally, it is recommended to remove highly collinear covariates. Once these are removed, the following steps are to identify outliers and influential observations, which may lead to considerably different estimated model parameters, see the next section. For the Fay-Herriot model of <strong>Chapter 3: <a class="reference internal" href="03_area-level.html#area-level"><span class="std std-ref">Area-level Models for Small Area Estimation</span></a></strong> a different approach than the one detailed here was taken. In the implemented approach for area-level models, the model started with all possible covariates and began removing covariates, starting with the least significant ones. The removal was done considering the random effects (see <strong><a class="reference internal" href="03_area-level.html#area-level-first-sae"><span class="std std-numref">Section 3.2</span></a></strong>).</p>
</section>
<section id="regression-diagnostics">
<span id="diagnostics-regression"></span><h2><span class="section-number">6.3. </span>Regression diagnostics<a class="headerlink" href="#regression-diagnostics" title="Permalink to this headline">#</a></h2>
<p>After the fitting process, checking whether the assumptions from the underlying model are satisfied is recommended. Regression diagnostics for Linear Mixed Models (LMM)<a class="footnote-reference brackets" href="#id152" id="id15">4</a> are more difficult to interpret than those of the standard linear models, since these models include random effects, which lead to a different covariance structure. Moreover, tools for diagnostics of linear mixed models are less common in software packages, including Stata. Thus, practitioners either must code their own diagnostics or rely on diagnostics often used for linear regression. The model assumptions to keep in mind are: <a class="footnote-reference brackets" href="#id153" id="id16">5</a></p>
<ol class="simple">
<li><p>Linearity: the dependent variable <span class="math notranslate nohighlight">\(y_{ch}\)</span> is a linear function of the selected vector of covariates <span class="math notranslate nohighlight">\(x_{ch}\)</span>.</p></li>
<li><p>Normality: random effects <span class="math notranslate nohighlight">\(\eta_{c}\)</span> and errors <span class="math notranslate nohighlight">\(e_{ch}\)</span> are normally distributed.</p></li>
<li><p>Homoskedasticity: errors’ variance <span class="math notranslate nohighlight">\(\sigma_{e}^{2}\)</span> is constant, although this assumption may be relaxed by modeling heteroskedasticity using a model such as the alpha model specification provided by ELL (<span id="id17">Elbers <em>et al.</em> [<a class="reference internal" href="#id52" title="Chris Elbers, Jean O Lanjouw, and Peter Lanjouw. Micro–level estimation of poverty and inequality. Econometrica, 71(1):355–364, 2003.">2003</a>]</span>). This can be done when choosing Henderson’s Method III fitting in Stata’s <code class="docutils literal notranslate"><span class="pre">sae</span></code> package.</p></li>
<li><p>Independence: errors <span class="math notranslate nohighlight">\(e_{ch}\)</span> are independently distributed. Under the nested-error model, the assumption is extended so that <span class="math notranslate nohighlight">\(e_{ch}\)</span> in location <span class="math notranslate nohighlight">\(c\)</span> is unrelated to the corresponding location effect <span class="math notranslate nohighlight">\(\eta_{c}\)</span>, as well as to all other location effects <span class="math notranslate nohighlight">\(\eta_{l,}\:l\neq c\)</span>.</p></li>
</ol>
<p>Other issues to consider are the detection of influential observations and outliers and, as discussed above, multicollinearity. Although these are not part of the assumptions, their presence may affect the precision of estimates of model parameters and, in turn, model predictions.</p>
<p>The following subsections include some formal and informal ways to check if the assumptions of the underlying model are satisfied. The process starts by eliminating covariates with high multicollinearity, followed by influence analysis and, finally, residual analysis which encompasses most assumptions.<a class="footnote-reference brackets" href="#id154" id="id18">6</a> Model diagnostics based on residuals and influence measures for special cases of the general linear mixed model can be found in <span id="id19">Rao and Molina [<a class="reference internal" href="#id63" title="JNK Rao and Isabel Molina. Small Area Estimation. John Wiley &amp; Sons, 2nd edition, 2015.">2015</a>]</span>.</p>
<section id="multicollinearity">
<span id="diagnostics-regresion-coll"></span><h3><span class="section-number">6.3.1. </span>Multicollinearity<a class="headerlink" href="#multicollinearity" title="Permalink to this headline">#</a></h3>
<p>Collinearity reduces the accuracy of estimates of regression coefficients, leading to larger standard errors of the coefficients. Under the multiple imputation (MI) inspired bootstrap methods, such as the one often used in the ELL method (see <strong>Chapter 4: <a class="reference internal" href="04_unit-level.html#unit-level"><span class="std std-ref">Unit-level Models for Small Area Estimation</span></a></strong>), larger standard errors in the coefficients typically led to larger estimates of noise for the estimators of the indicators of interest. Thus, care was taken to avoid collinearity and multicollinearity. A simple way to detect collinearity is via a correlation matrix, where large absolute correlation coefficients may suggest collinearity problems (<span id="id20">James <em>et al.</em> [<a class="reference internal" href="#id138" title="Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani. An introduction to statistical learning. Volume 112. Springer, 2013. ISBN 978-1-0716-1418-1. URL: https://link.springer.com/book/10.1007/978-1-0716-1418-1?noAccess=true.">2013</a>]</span>). However, collinearity may occur between more than a pair of variables leading to multicollinearity, which cannot be detected under the pairwise correlation matrix (<em>ibid</em>).</p>
<p>Under the presence of multicollinearity, the inspection of the correlation matrix is no longer sufficient, and one must instead compute the variance inflation factors (VIFs) (<span id="id21">James <em>et al.</em> [<a class="reference internal" href="#id138" title="Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani. An introduction to statistical learning. Volume 112. Springer, 2013. ISBN 978-1-0716-1418-1. URL: https://link.springer.com/book/10.1007/978-1-0716-1418-1?noAccess=true.">2013</a>]</span>). The smallest possible value for a VIF is 1. There are multiple rules of thumb as to what is an acceptable VIF. According to <span id="id22">James <em>et al.</em> [<a class="reference internal" href="#id138" title="Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani. An introduction to statistical learning. Volume 112. Springer, 2013. ISBN 978-1-0716-1418-1. URL: https://link.springer.com/book/10.1007/978-1-0716-1418-1?noAccess=true.">2013</a>]</span>, values exceeding 5 or 10 may require action. After the model is fit, the command <code class="docutils literal notranslate"><span class="pre">estat</span> <span class="pre">vif</span></code> may be used to check the variance inflation factor for the covariates included in the model.</p>
<section id="example-1">
<h4><span class="section-number">6.3.1.1. </span>Example 1<a class="headerlink" href="#example-1" title="Permalink to this headline">#</a></h4>
<p>Variance inflation factor values above 10 might require special attention since the variable in question could be a linear combination of other independent variables. In the example below, a special Mata function,<a class="footnote-reference brackets" href="#id155" id="id23">7</a> <code class="docutils literal notranslate"><span class="pre">_f_stepvif()</span></code>, is used to remove covariates with a VIF above a specified threshold; in this case, the chosen value is 3.<a class="footnote-reference brackets" href="#id156" id="id24">8</a> The function expects the covariate list as its first argument, followed by the sample weights, and finally, the threshold. After the removal of high VIF covariates, the resulting covariate list is returned in a Stata local macro called <code class="docutils literal notranslate"><span class="pre">vifvar</span></code>.</p>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span><span class="c1">*===============================================================================</span>
<span class="c1">// Collinearity</span>
<span class="c1">*=============================================================================== </span>
<span class="k"> </span>
<span class="k">reg</span> y <span class="vg">$postsign</span> [aw=Whh],r 
    
    <span class="c1">//Check for multicollinearity, and remove highly collinear (VIF&gt;3)</span>
<span class="k">	cap drop</span> touse 	            <span class="c1">//remove vector if it is present to avoid error in next step</span>
<span class="k">	gen</span> touse =<span class="k"> e</span>(sample) 		<span class="c1">//Indicates the observations used</span>
<span class="k">	estat vif</span> 				    <span class="c1">//Variance inflation factor</span>
<span class="k">	local</span> hhvars <span class="vg">$postsign</span>
	
    <span class="c1">//Remove covariates with VIF greater than 3</span>
<span class="k">	mata</span>:<span class="k"> ds</span> = _f_stepvif(<span class="s">&quot;</span><span class="nv">`hhvars&#39;</span><span class="s">&quot;</span>,<span class="s">&quot;Whh&quot;</span>,<span class="m">3</span>,<span class="s">&quot;touse&quot;</span>) 
<span class="k">	global</span> postvif <span class="nv">`vifvar&#39;</span>
	
	<span class="c1">//VIF check</span>
<span class="k">	reg</span> y <span class="vg">$postvif</span> [aw=Whh], r
<span class="k">	vif</span>
    
    <span class="c1">// For ilustration</span>
    <span class="c1">// Henderson III GLS - model post removal of non-significant</span>
    sae model h3 y <span class="vg">$postsign</span> [aw=Whh], area(HID_mun) 
    
    <span class="c1">// Henderson III GLS - model post removal of non-significant</span>
	sae model h3 y <span class="vg">$postvif</span> [aw=Whh], area(HID_mun) 
</pre></div>
</div>
</section>
</section>
<section id="influence-analysis">
<span id="diagnostics-regresion-influence"></span><h3><span class="section-number">6.3.2. </span>Influence analysis<a class="headerlink" href="#influence-analysis" title="Permalink to this headline">#</a></h3>
<p>Influence analysis is used to detect observations that may have considerable impact on the estimates of the parameters and, consequently, model predictions. These observations include outliers (observations with a large residual, i.e., an observation poorly predicted by the model) and influential observations (the omission of which considerably changes the point estimates of <span class="math notranslate nohighlight">\(\beta\)</span>). These observations can be identified by measuring how far the observation’s value for a predictor variable is from the mean or by the size of their studentized residual. Influence analysis is recommended prior to calculating any small area estimate, as these observations may impact the bias and noise of the final small area estimates.</p>
<p>Cook’s distance (<span id="id25">Cook [<a class="reference internal" href="#id139" title="R Dennis Cook. Detection of influential observation in linear regression. Technometrics, 19(1):15–18, 1977.">1977</a>]</span>), also known as Cook’s D, measures the effect on the estimated coefficients when an observation is left out or deleted (<span id="id26">Rao and Molina [<a class="reference internal" href="#id63" title="JNK Rao and Isabel Molina. Small Area Estimation. John Wiley &amp; Sons, 2nd edition, 2015.">2015</a>]</span>). Under ordinary least squares regression, Cook’s distance can be obtained in Stata with the <code class="docutils literal notranslate"><span class="pre">cooksd</span></code> option after the <code class="docutils literal notranslate"><span class="pre">predict</span></code> command. Nevertheless, under regular OLS, Cook’s distance focuses solely on isolated observations, whereas, under the nested-error model used for SAE shown in <strong>Equation <a class="reference internal" href="#equation-eq-1-1-1-1">(6.1)</a></strong>, the analysis of the influence of particular locations may be more relevant. The Stata package <code class="docutils literal notranslate"><span class="pre">mlt</span></code> by <span id="id27">Möhring and Schmidt-Catran [<a class="reference internal" href="#id136" title="Katja Möhring and Alexander Schmidt-Catran. Mlt: stata module to provide multilevel tools. 2013. URL: https://econpapers.repec.org/software/bocbocode/s457577.htm.">2013</a>]</span> may be used to assess the influence on the estimated parameters of particular locations or groups.<a class="footnote-reference brackets" href="#id157" id="id28">9</a> The <code class="docutils literal notranslate"><span class="pre">mlt</span></code> command estimates Cook’s D empirically, making it computationally intensive. The rule of thumb for classifying influential locations is absolute Cook’s D values greater than <span class="math notranslate nohighlight">\(4/C,\)</span> where <span class="math notranslate nohighlight">\(C\)</span> is the number of locations into which the population is divided. The <code class="docutils literal notranslate"><span class="pre">mlt</span></code> command will also calculate DFBETAs, which measure the influence of a single location on the coefficient of each covariate. It represents the standardized difference between the coefficient with and without the given location (<span id="id29">Möhring and Schmidt-Catran [<a class="reference internal" href="#id136" title="Katja Möhring and Alexander Schmidt-Catran. Mlt: stata module to provide multilevel tools. 2013. URL: https://econpapers.repec.org/software/bocbocode/s457577.htm.">2013</a>]</span>). The rule of thumb for classifying locations as influential is a DFBETA absolute value above <span class="math notranslate nohighlight">\(2/\sqrt{C}\)</span>, although this should be applied with caution.</p>
<p>Leverage measures the influence on the fitted values of a given observation. Unfortunately, data packages that can obtain leverage under the assumed model are not available. <span id="id30">Cameron and Trivedi [<a class="reference internal" href="#id128" title="A Colin Cameron and Pravin K Trivedi. Microeconometrics: methods and applications. Cambridge university press, 2005. ISBN 978-0-521-84805-3.">2005</a>]</span> present an alternative toward handling influential observations under OLS by using the post estimation command <code class="docutils literal notranslate"><span class="pre">dfits</span></code>, which shows the difference in fits (predictions) with and without the unusual observation. The command combines outliers and leverage into a single statistic. A rule of thumb to identify these observations is if <span class="math notranslate nohighlight">\(|dfits|&gt;2\sqrt{k/n}\)</span>, where <span class="math notranslate nohighlight">\(k\)</span> is the number of covariates and <span class="math notranslate nohighlight">\(n\)</span> is the number of observations. Nevertheless, the removal of observations always entails loss of information (which may be fair) and thus much care should be taken before deciding on removal, and should be done only when, after inspecting the offender, it is determined to be mistaken.</p>
<section id="example-2">
<h4><span class="section-number">6.3.2.1. </span>Example 2<a class="headerlink" href="#example-2" title="Permalink to this headline">#</a></h4>
<p>After fitting the model and calculating residuals, problematic observations are identified using several rules of thumb: <span class="math notranslate nohighlight">\(Cooks'd&gt;4/n\)</span> , <span class="math notranslate nohighlight">\(leverage&gt;(2k+2)/n\)</span> and <span class="math notranslate nohighlight">\(abs(rstu)&gt;2\)</span> .</p>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span><span class="c1">// Step 1</span>

<span class="k">    reg</span> y <span class="vg">$postvif</span>	
    
    <span class="c1">// After regression without weights...</span>
    
    <span class="c1">// Calculate measures to identify influential observations</span>
<span class="k">	predict</span> cdist, cooksd      <span class="c1">// calculates the Cook&#39;s D influence statistic</span>
<span class="k">	predict</span> rstud, rstudent    <span class="c1">// calculates the Studentized (jackknifed) residuals</span>

<span class="c1">// Step 2</span>

<span class="k">    reg</span> y <span class="vg">$postvif</span> [aw=Whh]
    
    <span class="c1">// Predict leverage and residuals</span>
<span class="k">	predict</span> lev,<span class="k"> leverage</span>  <span class="c1">// calculates the diagonal elements of the </span>
                           <span class="c1">// projection (&quot;hat&quot;) matrix</span>
<span class="k">	predict</span> r, resid       <span class="c1">// calculates the residuals</span>

    <span class="c1">// Save useful locals</span>
<span class="k">    local</span> myN=<span class="nf">e</span>(N)              <span class="c1">// # observations              </span>
<span class="k">	local</span> myK=<span class="nf">e</span>(rank)           <span class="c1">// rank or k</span>
<span class="k">    local</span> KK =<span class="nf">e</span>(df_m)           <span class="c1">// degrees of freedom (k-1)</span>
<span class="k">    </span>
<span class="k">    sum</span> cdist,<span class="k"> d</span>        
<span class="c1">    * return list</span>
<span class="k">	local</span> max = <span class="nf">r</span>(max)          <span class="c1">// max value</span>
<span class="k">	local</span> p99 = <span class="nf">r</span>(p99)		    <span class="c1">// percentile 99</span>
 
 <span class="c1">// Step 3 </span>
    
    <span class="c1">// For ilustration...</span>
    <span class="c1">// We have influential data points...</span>
<span class="k">    reg</span> lny <span class="vg">$postvif</span><span class="k"> if</span> cdist<span class="o">&lt;</span><span class="m">4</span><span class="o">/</span><span class="nv">`myN&#39;</span> [aw=Whh]       
<span class="k">    reg</span> lny <span class="vg">$postvif</span><span class="k"> if</span> cdist<span class="o">&lt;</span><span class="nv">`p99&#39;</span>   [aw=Whh]
<span class="k">	reg</span> lny <span class="vg">$postvif</span><span class="k"> if</span> cdist<span class="o">&lt;</span><span class="nv">`max&#39;</span>   [aw=Whh]         

    <span class="c1">// Identified influential / outliers observations</span>
<span class="k">    gen</span> nogo = <span class="nf">abs</span>(rstud)<span class="o">&gt;</span><span class="m">2</span> <span class="o">&amp;</span> cdist<span class="o">&gt;</span><span class="m">4</span><span class="o">/</span><span class="nv">`myN&#39;</span> <span class="o">&amp;</span> lev<span class="o">&gt;</span>(<span class="m">2</span><span class="o">*</span><span class="nv">`myK&#39;</span><span class="o">+</span><span class="m">2</span>)<span class="o">/</span><span class="nv">`myN&#39;</span>
<span class="k">    </span>
<span class="k">    count if</span> nogo<span class="o">==</span><span class="m">1</span>        <span class="c1">// these are the obs that we want to eliminate</span>
</pre></div>
</div>
<p>A graphical representation of the squared normalized residual versus leverage (<code class="docutils literal notranslate"><span class="pre">lvr2plot)</span></code>, before and after the elimination of influential observations, is an easy way to identify potentially influential observations and outliers (<strong><a class="reference internal" href="#fig1-1-md"><span class="std std-numref">Fig. 6.1</span></a></strong>). The two reference lines are the means of the leverage and the squared normalized residual. Many points are outside these two reference points and should be scrutinized before deciding to remove them.</p>
<figure class="align-default" id="fig1-1-md">
<a class="reference internal image-reference" href="lvr2plot.png"><img alt="lvr2plot.png" src="lvr2plot.png" style="height: 350px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 6.1 </span><span class="caption-text"><em>Squared normalized residual vs leverage</em></span><a class="headerlink" href="#fig1-1-md" title="Permalink to this image">#</a></p>
<div class="legend">
<p>Source: own elaboration from code in Appendix <strong><a class="reference internal" href="#diagnostics-appendix-regression"><span class="std std-numref">Section 6.4.2</span></a></strong>. The red lines are references to the mean leverage on the Y axis and the mean squared normalized residual on the X axis. Observations that are far away from these reference points should be inspected more closely.</p>
</div>
</figcaption>
</figure>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span><span class="c1">// Graphic method &lt; after &gt;</span>

<span class="k">    reg</span> y <span class="vg">$postvif</span> [aw=Whh]<span class="k"> if</span> nogo<span class="o">==</span><span class="m">0</span>
    
    <span class="c1">// residuals vs fitted vals</span>
<span class="k">    rvfplot</span> , yline(<span class="m">0</span>)  <span class="nv">`graphs&#39;</span> 
<span class="k">                                         </span>
<span class="k">    graph</span> export <span class="s">&quot;</span><span class="vg">$figs</span><span class="s">\rvfplot_2_after.png&quot;</span>,<span class="k"> as</span>(png)<span class="k"> replace</span>
    
    
    <span class="c1">// normalized residual squared vs leverage</span>
<span class="k">    lvr2plot</span> ,        <span class="nv">`graphs&#39;</span> 
<span class="k">                                         </span>
<span class="k">    graph</span> export <span class="s">&quot;</span><span class="vg">$figs</span><span class="s">\lvr2plot_after.png&quot;</span>,<span class="k"> as</span>(png)<span class="k"> replace</span>
</pre></div>
</div>
</section>
</section>
<section id="residual-analysis">
<span id="diagnostics-regresion-residual"></span><h3><span class="section-number">6.3.3. </span>Residual analysis<a class="headerlink" href="#residual-analysis" title="Permalink to this headline">#</a></h3>
<p>Most techniques for residual analysis rely on visual inspection of the graphed residuals. Residuals should be checked for linearity, normality, and constant variance in case homoskedasticity is assumed.</p>
<section id="linearity">
<span id="diagnostics-regresion-residual-linearity"></span><h4><span class="section-number">6.3.3.1. </span>Linearity<a class="headerlink" href="#linearity" title="Permalink to this headline">#</a></h4>
<p>The nested-error model used in SAE (<strong>Equation <a class="reference internal" href="#equation-eq-1-1-1-1">(6.1)</a></strong>) assumes that the outcome variable <span class="math notranslate nohighlight">\(y\)</span> is a linear function of the covariates.<a class="footnote-reference brackets" href="#id158" id="id31">10</a> If a single covariate is used, a scatter plot of the residual versus the covariate is enough to see if a linear relationship exists. When several covariates are used, checking for linearity is somewhat more complex.</p>
<p>To assess linearity in a simple regression, use <code class="docutils literal notranslate"><span class="pre">scatter</span></code> to produce a plot of <span class="math notranslate nohighlight">\(y\)</span> versus <span class="math notranslate nohighlight">\(x\)</span>, <code class="docutils literal notranslate"><span class="pre">lfit</span></code> to fit a regression line, and <code class="docutils literal notranslate"><span class="pre">lowess</span></code> to show a smoothed fit.</p>
<p><code class="docutils literal notranslate"><span class="pre">.</span> <span class="pre">reg</span> <span class="pre">depvar</span> <span class="pre">indepvar</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">.</span> <span class="pre">twoway</span> <span class="pre">(scatter</span> <span class="pre">depvar</span> <span class="pre">indepvar)(lfit</span> <span class="pre">depvar</span> <span class="pre">indepvar)(lowess</span> <span class="pre">depvar</span> <span class="pre">indepvar)</span></code></p>
<p>For multiple regression:</p>
<p><code class="docutils literal notranslate"><span class="pre">.</span> <span class="pre">reg</span> <span class="pre">depvar</span> <span class="pre">indepvars</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">.</span> <span class="pre">predict</span> <span class="pre">r,</span> <span class="pre">residual</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">.</span> <span class="pre">scatter</span> <span class="pre">r</span> <span class="pre">indepvar1</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">.</span> <span class="pre">scatter</span> <span class="pre">r</span> <span class="pre">indepvar2</span></code></p>
<p>Other checks for non-linearity include <code class="docutils literal notranslate"><span class="pre">acprlot</span> </code>and<code class="docutils literal notranslate"> <span class="pre">cprplot</span></code>, which produce graphs of an augmented component-plus-residual plot and a residual plot, respectively.</p>
<p><code class="docutils literal notranslate"><span class="pre">.</span> <span class="pre">reg</span> <span class="pre">depvar</span> <span class="pre">indepvars</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">.</span> <span class="pre">acprplot</span> <span class="pre">indepvar1,</span> <span class="pre">lowess</span> <span class="pre">lsopts(bwidth(1))</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">.</span> <span class="pre">acprplot</span> <span class="pre">indepvar2,</span> <span class="pre">lowess</span> <span class="pre">lsopts(bwidth(1))</span></code></p>
<p>When a clear non-linear pattern is observed, transformations of the independent variable might help.</p>
<p><code class="docutils literal notranslate"><span class="pre">.</span> <span class="pre">graph</span> <span class="pre">matrix</span> <span class="pre">depvar</span> <span class="pre">indepvars,</span> <span class="pre">half</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">.</span> <span class="pre">kdensity</span> <span class="pre">indepvar,</span> <span class="pre">normal</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">.</span> <span class="pre">gen</span> <span class="pre">logvar=log(indepvar)</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">.</span> <span class="pre">kdensity</span> <span class="pre">logvar,</span> <span class="pre">normal</span></code></p>
</section>
<section id="tests-for-normality-of-residuals-and-random-effects">
<span id="diagnostics-regresion-residual-tests"></span><h4><span class="section-number">6.3.3.2. </span>Tests for normality of residuals and random effects<a class="headerlink" href="#tests-for-normality-of-residuals-and-random-effects" title="Permalink to this headline">#</a></h4>
<p>Model errors and random effects are assumed to be normally distributed under the nested-error model used for SAE. Deviations from normality may lead to considerable bias in the final small area estimates. Scatter plots of residuals against fitted values and normal Q-Q plots of residuals provide a natural way to identify outliers or influential observations that might affect the precision of the estimates. <span id="id32">West <em>et al.</em> [<a class="reference internal" href="#id132" title="Brady T West, Kathleen B Welch, and Andrzej T Galecki. Linear mixed models: a practical guide using statistical software. Chapman and Hall/CRC, 2nd edition, 2014. URL: https://www.taylorfrancis.com/books/mono/10.1201/b17198/linear-mixed-models-brady-west-kathleen-welch-andrzej-galecki, doi:10.1201/b17198.">2014</a>]</span> mention that the random effects vector is assumed to follow a multivariate normal distribution. Thus, the information from the observations sharing the same random effect is used to predict (instead of estimating) the values of that random effect in the model.</p>
<p>The usual predictors of the random effects under linear mixed models are known as Empirical Best Linear Unbiased Predictors (EBLUPs), since they are the most precise linear unbiased predictors. They use the weighted least squares estimates of <span class="math notranslate nohighlight">\(\beta\)</span>, and the variance parameters are replaced by suitable estimates (<span id="id33">Robinson and others [<a class="reference internal" href="#id127" title="George K Robinson and others. That blup is a good thing: the estimation of random effects. Statistical science, 6(1):15–32, 1991.">1991</a>]</span>). <span id="id34">Rao and Molina [<a class="reference internal" href="#id63" title="JNK Rao and Isabel Molina. Small Area Estimation. John Wiley &amp; Sons, 2nd edition, 2015.">2015</a>]</span> provide a comprehensive formal derivation of the EBLUPs, and applications beyond small area estimation can be found in <span id="id35">West <em>et al.</em> [<a class="reference internal" href="#id132" title="Brady T West, Kathleen B Welch, and Andrzej T Galecki. Linear mixed models: a practical guide using statistical software. Chapman and Hall/CRC, 2nd edition, 2014. URL: https://www.taylorfrancis.com/books/mono/10.1201/b17198/linear-mixed-models-brady-west-kathleen-welch-andrzej-galecki, doi:10.1201/b17198.">2014</a>]</span>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">xtmixed</span></code> or <code class="docutils literal notranslate"><span class="pre">mixed</span></code> command may be used to check the validity of a linear mixed model in Stata. Deviations from normality can be observed in a normal Q-Q plot of residuals (<strong><a class="reference internal" href="#fig-1-1-3"><span class="std std-numref">Fig. 6.2</span></a></strong>), which displays sample quantiles of unit-level residuals against the theoretical quantiles of a normal distribution plot:</p>
<p><code class="docutils literal notranslate"><span class="pre">mixed</span> <span class="pre">depvar</span> <span class="pre">indepvars</span> <span class="pre">||</span> <span class="pre">area:,</span> <span class="pre">reml</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">predict</span> <span class="pre">res,</span> <span class="pre">residual</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">qnorm</span> <span class="pre">res</span></code></p>
<figure class="align-default" id="fig-1-1-3">
<a class="reference internal image-reference" href="qnorm_mixed.png"><img alt="qnorm_mixed.png" src="qnorm_mixed.png" style="height: 350px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 6.2 </span><span class="caption-text"><em>Sample quantiles of residuals against theoretical quantiles of a Normal distribution</em></span><a class="headerlink" href="#fig-1-1-3" title="Permalink to this image">#</a></p>
<div class="legend">
<p>Source: own elaboration from code in Appendix <strong><a class="reference internal" href="#diagnostics-appendix-regression"><span class="std std-numref">Section 6.4.2</span></a></strong>. Deviations from normality can be observed in the figure particularly at the bottom. <span id="id36">Marhuenda <em>et al.</em> [<a class="reference internal" href="#id106" title="Yolanda Marhuenda, Isabel Molina, Domingo Morales, and JNK Rao. Poverty mapping in small areas under a twofold nested error regression model. Journal of the Royal Statistical Society: Series A (Statistics in Society), 180(4):1111-1136, 2017. doi:10.1111/rssa.12306.">2017</a>]</span> notes that, in applications using real data, the exact fit to a distribution is hardly met; it is recommended that practitioners apply several transformations to the dependent variable and select the one that provides the best approximation to the nested-error model’s assumptions.</p>
</div>
</figcaption>
</figure>
<p>It is also important to check the assumptions regarding the distribution of the random effects. This may be done after fitting the linear mixed model and obtaining the predicted random effects (<strong><a class="reference internal" href="#fig-1-1-3-1"><span class="std std-numref">Fig. 6.3</span></a></strong>):</p>
<p><code class="docutils literal notranslate"><span class="pre">predict</span> <span class="pre">eta,</span> <span class="pre">reffects</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">bysort</span> <span class="pre">area:</span> <span class="pre">gen</span> <span class="pre">first</span> <span class="pre">=</span> <span class="pre">_n</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">qnorm</span> <span class="pre">eta</span> <span class="pre">if</span> <span class="pre">first==1</span></code></p>
<figure class="align-default" id="fig-1-1-3-1">
<a class="reference internal image-reference" href="qnorm_mixed_1.png"><img alt="qnorm_mixed_1.png" src="qnorm_mixed_1.png" style="height: 350px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 6.3 </span><span class="caption-text"><em>Sample quantiles of predicted random effects against theoretical quantiles of a Normal distribution</em></span><a class="headerlink" href="#fig-1-1-3-1" title="Permalink to this image">#</a></p>
<div class="legend">
<p>Source: own elaboration.</p>
</div>
</figcaption>
</figure>
<p>The plots of empirical quantiles compared to theoretical quantiles of the normal distribution (normal Q-Q plots) are helpful to detect deviations from normality. Transformations of the dependent variable are often taken to ensure that empirical quantiles are better aligned to the theoretical ones. As <span id="id37">Marhuenda <em>et al.</em> [<a class="reference internal" href="#id106" title="Yolanda Marhuenda, Isabel Molina, Domingo Morales, and JNK Rao. Poverty mapping in small areas under a twofold nested error regression model. Journal of the Royal Statistical Society: Series A (Statistics in Society), 180(4):1111-1136, 2017. doi:10.1111/rssa.12306.">2017</a>]</span> note, in real life applications, the exact fit to a distribution is hardly met.</p>
</section>
</section>
</section>
<section id="appendix">
<span id="diagnostics-appendix"></span><h2><span class="section-number">6.4. </span>Appendix<a class="headerlink" href="#appendix" title="Permalink to this headline">#</a></h2>
<section id="useful-definitions-and-concepts">
<span id="diagnostics-appendix-definitions"></span><h3><span class="section-number">6.4.1. </span>Useful definitions and concepts<a class="headerlink" href="#useful-definitions-and-concepts" title="Permalink to this headline">#</a></h3>
<p>Definitions are based on <span id="id38">Molina and Marhuenda [<a class="reference internal" href="#id68" title="Isabel Molina and Yolanda Marhuenda. Sae: an R package for small area estimation. The R Journal, 7(1):81–98, 2015.">2015</a>]</span>, <span id="id39">Ghosh and Rao [<a class="reference internal" href="#id108" title="Malay Ghosh and JNK Rao. Small area estimation: an appraisal. Statistical science, 9(1):55–76, 1994.">1994</a>]</span>, <span id="id40">Rao and Molina [<a class="reference internal" href="#id63" title="JNK Rao and Isabel Molina. Small Area Estimation. John Wiley &amp; Sons, 2nd edition, 2015.">2015</a>]</span>, and <span id="id41">Cochran [<a class="reference internal" href="#id119" title="William G Cochran. Sampling techniques. John Wiley &amp; Sons, 2007.">2007</a>]</span>.</p>
<ul class="simple">
<li><p><strong>Small area:</strong> a domain (area) is regarded as small if the domain-specific sample size is not large enough to support direct estimates of adequate precision. That is to say, a small area is any domain of interest for which direct estimates of adequate precision cannot be produced.</p></li>
<li><p><strong>Large area:</strong> an area or domain where a direct estimate of the parameter of interest for the area has a sufficiently large sample to yield estimates with the desired precision.</p></li>
<li><p><strong>Domain:</strong> domain may be defined by geographic delimitation/territories (e.g., state, county, school district, health service area), socio-demographic groups, or both (e.g., specific age-sex-race group within a large geographic area) or even other types of sub-populations (e.g., set of firms belonging to a census division by industry group).</p></li>
<li><p><strong>Direct (domain) estimators:</strong> estimators based only on the domain-specific sample area. These estimators are typically design-unbiased but tend to have low precision in small areas.</p></li>
<li><p><strong>Indirect (domain) estimators:</strong> estimator that uses information from other areas, under the assumption that there exists some homogeneity relationship between them.</p></li>
<li><p><strong>Target parameter:</strong> indicator to be estimated. Some examples are population mean, proportion, and rate.</p></li>
<li><p><strong>Efficiency/precision:</strong> 1/variance when an estimator is unbiased; 1/MSE otherwise.</p></li>
<li><p><strong>Sampling error:</strong> error from using a sample from the population rather than the whole population.</p></li>
</ul>
<p>For a better understanding of statistical inference, the following concepts/definitions are necessary. Definitions and observations are from <span id="id42">Molina and García-Portugues [<a class="reference internal" href="#id120" title="Isabel Molina and Eduardo García-Portugues. A First Course on Statistical Inference. Bookdown.org, 2021. Accessed: 2010-06-22. URL: https://bookdown.org/egarpor/inference/.">2021</a>]</span> and <span id="id43">Rao and Molina [<a class="reference internal" href="#id63" title="JNK Rao and Isabel Molina. Small Area Estimation. John Wiley &amp; Sons, 2nd edition, 2015.">2015</a>]</span>. Note that, when dealing with SAE, the bias for each area <span class="math notranslate nohighlight">\(c=1,\ldots,C\)</span> is of interest, not the average bias over all the areas.</p>
<ul class="simple">
<li><p><strong>Unbiased estimator:</strong> if an estimator’s bias is equal to zero for all the parameter values. If the expected value of the estimator is equal to the parameter. The estimator <span class="math notranslate nohighlight">\(\hat{\vartheta}_{c}\)</span> of parameter <span class="math notranslate nohighlight">\(\vartheta_{c}\)</span> is unbiased if and only if <span class="math notranslate nohighlight">\(E(\hat{\vartheta}_{c}-\vartheta_{c})=0\)</span></p></li>
<li><p><strong>Estimation error:</strong> the estimation error <span class="math notranslate nohighlight">\(\hat{\vartheta}_{c}-\vartheta_{c}\)</span> is typically different from zero even if the estimator is unbiased. The bias is the mean estimation error: <span class="math notranslate nohighlight">\(Bias(\hat{\vartheta}_{c})=E(\hat{\vartheta}_{c}-\vartheta_{c})\)</span>.</p></li>
<li><p><strong>Mean squared (estimation) error (MSE):</strong> is also called mean squared prediction error (MSPE) or prediction mean squared error (PMSE). <span class="math notranslate nohighlight">\(MSE(\hat{\vartheta}_{c})=E[(\hat{\vartheta}_{c}-\vartheta_{c})^{2}]\)</span>.</p></li>
<li><p><strong>Standard error (SE) of <span class="math notranslate nohighlight">\(\hat{\vartheta}_{c}\)</span>:</strong> is the standard deviation of the sampling distribution of <span class="math notranslate nohighlight">\(\hat{\vartheta}_{c}.\)</span></p></li>
<li><p><strong>Coefficient of variation (CV) of <span class="math notranslate nohighlight">\(\vartheta\)</span>:</strong> <span class="math notranslate nohighlight">\(cv(\hat{\vartheta})=s(\hat{\vartheta})/\vartheta\)</span> is the associated standard error of the estimate over the true value of <span class="math notranslate nohighlight">\(\vartheta\)</span>. It is also known as the relative standard deviation (RSD). The estimated CV is then <span class="math notranslate nohighlight">\(\hat{cv}(\hat{\vartheta})=s(\hat{\vartheta})/\hat{\vartheta}\)</span>.</p></li>
<li><p><strong>Consistency:</strong> when increasing the sample size <span class="math notranslate nohighlight">\(n\)</span>, the probability that the estimator differs from the true value <span class="math notranslate nohighlight">\(\vartheta_{c}\)</span> by more than <span class="math notranslate nohighlight">\(\varepsilon\)</span> vanishes for every <span class="math notranslate nohighlight">\(\varepsilon&gt;0\)</span>.</p></li>
</ul>
</section>
<section id="regression-diagnostics-do-file">
<span id="diagnostics-appendix-regression"></span><h3><span class="section-number">6.4.2. </span>Regression diagnostics do-file<a class="headerlink" href="#regression-diagnostics-do-file" title="Permalink to this headline">#</a></h3>
<p>The following Stata do-file provides an example of how regression diagnostics are often incorporated in the model selection process for small area estimation. Note that the checks are not exhaustive and only serve as a guide for the practitioner.</p>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span><span class="k">clear</span> all <span class="k"></span>
<span class="k">set more</span> off
<span class="cm">/*===============================================================================</span>
<span class="cm">Do-file prepared for SAE Guidelines</span>
<span class="cm">- Regression Diagnostics</span>
<span class="cm">- authors Paul Corral, Minh Nguyen &amp; Sandra Segovia </span>
<span class="cm">*==============================================================================*/</span>

<span class="k">global</span> main       <span class="s">&quot;C:\Users</span><span class="se">\\</span><span class="nv">`c(username)&#39;</span><span class="s">\OneDrive\SAE Guidelines 2021&quot;</span><span class="k"></span>
<span class="k">global</span> section    <span class="s">&quot;</span><span class="vg">$main</span><span class="s">\4_Model_selection&quot;</span>

<span class="k">global</span> data      <span class="s">&quot;</span><span class="vg">$section</span><span class="s">\1_data&quot;</span><span class="k"></span>
<span class="k">global</span> dofile    <span class="s">&quot;</span><span class="vg">$section</span><span class="s">\2_dofiles&quot;</span><span class="k"></span>
<span class="k">global</span> figs      <span class="s">&quot;</span><span class="vg">$section</span><span class="s">\3_figures&quot;</span>

<span class="k">local</span> survey       <span class="s">&quot;</span><span class="vg">$data</span><span class="s">\survey_public.dta&quot;</span>
<span class="c1">*local census      &quot;$main\3_Unit_level\1_data\census_public.dta&quot;</span>

<span class="c1">//global with candidate variables.</span>
<span class="k">global</span> myvar rural  lnhhsize age_hh male_hh  piped_water no_piped_water <span class="cs">///</span>
no_sewage sewage_pub sewage_priv electricity telephone cellphone internet <span class="cs">///</span>
computer washmachine fridge television share_under15 share_elderly <span class="cs">///</span>
share_adult max_tertiary max_secondary HID_<span class="o">*</span> mun_<span class="o">*</span> state_<span class="o">*</span>


<span class="k">version</span> <span class="m">15</span><span class="k"></span>
<span class="k">set</span> seed <span class="m">648743</span>

<span class="k">local</span> graphs graphregion(color(white)) xsize(<span class="m">9</span>) ysize(<span class="m">6</span>) msize(small)
<span class="c1">*===============================================================================</span>
<span class="c1">// End of preamble</span>
<span class="c1">*===============================================================================</span>

<span class="c1">// First part is just as the model selection dofile</span>

<span class="c1">// Load in survey data</span>
<span class="k">use</span> <span class="s">&quot;</span><span class="nv">`survey&#39;</span><span class="s">&quot;</span>,<span class="k"> clear</span>

	<span class="c1">//Remove small incomes affecting model</span>
<span class="k">	drop if</span> e_y<span class="o">&lt;</span><span class="m">1</span>
        
    <span class="c1">// Kernel density plot  for e_y with a normal density overlaid</span>
<span class="k">    kdensity</span> e_y, normal <span class="nv">`graphs&#39;</span>
<span class="k">                  </span>
<span class="k">    graph</span> export <span class="s">&quot;</span><span class="vg">$figs</span><span class="s">\kdensity_e_y.png&quot;</span>,<span class="k"> as</span>(png)<span class="k"> replace</span>    
    
	<span class="c1">//Log shift transformation to approximate normality</span>
<span class="k">	lnskew0</span> double bcy = <span class="nf">exp</span>(lny)
    
    <span class="c1">// Kernel density plot  for lnywith a normal density overlaid</span>
<span class="k">    kdensity</span> lny, normal <span class="nv">`graphs&#39;</span> 
<span class="k">                  </span>
<span class="k">    graph</span> export <span class="s">&quot;</span><span class="vg">$figs</span><span class="s">\kdensity_lny.png&quot;</span>,<span class="k"> as</span>(png)<span class="k"> replace</span>
    
    <span class="c1">// Kernel density plot  for bcy with a normal density overlaid</span>
<span class="k">    kdensity</span> bcy, normal <span class="nv">`graphs&#39;</span>
<span class="k">                  </span>
<span class="k">    graph</span> export <span class="s">&quot;</span><span class="vg">$figs</span><span class="s">\kdensity_bcy.png&quot;</span>,<span class="k"> as</span>(png)<span class="k"> replace</span>
    
    <span class="c1">// removes skeweness from distribution</span>
<span class="k">    sum</span> e_y,<span class="k"> d</span>
<span class="k">	sum</span> lny,<span class="k"> d</span> 
<span class="k">	sum</span> bcy,<span class="k"> d</span>
    
	<span class="c1">// Data has already been cleaned and prepared. Data preparation and the creation</span>
	<span class="c1">// of eligible covariates is of extreme importance. </span>
	<span class="c1">// In this instance, we skip these comparison steps because the sample is </span>
	<span class="c1">// literally a subsample of the census.</span>
<span class="k">	codebook</span> HID <span class="c1">//10 digits, every single one</span>
<span class="k">	codebook</span> HID_mun <span class="c1">//7 digits every single one</span>
	
	<span class="c1">//We rename HID_mun</span>
<span class="k">	rename</span> HID_mun MUN
	<span class="c1">//Drop automobile, it is missing</span>
<span class="k">	drop</span> <span class="o">*</span>automobile<span class="o">*</span> <span class="c1">//all these are missing</span>
	
	<span class="c1">//Check to see if lassoregress is installed, if not install</span>
<span class="k">	cap which</span> lassoregress
<span class="k">	if</span> (_rc)<span class="k"> ssc</span> install elasticregress
	
	<span class="c1">//Model selection - with Lasso	</span>
<span class="k">	gen</span> lnhhsize = <span class="nf">ln</span>(hhsize)
	lassoregress bcy  <span class="vg">$myvar</span> [aw=Whh], lambda1se epsilon(<span class="m">1e-10</span>) numfolds(<span class="m">10</span>)
<span class="k">	local</span> hhvars =<span class="k"> e</span>(varlist_nonzero)
<span class="k">	global</span> postlasso  <span class="nv">`hhvars&#39;</span>
	
	<span class="c1">//Try Henderson III GLS</span>
	sae model h3 bcy <span class="vg">$postlasso</span> [aw=Whh], area(MUN) 
	
	<span class="c1">//Rename HID_mun</span>
<span class="k">	rename</span> MUN HID_mun
	
	<span class="c1">//Loop designed to remove non-significant covariates sequentially</span>
<span class="k">	forval</span> z= <span class="m">0.5</span>(<span class="o">-</span><span class="m">0.05</span>)<span class="m">0.05</span>{
<span class="k">		qui</span>:sae model h3 bcy <span class="nv">`hhvars&#39;</span> [aw=Whh], area(HID_mun) 
<span class="k">		mata</span>: bb=st_matrix(<span class="s">&quot;e(b_gls)&quot;</span>)
<span class="k">		mata</span>:<span class="k"> se</span>=<span class="nf">sqrt</span>(diagonal(st_matrix(<span class="s">&quot;e(V_gls)&quot;</span>)))
<span class="k">		mata</span>: zvals = bb&#39;:<span class="o">/</span>se
<span class="k">		mata</span>: st_matrix(<span class="s">&quot;min&quot;</span>,<span class="nf">min</span>(<span class="nf">abs</span>(zvals)))
<span class="k">		local</span> zv = (<span class="o">-</span>min[<span class="m">1</span>,<span class="m">1</span>])
<span class="k">		if</span> (<span class="m">2</span><span class="o">*</span><span class="nf">normal</span>(<span class="nv">`zv&#39;</span>)<span class="o">&lt;</span><span class="nv">`z&#39;</span>)<span class="k"> exit</span>
<span class="k">	</span>
<span class="k">		foreach</span> x of<span class="k"> varlist</span> <span class="nv">`hhvars&#39;</span>{
<span class="k">			local</span> hhvars1
<span class="k">			qui</span>: sae model h3 bcy <span class="nv">`hhvars&#39;</span> [aw=Whh], area(HID_mun)
<span class="k">			qui</span>:<span class="k"> test</span> <span class="nv">`x&#39;</span> 
<span class="k">			if</span> (<span class="nf">r</span>(p)<span class="o">&gt;</span><span class="nv">`z&#39;</span>){
<span class="k">				local</span> hhvars1
<span class="k">				foreach</span> yy of<span class="k"> local</span> hhvars{
<span class="k">					if</span> (<span class="s">&quot;</span><span class="nv">`yy&#39;</span><span class="s">&quot;</span><span class="o">==</span><span class="s">&quot;</span><span class="nv">`x&#39;</span><span class="s">&quot;</span>)<span class="k"> dis</span> <span class="s">&quot;&quot;</span>
<span class="k">					else local</span> hhvars1 <span class="nv">`hhvars1&#39;</span> <span class="nv">`yy&#39;</span>
				}
			}
<span class="k">			else local</span> hhvars1 <span class="nv">`hhvars&#39;</span>
<span class="k">			local</span> hhvars <span class="nv">`hhvars1&#39;</span>		
		}
	}	
<span class="k">	</span>
<span class="k">	global</span> postsign <span class="nv">`hhvars&#39;</span>

<span class="c1">    </span>
<span class="c1">*===============================================================================</span>
<span class="c1">// Regression diagnostics</span>
<span class="c1">*===============================================================================</span>

<span class="cm">/*This is not a complete diagnostic; it is just a preview, steps &amp; repetitions </span>
<span class="cm">depend on the underlying model. Check all vars, check different transformations, </span>
<span class="cm">do not forget a model for heteroskedasticity (alpha model) if needed */</span>

<span class="k">rename</span> bcy y

<span class="c1">*===============================================================================</span>
<span class="c1">// Collinearity</span>
<span class="c1">*=============================================================================== </span>
<span class="k"> </span>
<span class="k">reg</span> y <span class="vg">$postsign</span> [aw=Whh],r 
    
    <span class="c1">//Check for multicollinearity, and remove highly collinear (VIF&gt;3)</span>
<span class="k">	cap drop</span> touse 	            <span class="c1">//remove vector if it is present to avoid error in next step</span>
<span class="k">	gen</span> touse =<span class="k"> e</span>(sample) 		<span class="c1">//Indicates the observations used</span>
<span class="k">	estat vif</span> 				    <span class="c1">//Variance inflation factor</span>
<span class="k">	local</span> hhvars <span class="vg">$postsign</span>
	
    <span class="c1">//Remove covariates with VIF greater than 3</span>
<span class="k">	mata</span>:<span class="k"> ds</span> = _f_stepvif(<span class="s">&quot;</span><span class="nv">`hhvars&#39;</span><span class="s">&quot;</span>,<span class="s">&quot;Whh&quot;</span>,<span class="m">3</span>,<span class="s">&quot;touse&quot;</span>) 
<span class="k">	global</span> postvif <span class="nv">`vifvar&#39;</span>
	
	<span class="c1">//VIF check</span>
<span class="k">	reg</span> y <span class="vg">$postvif</span> [aw=Whh], r
<span class="k">	vif</span>
    
    <span class="c1">// For ilustration</span>
    <span class="c1">// Henderson III GLS - model post removal of non-significant</span>
    sae model h3 y <span class="vg">$postsign</span> [aw=Whh], area(HID_mun) 
    
    <span class="c1">// Henderson III GLS - model post removal of non-significant</span>
	sae model h3 y <span class="vg">$postvif</span> [aw=Whh], area(HID_mun) 
<span class="c1">    </span>
<span class="c1">*===============================================================================</span>
<span class="c1">// Residual Analysis</span>
<span class="c1">*=============================================================================== </span>

<span class="c1">// Linearity </span>

<span class="k">    reg</span> y <span class="vg">$postsign</span>, r
    
    <span class="c1">// Augmented component-plus-residual plot; works better than the                            </span>
    <span class="c1">// component-plus-residual plot for identifying nonlinearities in the data.</span>
<span class="k">    acprplot</span> age_hh,<span class="k"> lowess</span> lsopts(bwidth(<span class="m">1</span>)) <span class="nv">`graphs&#39;</span> 
<span class="k">    </span>
<span class="k">    graph</span> export <span class="s">&quot;</span><span class="vg">$figs</span><span class="s">\acprplot_age_hh.png&quot;</span>,<span class="k"> as</span>(png)<span class="k"> replace</span>
   
    <span class="c1">// Kernel density plot  for log_age_hh with a normal density overlaid</span>
<span class="k">    kdensity</span> age_hh, normal <span class="nv">`graphs&#39;</span> 
<span class="k">                  </span>
<span class="k">    graph</span> export <span class="s">&quot;</span><span class="vg">$figs</span><span class="s">\kdensity_age_hh.png&quot;</span>,<span class="k"> as</span>(png)<span class="k"> replace</span>
   
    <span class="c1">// log transformation</span>
<span class="k">    gen</span> log_age_hh =<span class="nf">log</span>(age_hh)
    
    <span class="c1">// Kernel density plot  for log_age_hh with a normal density overlaid</span>
<span class="k">    kdensity</span> log_age_hh, normal <span class="nv">`graphs&#39;</span> 
<span class="k">                  </span>
<span class="k">    graph</span> export <span class="s">&quot;</span><span class="vg">$figs</span><span class="s">\kdensity_log_age_hh.png&quot;</span>,<span class="k"> as</span>(png)<span class="k"> replace</span>
    

    
<span class="c1">// Normality </span>
<span class="k"> </span>
<span class="k">    reg</span> y <span class="vg">$postvif</span> [aw=Whh],r
<span class="k">    predict</span> resid, resid
    
    <span class="c1">// Kernel density plot  for residuals with a normal density overlaid</span>
<span class="k">    kdensity</span> resid, normal <span class="nv">`graphs&#39;</span> 
<span class="k">                  </span>
<span class="k">    graph</span> export <span class="s">&quot;</span><span class="vg">$figs</span><span class="s">\kdensity_resid.png&quot;</span>,<span class="k"> as</span>(png)<span class="k"> replace</span>
    
    <span class="c1">// Standardized normal probability </span>
<span class="k">    pnorm</span> resid , <span class="nv">`graphs&#39;</span> 
<span class="k">                  </span>
<span class="k">    graph</span> export <span class="s">&quot;</span><span class="vg">$figs</span><span class="s">\pnorm.png&quot;</span>,<span class="k"> as</span>(png)<span class="k"> replace</span>
    
    <span class="c1">// Quantiles of a variable against the quantiles of a normal distribution</span>
<span class="k">    qnorm</span> resid , <span class="nv">`graphs&#39;</span> 
<span class="k">                  </span>
<span class="k">    graph</span> export <span class="s">&quot;</span><span class="vg">$figs</span><span class="s">\qnorm.png&quot;</span>,<span class="k"> as</span>(png)<span class="k"> replace</span>
    
    <span class="c1">// Numerical Test:  Shapiro-Wilk W test for normal data</span>
<span class="k">    swilk</span> resid
    
    
<span class="c1">// Heteroscedasticity </span>

<span class="k">    reg</span> y <span class="vg">$postvif</span>

    <span class="c1">// Residuals vs fitted values with a reference line at y=0</span>
<span class="k">    rvfplot</span> , yline(<span class="m">0</span>)  <span class="nv">`graphs&#39;</span> 
<span class="k">                                         </span>
<span class="k">    graph</span> export <span class="s">&quot;</span><span class="vg">$figs</span><span class="s">\rvfplot_1.png&quot;</span>,<span class="k"> as</span>(png)<span class="k"> replace</span>

    <span class="c1">// Cameron &amp; Trivedi&#39;s decomposition of IM-test / White test</span>
<span class="k">    estat imtest</span>
    
    <span class="c1">// Breusch-Pagan / Cook-Weisberg test for heteroskedasticity</span>
<span class="k">    estat hettest</span>

<span class="c1">    </span>
<span class="c1">*===============================================================================</span>
<span class="c1">// Influence Analysis</span>
<span class="c1">*===============================================================================     </span>

<span class="c1">// Graphic method &lt; before &gt;</span>

<span class="k">    reg</span> y <span class="vg">$postvif</span> [aw=Whh]
    
    <span class="c1">// residuals vs fitted vals</span>
<span class="k">    rvfplot</span> , yline(<span class="m">0</span>)  <span class="nv">`graphs&#39;</span> 
<span class="k">                                         </span>
<span class="k">    graph</span> export <span class="s">&quot;</span><span class="vg">$figs</span><span class="s">\rvfplot_2.png&quot;</span>,<span class="k"> as</span>(png)<span class="k"> replace</span>
    
    
    <span class="c1">// normalized residual squared vs leverage</span>
<span class="k">    lvr2plot</span> ,  <span class="nv">`graphs&#39;</span> 
<span class="k">                                         </span>
<span class="k">    graph</span> export <span class="s">&quot;</span><span class="vg">$figs</span><span class="s">\lvr2plot.png&quot;</span>,<span class="k"> as</span>(png)<span class="k"> replace</span>


<span class="c1">// Numerical method</span>


<span class="c1">// Step 1</span>

<span class="k">    reg</span> y <span class="vg">$postvif</span>	
    
    <span class="c1">// After regression without weights...</span>
    
    <span class="c1">// Calculate measures to identify influential observations</span>
<span class="k">	predict</span> cdist, cooksd      <span class="c1">// calculates the Cook&#39;s D influence statistic</span>
<span class="k">	predict</span> rstud, rstudent    <span class="c1">// calculates the Studentized (jackknifed) residuals</span>

<span class="c1">// Step 2</span>

<span class="k">    reg</span> y <span class="vg">$postvif</span> [aw=Whh]
    
    <span class="c1">// Predict leverage and residuals</span>
<span class="k">	predict</span> lev,<span class="k"> leverage</span>  <span class="c1">// calculates the diagonal elements of the </span>
                           <span class="c1">// projection (&quot;hat&quot;) matrix</span>
<span class="k">	predict</span> r, resid       <span class="c1">// calculates the residuals</span>

    <span class="c1">// Save useful locals</span>
<span class="k">    local</span> myN=<span class="nf">e</span>(N)              <span class="c1">// # observations              </span>
<span class="k">	local</span> myK=<span class="nf">e</span>(rank)           <span class="c1">// rank or k</span>
<span class="k">    local</span> KK =<span class="nf">e</span>(df_m)           <span class="c1">// degrees of freedom (k-1)</span>
<span class="k">    </span>
<span class="k">    sum</span> cdist,<span class="k"> d</span>        
<span class="c1">    * return list</span>
<span class="k">	local</span> max = <span class="nf">r</span>(max)          <span class="c1">// max value</span>
<span class="k">	local</span> p99 = <span class="nf">r</span>(p99)		    <span class="c1">// percentile 99</span>
 
 <span class="c1">// Step 3 </span>
    
    <span class="c1">// For ilustration...</span>
    <span class="c1">// We have influential data points...</span>
<span class="k">    reg</span> lny <span class="vg">$postvif</span><span class="k"> if</span> cdist<span class="o">&lt;</span><span class="m">4</span><span class="o">/</span><span class="nv">`myN&#39;</span> [aw=Whh]       
<span class="k">    reg</span> lny <span class="vg">$postvif</span><span class="k"> if</span> cdist<span class="o">&lt;</span><span class="nv">`p99&#39;</span>   [aw=Whh]
<span class="k">	reg</span> lny <span class="vg">$postvif</span><span class="k"> if</span> cdist<span class="o">&lt;</span><span class="nv">`max&#39;</span>   [aw=Whh]         

    <span class="c1">// Identified influential / outliers observations</span>
<span class="k">    gen</span> nogo = <span class="nf">abs</span>(rstud)<span class="o">&gt;</span><span class="m">2</span> <span class="o">&amp;</span> cdist<span class="o">&gt;</span><span class="m">4</span><span class="o">/</span><span class="nv">`myN&#39;</span> <span class="o">&amp;</span> lev<span class="o">&gt;</span>(<span class="m">2</span><span class="o">*</span><span class="nv">`myK&#39;</span><span class="o">+</span><span class="m">2</span>)<span class="o">/</span><span class="nv">`myN&#39;</span>
<span class="k">    </span>
<span class="k">    count if</span> nogo<span class="o">==</span><span class="m">1</span>        <span class="c1">// these are the obs that we want to eliminate</span>
    
 
<span class="c1">// Graphic method &lt; after &gt;</span>

<span class="k">    reg</span> y <span class="vg">$postvif</span> [aw=Whh]<span class="k"> if</span> nogo<span class="o">==</span><span class="m">0</span>
    
    <span class="c1">// residuals vs fitted vals</span>
<span class="k">    rvfplot</span> , yline(<span class="m">0</span>)  <span class="nv">`graphs&#39;</span> 
<span class="k">                                         </span>
<span class="k">    graph</span> export <span class="s">&quot;</span><span class="vg">$figs</span><span class="s">\rvfplot_2_after.png&quot;</span>,<span class="k"> as</span>(png)<span class="k"> replace</span>
    
    
    <span class="c1">// normalized residual squared vs leverage</span>
<span class="k">    lvr2plot</span> ,        <span class="nv">`graphs&#39;</span> 
<span class="k">                                         </span>
<span class="k">    graph</span> export <span class="s">&quot;</span><span class="vg">$figs</span><span class="s">\lvr2plot_after.png&quot;</span>,<span class="k"> as</span>(png)<span class="k"> replace</span>
<span class="c1"> </span>
<span class="c1">    </span>
<span class="c1">*===============================================================================</span>
<span class="c1">// Model Specification tests</span>
<span class="c1">*===============================================================================</span>
<span class="k">   </span>
<span class="k">   reg</span> y <span class="vg">$postvif</span> 
      
<span class="c1">// Wald test for ommited vars &lt; will compare with previous regression&gt;   </span>
<span class="k">   boxcox</span> y <span class="vg">$postvif</span>, nolog <span class="c1">// Box - Cox model </span>

   
<span class="c1">// Functional form of the conditional mean </span>
<span class="k">    reg</span> y <span class="vg">$postvif</span> 

<span class="k">    estat ovtest</span> <span class="c1">// performs regression specification error test (RESET) for omitted variables </span>

<span class="k">    linktest</span> <span class="c1">//performs a link test for model specification</span>

<span class="c1">// Omnibus tests + Heteroscedasticity tests </span>
<span class="k">    reg</span> y <span class="vg">$postvif</span> 
<span class="k">    </span>
<span class="k">    estat imtest</span>   <span class="c1">// Cameron &amp; Trivedi&#39;s decomposition of IM-test / White test</span>
<span class="k">        </span>
<span class="k">    estat hettest</span> <span class="c1">// Breusch-Pagan / Cook-Weisberg test for Heteroscedasticity </span>


<span class="c1">*===============================================================================</span>
<span class="c1">// Diagnostics for random effects</span>
<span class="c1">*===============================================================================</span>

<span class="c1">// Multilevel mixed-effects linear regression</span>
    mixed y <span class="vg">$postvif</span> || state:, reml
<span class="k">    </span>
<span class="k">    predict</span> res, residual
<span class="k">    </span>
<span class="k">    predict</span> eta, reffects

<span class="k">    bysort</span> state:<span class="k"> gen</span> first=_n
    
    <span class="c1">// For state == 1</span>
<span class="k">    qnorm</span> eta<span class="k"> if</span> first<span class="o">==</span><span class="m">1</span> , <span class="nv">`graphs&#39;</span> 
<span class="k">                     </span>
<span class="k">    graph</span> export <span class="s">&quot;</span><span class="vg">$figs</span><span class="s">\qnorm_mixed_1.png&quot;</span>,<span class="k"> as</span>(png)<span class="k"> replace</span>


<span class="c1">// Quantiles of a variable against the quantiles of a normal distribution</span>
<span class="k">    qnorm</span> res , <span class="nv">`graphs&#39;</span> 
<span class="k">                  </span>
<span class="k">    graph</span> export <span class="s">&quot;</span><span class="vg">$figs</span><span class="s">\qnorm_mixed.png&quot;</span>,<span class="k"> as</span>(png)<span class="k"> replace</span>
    
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>And for the figures</p>
</div>
<div class="highlight-stata notranslate"><div class="highlight"><pre><span></span><span class="k">set more</span> off<span class="k"></span>
<span class="k">clear</span> all

<span class="c1">*===============================================================================</span>
<span class="c1">//Macros for inputs to the simulation</span>
<span class="c1">*===============================================================================</span>

<span class="c1">// Replication of Molina and Rao&#39;s 2010 simulation - SAE Guidelines</span>
<span class="k">global</span> main    <span class="s">&quot;C:\Users</span><span class="se">\\</span><span class="nv">`c(username)&#39;</span><span class="s">\OneDrive\WPS_2020</span><span class="se">\&quot;</span><span class="k"></span>
<span class="k">global</span> dpath   <span class="s">&quot;</span><span class="vg">$main</span><span class="s">\1.data&quot;</span><span class="k"></span>
<span class="k">global</span> simdata <span class="s">&quot;</span><span class="vg">$dpath</span><span class="se">\&quot;</span><span class="k"></span>
<span class="k">global</span> thedo   <span class="s">&quot;</span><span class="vg">$main</span><span class="s">\2.dofiles\Model sim</span><span class="se">\&quot;</span><span class="k"></span>
<span class="k">global</span> XL 	   <span class="s">&quot;</span><span class="vg">$main</span><span class="s">\SAE result summary.xlsx&quot;</span>

<span class="k">	local</span> direct           Direct
<span class="k">	local</span> h3area		   Unit<span class="o">-</span>Context CEB
<span class="k">	local</span> true             True
<span class="k">	local</span> ellold           ELL <span class="o">-</span> with context (collapsed)
<span class="k">	local</span> h3eb             CensusEB
<span class="k">	local</span> h3ebc            CensusEB <span class="o">-</span> with context (collapsed)
<span class="k">	local</span> ell			   ELL <span class="o">-</span> with context (New Sim)	
<span class="k">	local</span> twofold          Twofold nested<span class="k"> error</span> CEB
<span class="k">	local</span> twofoldA         U<span class="o">-</span>C twofold nested<span class="k"> error</span> CEB


<span class="k">	</span>
<span class="k">	local</span> direct_s           ms(<span class="o">+</span>)
<span class="k">	local</span> h3area_s		     mcolor(black) msize(small) msymbol(O)
<span class="k">	local</span> ellold_s           mcolor(gray) msize(small) msymbol(X)
<span class="k">	local</span> h3eb_s             mcolor(green) msize(small) msymbol(t)
<span class="k">	local</span> h3ebc_s            mcolor(green) msize(small) msymbol(Sh)
	<span class="c1">//local ell_s				 mcolor(gray)  msiz(vsmall) msymbol(Th)</span>
<span class="k">	local</span> twofold_s            mcolor(red)  msiz(small) msymbol(Oh)
<span class="k">	local</span> twofoldA_s           mcolor(blue)  msiz(vsmall) msymbol(D)

<span class="c1">// Replication of Molina and Rao&#39;s 2010 simulation - SAE Guidelines</span>
<span class="k">local</span> indis fgt0 fgt1 fgt2 Mean<span class="k"></span>
<span class="k">local</span> simres1 h3ebc h3eb direct h3area ellold ell twofold twofoldA<span class="k"></span>
<span class="k">local</span> simres2 h3ebc h3eb direct h3area ellold ell twofold twofoldA<span class="k"></span>
<span class="k">local</span> simres3 h3ebc h3eb direct h3area ellold ell twofold twofoldA<span class="k"></span>
<span class="k">local</span> simres4 h3ebc h3eb direct h3area ellold ell twofold twofoldA

<span class="c1">*===============================================================================</span>
<span class="c1">// Figures for models</span>
<span class="c1">*===============================================================================</span>



<span class="k">foreach</span> i<span class="k"> in</span> Mean fgt0 fgt1 fgt2{
<span class="k">	foreach</span> sim<span class="k"> in</span> <span class="m">1</span> <span class="m">2</span> <span class="m">3</span> <span class="m">4</span>{
<span class="k">		use</span> <span class="s">&quot;</span><span class="vg">$simdata</span><span class="s">\accumulate_results.dta&quot;</span>,<span class="k"> clear</span>
<span class="k">		lab var</span> area <span class="s">&quot;Area&quot;</span>
<span class="k">			</span>
<span class="k">		keep if</span> simulation<span class="o">==</span><span class="nv">`sim&#39;</span>
<span class="k">		replace</span> <span class="nv">`i&#39;</span>_bias=<span class="nv">`i&#39;</span>_bias<span class="o">*</span><span class="m">100</span>
<span class="k">		replace</span> <span class="nv">`i&#39;</span>_mse=<span class="nv">`i&#39;</span>_mse<span class="o">*</span><span class="m">10000</span>
<span class="k">		local</span> forlab = upper(<span class="s">&quot;</span><span class="nv">`i&#39;</span><span class="s">&quot;</span>)
<span class="k">		lab var</span> <span class="nv">`i&#39;</span>_bias <span class="s">&quot;Bias </span><span class="nv">`forlab&#39;</span><span class="s"> (x100)&quot;</span>
<span class="k">		lab var</span> <span class="nv">`i&#39;</span>_mse <span class="s">&quot;MSE </span><span class="nv">`forlab&#39;</span><span class="s"> (x10000)&quot;</span>
<span class="k">		</span>
<span class="k">		foreach</span> b<span class="k"> in</span> bias mse{		
<span class="k">			twoway scatter</span> <span class="nv">`i&#39;</span>_<span class="nv">`b&#39;</span> area<span class="k"> if</span> method<span class="o">==</span><span class="s">&quot;direct&quot;</span>,<span class="k"> sort</span> <span class="nv">`direct_s&#39;</span> || <span class="cs">///</span>
<span class="k">			scatter</span> <span class="nv">`i&#39;</span>_<span class="nv">`b&#39;</span> area<span class="k"> if</span> method<span class="o">==</span><span class="s">&quot;twofold&quot;</span>,<span class="k"> sort</span> <span class="nv">`twofold_s&#39;</span> || <span class="cs">///</span>
<span class="k">			scatter</span> <span class="nv">`i&#39;</span>_<span class="nv">`b&#39;</span> area<span class="k"> if</span> method<span class="o">==</span><span class="s">&quot;h3eb&quot;</span>,<span class="k"> sort</span> <span class="nv">`h3eb_s&#39;</span> || <span class="cs">///</span>
<span class="k">			scatter</span> <span class="nv">`i&#39;</span>_<span class="nv">`b&#39;</span> area<span class="k"> if</span> method<span class="o">==</span><span class="s">&quot;h3ebc&quot;</span>,<span class="k"> sort</span> <span class="nv">`h3ebc_s&#39;</span> || <span class="cs">///</span>
<span class="k">			scatter</span> <span class="nv">`i&#39;</span>_<span class="nv">`b&#39;</span> area<span class="k"> if</span> method<span class="o">==</span><span class="s">&quot;ellold&quot;</span>,<span class="k"> sort</span> <span class="nv">`ellold_s&#39;</span> || <span class="cs">///</span>
<span class="k">			scatter</span> <span class="nv">`i&#39;</span>_<span class="nv">`b&#39;</span> area<span class="k"> if</span> method<span class="o">==</span><span class="s">&quot;h3area&quot;</span>,<span class="k"> sort</span> <span class="nv">`h3area_s&#39;</span> || <span class="cs">///</span>
<span class="k">			scatter</span> <span class="nv">`i&#39;</span>_<span class="nv">`b&#39;</span> area<span class="k"> if</span> method<span class="o">==</span><span class="s">&quot;twofoldA&quot;</span>,<span class="k"> sort</span> <span class="nv">`twofoldA_s&#39;</span> ||, <span class="cs">///</span>
			legend(order(<span class="m">1</span> <span class="s">&quot;</span><span class="nv">`direct&#39;</span><span class="s">&quot;</span> <span class="m">2</span> <span class="s">&quot;</span><span class="nv">`twofold&#39;</span><span class="s">&quot;</span> <span class="m">3</span> <span class="s">&quot;</span><span class="nv">`h3eb&#39;</span><span class="s">&quot;</span> <span class="m">4</span> <span class="s">&quot;</span><span class="nv">`h3ebc&#39;</span><span class="s">&quot;</span> <span class="m">5</span> <span class="s">&quot;</span><span class="nv">`ell&#39;</span><span class="s">&quot;</span> <span class="m">6</span> <span class="s">&quot;</span><span class="nv">`h3area&#39;</span><span class="s">&quot;</span> <span class="m">7</span> <span class="s">&quot;</span><span class="nv">`twofoldA&#39;</span><span class="s">&quot;</span>)) graphregion(color(white))	
<span class="k">			</span>
<span class="k">			graph</span> export <span class="s">&quot;</span><span class="vg">$main</span><span class="s">/4.figures//</span><span class="nv">`b&#39;</span><span class="s">_sim</span><span class="nv">`sim&#39;</span><span class="s">_</span><span class="nv">`i&#39;</span><span class="s">.png&quot;</span>,<span class="k"> replace as</span>(png)
		} <span class="c1">// End bias/mse</span>
	} <span class="c1">//End sim</span>
} <span class="c1">//End measures</span>
		sss
<span class="c1">//Question, how does the estimated MSE look like when collapsing H3EB to the next level?</span>
<span class="k">use</span> <span class="s">&quot;</span><span class="vg">$simdata</span><span class="s">\accumulate_results.dta&quot;</span>,<span class="k"> clear</span>

<span class="k">foreach</span> x of<span class="k"> varlist</span> fgt0_ms<span class="o">*</span> fgt1_ms<span class="o">*</span> fgt2_ms<span class="o">*</span> Mean_ms<span class="o">*</span>{
<span class="k">	replace</span> <span class="nv">`x&#39;</span> = <span class="nf">sqrt</span>(<span class="nv">`x&#39;</span>)
}<span class="k"></span>
<span class="k">foreach</span> x of<span class="k"> varlist</span> fgt0_bias<span class="o">*</span> fgt1_bias<span class="o">*</span> fgt2_bias<span class="o">*</span> Mean_bias<span class="o">*</span>{
<span class="k">	gen</span> <span class="nv">`x&#39;</span>_abs = <span class="nf">abs</span>(<span class="nv">`x&#39;</span>)
}


sp_groupfunction,<span class="k"> mean</span>( fgt0_bias_rel_abs fgt1_bias_rel_abs fgt2_bias_rel_abs fgt0_mse_rel fgt1_mse_rel fgt2_mse_rel Mean_bias_rel_abs Mean_mse_rel  fgt0_bias_abs fgt1_bias_abs fgt2_bias_abs Mean_bias_abs <span class="o">*</span>_mse)<span class="k"> by</span>(method sim)


<span class="k">gen</span> concat = method<span class="o">+</span><span class="s">&quot;_&quot;</span><span class="o">+</span>variable<span class="o">+</span><span class="s">&quot;_&quot;</span><span class="o">+</span><span class="nf">string</span>(sim)<span class="k"></span>
<span class="k">order</span> concat, first

export excel using <span class="s">&quot;</span><span class="vg">$XL</span><span class="s">&quot;</span>, sheet(result) sheetreplace first(var)
</pre></div>
</div>
</section>
</section>
<section id="references">
<span id="diagnostics-ref"></span><h2><span class="section-number">6.5. </span>References<a class="headerlink" href="#references" title="Permalink to this headline">#</a></h2>
<div class="docutils container" id="id44">
<dl class="citation">
<dt class="label" id="id128"><span class="brackets"><a class="fn-backref" href="#id30">CT05</a></span></dt>
<dd><p>A Colin Cameron and Pravin K Trivedi. <em>Microeconometrics: methods and applications</em>. Cambridge university press, 2005. ISBN 978-0-521-84805-3.</p>
</dd>
<dt class="label" id="id119"><span class="brackets"><a class="fn-backref" href="#id41">Coc07</a></span></dt>
<dd><p>William G Cochran. <em>Sampling techniques</em>. John Wiley &amp; Sons, 2007.</p>
</dd>
<dt class="label" id="id139"><span class="brackets"><a class="fn-backref" href="#id25">Coo77</a></span></dt>
<dd><p>R Dennis Cook. Detection of influential observation in linear regression. <em>Technometrics</em>, 19(1):15–18, 1977.</p>
</dd>
<dt class="label" id="id112"><span class="brackets"><a class="fn-backref" href="#id5">CHMM21</a></span></dt>
<dd><p>Paul Corral, Kristen Himelein, Kevin McGee, and Isabel Molina. A map of the poor or a poor map? <em>Mathematics</em>, 2021. URL: <a class="reference external" href="https://www.mdpi.com/2227-7390/9/21/2780">https://www.mdpi.com/2227-7390/9/21/2780</a>, <a class="reference external" href="https://doi.org/10.3390/math9212780">doi:10.3390/math9212780</a>.</p>
</dd>
<dt class="label" id="id90"><span class="brackets">CMN21</span><span class="fn-backref">(<a href="#id11">1</a>,<a href="#id150">2</a>)</span></dt>
<dd><p>Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. <em>Journal of Statistical Computation and Simulation</em>, 91(16):3304–3357, 2021. URL: <a class="reference external" href="https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460">https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460</a>, <a class="reference external" href="https://doi.org/10.1080/00949655.2021.1926460">doi:10.1080/00949655.2021.1926460</a>.</p>
</dd>
<dt class="label" id="id52"><span class="brackets">ELL03</span><span class="fn-backref">(<a href="#id3">1</a>,<a href="#id17">2</a>)</span></dt>
<dd><p>Chris Elbers, Jean O Lanjouw, and Peter Lanjouw. Micro–level estimation of poverty and inequality. <em>Econometrica</em>, 71(1):355–364, 2003.</p>
</dd>
<dt class="label" id="id64"><span class="brackets"><a class="fn-backref" href="#id151">ELL02</a></span></dt>
<dd><p>Chris Elbers, Jean Olson Lanjouw, and Peter Lanjouw. Micro-level estimation of welfare. <em>World Bank Policy Research Working Paper</em>, 2002.</p>
</dd>
<dt class="label" id="id108"><span class="brackets"><a class="fn-backref" href="#id39">GR94</a></span></dt>
<dd><p>Malay Ghosh and JNK Rao. Small area estimation: an appraisal. <em>Statistical science</em>, 9(1):55–76, 1994.</p>
</dd>
<dt class="label" id="id138"><span class="brackets">JWHT13</span><span class="fn-backref">(<a href="#id20">1</a>,<a href="#id21">2</a>,<a href="#id22">3</a>)</span></dt>
<dd><p>Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani. <em>An introduction to statistical learning</em>. Volume 112. Springer, 2013. ISBN 978-1-0716-1418-1. URL: <a class="reference external" href="https://link.springer.com/book/10.1007/978-1-0716-1418-1?noAccess=true">https://link.springer.com/book/10.1007/978-1-0716-1418-1?noAccess=true</a>.</p>
</dd>
<dt class="label" id="id143"><span class="brackets"><a class="fn-backref" href="#id8">LS15</a></span></dt>
<dd><p>Partha Lahiri and Jiraphan Suntornchost. Variable selection for linear mixed models with applications in small area estimation. <em>Sankhya B</em>, 77(2):312–320, 2015.</p>
</dd>
<dt class="label" id="id106"><span class="brackets">MMMR17</span><span class="fn-backref">(<a href="#id36">1</a>,<a href="#id37">2</a>)</span></dt>
<dd><p>Yolanda Marhuenda, Isabel Molina, Domingo Morales, and JNK Rao. Poverty mapping in small areas under a twofold nested error regression model. <em>Journal of the Royal Statistical Society: Series A (Statistics in Society)</em>, 180(4):1111–1136, 2017. <a class="reference external" href="https://doi.org/10.1111/rssa.12306">doi:10.1111/rssa.12306</a>.</p>
</dd>
<dt class="label" id="id120"><span class="brackets"><a class="fn-backref" href="#id42">MGarciaP21</a></span></dt>
<dd><p>Isabel Molina and Eduardo García-Portugues. <em>A First Course on Statistical Inference</em>. Bookdown.org, 2021. Accessed: 2010-06-22. URL: <a class="reference external" href="https://bookdown.org/egarpor/inference/">https://bookdown.org/egarpor/inference/</a>.</p>
</dd>
<dt class="label" id="id68"><span class="brackets"><a class="fn-backref" href="#id38">MM15</a></span></dt>
<dd><p>Isabel Molina and Yolanda Marhuenda. Sae: an R package for small area estimation. <em>The R Journal</em>, 7(1):81–98, 2015.</p>
</dd>
<dt class="label" id="id67"><span class="brackets"><a class="fn-backref" href="#id4">MR10</a></span></dt>
<dd><p>Isabel Molina and JNK Rao. Small area estimation of poverty indicators. <em>Canadian Journal of Statistics</em>, 38(3):369–385, 2010.</p>
</dd>
<dt class="label" id="id136"><span class="brackets">MohringSC13</span><span class="fn-backref">(<a href="#id27">1</a>,<a href="#id29">2</a>)</span></dt>
<dd><p>Katja Möhring and Alexander Schmidt-Catran. Mlt: stata module to provide multilevel tools. 2013. URL: <a class="reference external" href="https://econpapers.repec.org/software/bocbocode/s457577.htm">https://econpapers.repec.org/software/bocbocode/s457577.htm</a>.</p>
</dd>
<dt class="label" id="id137"><span class="brackets"><a class="fn-backref" href="#id6">Pfe13</a></span></dt>
<dd><p>Danny Pfeffermann. New important developments in small area estimation. <em>Statistical Science</em>, 28(1):40–68, 2013.</p>
</dd>
<dt class="label" id="id63"><span class="brackets">RM15</span><span class="fn-backref">(<a href="#id2">1</a>,<a href="#id7">2</a>,<a href="#id19">3</a>,<a href="#id26">4</a>,<a href="#id34">5</a>,<a href="#id40">6</a>,<a href="#id43">7</a>)</span></dt>
<dd><p>JNK Rao and Isabel Molina. <em>Small Area Estimation</em>. John Wiley &amp; Sons, 2nd edition, 2015.</p>
</dd>
<dt class="label" id="id127"><span class="brackets"><a class="fn-backref" href="#id33">R+91</a></span></dt>
<dd><p>George K Robinson and others. That blup is a good thing: the estimation of random effects. <em>Statistical science</em>, 6(1):15–32, 1991.</p>
</dd>
<dt class="label" id="id105"><span class="brackets"><a class="fn-backref" href="#id10">TZL+18</a></span></dt>
<dd><p>Nikos Tzavidis, Li-Chun Zhang, Angela Luna, Timo Schmid, and Natalia Rojas-Perilla. From start to finish: a framework for the production of small area official statistics. <em>Journal of the Royal Statistical Society: Series A (Statistics in Society)</em>, 181(4):927–979, 2018.</p>
</dd>
<dt class="label" id="id132"><span class="brackets">WWG14</span><span class="fn-backref">(<a href="#id32">1</a>,<a href="#id35">2</a>)</span></dt>
<dd><p>Brady T West, Kathleen B Welch, and Andrzej T Galecki. <em>Linear mixed models: a practical guide using statistical software</em>. Chapman and Hall/CRC, 2nd edition, 2014. URL: <a class="reference external" href="https://www.taylorfrancis.com/books/mono/10.1201/b17198/linear-mixed-models-brady-west-kathleen-welch-andrzej-galecki">https://www.taylorfrancis.com/books/mono/10.1201/b17198/linear-mixed-models-brady-west-kathleen-welch-andrzej-galecki</a>, <a class="reference external" href="https://doi.org/10.1201/b17198">doi:10.1201/b17198</a>.</p>
</dd>
</dl>
</div>
</section>
<section id="notes">
<span id="diagnostics-notes"></span><h2><span class="section-number">6.6. </span>Notes<a class="headerlink" href="#notes" title="Permalink to this headline">#</a></h2>
<hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="id147"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Except for the gradient boosting application shown.</p>
</dd>
<dt class="label" id="id148"><span class="brackets"><a class="fn-backref" href="#id9">2</a></span></dt>
<dd><p>The authors define the approximation error as the difference between standard variable selection criterion and the ideal variable selection criterion, where it is assumed that the direct estimates are not measured with noise.</p>
</dd>
<dt class="label" id="id149"><span class="brackets"><a class="fn-backref" href="#id12">3</a></span></dt>
<dd><p>See <span id="id150">Corral <em>et al.</em> [<a class="reference internal" href="#id90" title="Paul Corral, Isabel Molina, and Minh Cong Nguyen. Pull your small area estimates up by the bootstraps. Journal of Statistical Computation and Simulation, 91(16):3304–3357, 2021. URL: https://www.tandfonline.com/doi/abs/10.1080/00949655.2021.1926460, doi:10.1080/00949655.2021.1926460.">2021</a>]</span> for a detailed discussion on the previous ELL bootstrap. Also see <span id="id151">Elbers <em>et al.</em> [<a class="reference internal" href="#id64" title="Chris Elbers, Jean Olson Lanjouw, and Peter Lanjouw. Micro-level estimation of welfare. World Bank Policy Research Working Paper, 2002.">2002</a>]</span> for the sources of noise in their algorithm.</p>
</dd>
<dt class="label" id="id152"><span class="brackets"><a class="fn-backref" href="#id15">4</a></span></dt>
<dd><p>LMM are an extension of general linear models which include both fixed and random effects.</p>
</dd>
<dt class="label" id="id153"><span class="brackets"><a class="fn-backref" href="#id16">5</a></span></dt>
<dd><p>These assumptions are similar to the ones of a classic linear regression, but adding those for the random effects inclusion.</p>
</dd>
<dt class="label" id="id154"><span class="brackets"><a class="fn-backref" href="#id18">6</a></span></dt>
<dd><p>Many of the commands provided in the following subsections can be easily reviewed by typing <code class="docutils literal notranslate"><span class="pre">help</span> <span class="pre">regress</span> <span class="pre">postestimation</span></code> in Stata’s command window.</p>
</dd>
<dt class="label" id="id155"><span class="brackets"><a class="fn-backref" href="#id23">7</a></span></dt>
<dd><p>The Mata function is included in Stata’s <code class="docutils literal notranslate"><span class="pre">sae</span></code> package.</p>
</dd>
<dt class="label" id="id156"><span class="brackets"><a class="fn-backref" href="#id24">8</a></span></dt>
<dd><p>The specific threshold value is up to the practitioner, although it is not recommended to use thresholds above 10.</p>
</dd>
<dt class="label" id="id157"><span class="brackets"><a class="fn-backref" href="#id28">9</a></span></dt>
<dd><p><a class="reference external" href="https://www.stata.com/meeting/germany12/abstracts/desug12_moehring.pdf">https://www.stata.com/meeting/germany12/abstracts/desug12_moehring.pdf</a></p>
</dd>
<dt class="label" id="id158"><span class="brackets"><a class="fn-backref" href="#id31">10</a></span></dt>
<dd><p>Much of the information in this section is borrowed from <span id="id159"></span>; <a class="reference external" href="https://stats.idre.ucla.edu/stata/webbooks/reg/chapter2/stata-webbooksregressionwith-statachapter-2-regression-diagnostics/">https://stats.idre.ucla.edu/stata/webbooks/reg/chapter2/stata-webbooksregressionwith-statachapter-2-regression-diagnostics/</a></p>
</dd>
</dl>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="05_off-census.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">5. </span>Poverty Mapping in Off-Census Years</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="07_conclusion.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">7. </span>Concluding Remarks</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Paul Corral, Isabel Molina, Alexandru Cojocaru, and Sandra Segovia<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>