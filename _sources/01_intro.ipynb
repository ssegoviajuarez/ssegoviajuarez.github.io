{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c1dfbd7-a7d9-46d7-8820-9107f6b99712",
   "metadata": {},
   "source": [
    "(intro)=\n",
    "# Small Area Estimation for Poverty Mapping\n",
    "<hr style=\"height:1px;border:none;color:#666;background-color:#666;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda75372-78fd-498b-9bf7-79cd771b47c0",
   "metadata": {},
   "source": [
    "The eradication of poverty, which was the first of the Millennium Development Goals (MDG) established by the United Nations and followed by the Sustainable Development Goals (SDG), requires knowing where the poor are located. Traditionally, household surveys are considered the best source of information on the living standards of a country's population. Data from these surveys typically provide a sufficiently accurate direct estimate of household expenditures or income and thus estimates of poverty at the national level and larger international regions. However, when one starts to disaggregate data by local areas or population subgroups, the quality of these direct estimates diminishes. Consequently, National Statistical Offices (NSOs) cannot provide reliable wellbeing statistical figures at a local level. For example, the Module of Socioeconomic Conditions of the Mexican National Survey of Household Income and Expenditure (ENIGH in Spanish) is designed to produce estimates of poverty and inequality at the national level and for the 32 federate entities (31 states and Mexico City) with disaggregation by rural and urban zones, every two years, but there is a mandate to produce estimates by municipality every five years, and the ENIGH alone cannot provide estimates for all municipalities with adequate precision. This makes monitoring progress toward the Sustainable Development Goals more difficult.\n",
    "\n",
    "Beyond the SDGs, poverty estimates at a local level are crucial for poverty reduction. Policymakers interested in poverty reduction and alleviation will often have a limited budget, and information on poverty at a local level can potentially improve targeting. The need for cost-effective disaggregated statistics makes it necessary to use indirect techniques for poverty estimation at a local level. To better understand the spatial distribution of poverty within countries, the World Bank has been producing poverty estimates at increasingly higher resolutions (poverty maps) since before the turn of the 21st century. A poverty map is the illustration of poverty rates on a map and is used to highlight the spatial distribution of poverty and inequality across a given country. Poverty mapping relies on Small Area Estimation (SAE) methods which are statistical tools that can be deployed to produce statistics for small areas with much better quality than those obtained directly from a sample survey.[^1]\n",
    "\n",
    "Small area techniques combine auxiliary information from censuses, registers, or other larger surveys to produce disaggregated statistics of sufficient precision where survey data alone is insufficient. The techniques achieve this by specifying some homogeneity relationships across areas; hence, they are based on the idea that \"union is strength.\" Despite small area estimation being useful for many indicators, the focus here is on small area methods used for poverty and related indicators derived from welfare.\n",
    "\n",
    "Ending extreme poverty is one of the World Bank's twin goals and poverty reduction is how the institution's efforts are often gauged. Accurate estimates of poverty at a granular level are an essential tool for monitoring poverty reduction and spatial inequalities. The World Bank's efforts to develop small area estimates of poverty can be traced back to the late 1990s. An initial effort by the institution was implemented by {cite:t}`jesko1998` in an application in Ecuador and is the bedrock of what came after. Much of the research efforts on small area estimation within the World Bank came to a zenith in the early 2000s with the publication of the paper \"Micro-level estimation of poverty and inequality\" by {cite:t}`elbers2003micro`. The method came to be known as ELL, and for over a decade-and-a-half, it was the default method used for all poverty mapping conducted by the World Bank. The method's popularity was spurred by the World Bank's development of a software application called `PovMap` ({cite:t}`zhao2006user`).[^2] The software provided a user-friendly interface for practitioners and did not require knowledge of specialized programming languages. The `PovMap` software was followed nearly a decade after by a Stata version called `sae` ({cite:t}`nguyen2018sae`).[^3]\n",
    "\n",
    "*The Guidelines to Small Area Estimation for Poverty Mapping* (hereafter the Guidelines) come after more than two decades of poverty mapping by the World Bank. These guidelines on small area estimation are meant as a practical guide to enable practitioners working on small area estimation of poverty to make informed choices between the available methods and make them aware of the strengths and limitations of the methodologies at hand. The Guidelines are also presented for practitioners who wish to learn about updates to the software and methods used within the World Bank for small area estimation. The Guidelines are not meant to be an exhaustive presentation of the small area estimation literature, instead, they focus almost exclusively on poverty and are a practical guide for practitioners to assist them in navigating the multiple different small area techniques available.[^4] The methods include but are not limited to, those proposed by {cite:t}`elbers2003micro` that generated a lot of the early poverty mapping work at the World Bank, a number of subsequent refinements and improvements to the original ELL methodology, area-level models, and some ongoing research. The Guidelines advise readers on what may be the best approach for different poverty mapping projects and different sets of data constraints by reviewing the relevant literature and conducting simulation exercises that compare across available methodologies. It is expected that the Guidelines will become a valuable resource to practitioners working in the area of poverty mapping.\n",
    "\n",
    "Before jumping into the Guidelines, a brief background to small area estimation is provided, as well as a decision tree aimed at practitioners (**{numref}`SAE-Decision-tree`**) who seek what may be the best approach given their context. After the brief background, the guidelines present direct estimates in **Chapter 2: {ref}`direct`**. Area-level models are presented in **Chapter 3: {ref}`area-level`**, focusing on Fay-Herriot methods ({cite:t}`fay1979estimates`). Unit-level methods are presented in **Chapter 4: {ref}`unit-level`**, giving special attention to the approach from {cite:t}`elbers2003micro` as well as that of {cite:t}`molina2010small`. **Chapter 5: {ref}`off-census`**, presents proposed alternatives for poverty mapping in off-census years beyond area-level models. Finally, **Chapter 6: {ref}`diagnostics`** is devoted to model selection and other considerations. Throughout chapters 2--5 the pros and cons of the chapter's corresponding approaches are noted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406cb342-d077-403a-a231-71f84b5b617c",
   "metadata": {},
   "source": [
    "(intro:background)=\n",
    "## A Brief Background to Small Area Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4130ed9a-107d-485f-9592-2834c98355e7",
   "metadata": {},
   "source": [
    "Small area estimates are often used to create a poverty map, but the two terms, Poverty Mapping and Small Area Estimation, should not be used interchangeably. Small area estimation is a set of methods used by National Statistical Offices (NSO) and other organizations to achieve estimates of acceptable quality for publication. As statistical information is disaggregated into smaller population subgroups, it will become noisier and will yield larger Coefficients of Variation (CV), which may exceed the threshold established by the NSO above which they will choose not to publish that specific estimate. Model-based small area estimation techniques incorporate auxiliary information from censuses, registers, geospatial data, or other large surveys, to produce estimates of much better quality, even for areas with very small sample sizes.\n",
    "\n",
    "Model-based techniques are popular because they yield good quality estimates even for areas with very small sample sizes. Of course, to achieve this, one needs to make model assumptions, and these assumptions need to be validated using the available data ({cite:t}`mcn2021`). Moreover, the quality of the model behind the estimates should be thoroughly evaluated and small area estimates should be accompanied by valid measures of their precision ({cite:t}`rao2015small`).\n",
    "\n",
    "Among small area estimation methodologies, area-level models use only aggregate auxiliary information at the area level. Aggregated data are more readily available because it is typically not subject to confidentiality. These models have other advantages that come with aggregate data, such as lower sensitivity to unit-level outliers. The disadvantage of the area-level method is less detailed information than unit-level models, specifically at the microdata level. Perhaps the most popular area method is the one proposed by {cite:t}`fay1979estimates` which is discussed in more detail in **Chapter 3: {ref}`area-level`** of these Guidelines.\n",
    "\n",
    "Unit-level models take advantage of detailed unit-record information, when such information is available. The models rely on detailed income/expenditure information from household surveys and a set of household-level characteristics in both a household survey and a population census to simulate household expenditures or incomes for each household in the population census data.[^5]\n",
    "\n",
    "The first unit-level model for small area estimation, discussed in more detail in **Chapter 4: {ref}`unit-level`** of these Guidelines, was proposed by {cite:t}`BHF` to estimate county crop areas of corn and soybeans. That model, called hereafter the BHF Model, includes, apart from the usual individual errors, random effects for the areas representing the between-area heterogeneity or idiosyncrasy the available auxiliary variables cannot explain. These models might also include area-level (or contextual) variables and thus may incorporate much more information in the estimation process than area-level models. As noted by {cite:t}`robinson1991blup`, models with random effects belong to the general class of mixed models and are commonly used in other fields such as Biostatistics, Engineering, Econometrics, and additional Social Sciences.[^6]\n",
    "\n",
    "Model-based small area estimates rely on statistical models to establish a relationship between a dependent variable and a set of covariates. The covariates and the parameters obtained from the fitted model are then used to predict the dependent variable in the auxiliary data. In the context of small area estimates of poverty, under unit-level models, the dependent variable is typically consumption/expenditure or income and relies on properly replicating the welfare distribution. The simulated welfare distribution makes it possible to obtain well-being indicators, such as the FGT class of indicators ({cite:t}`foster1984class`). In the case of area-level models, the dependent variable is the direct estimator of the same indicator for the area.\n",
    "\n",
    "The ELL method falls under the class of methods based on unit-level models for small area estimation. The method relies on a BHF model specified at the household level and may also include area or sub-area-level (contextual) variables. At the time of publication, it was one of the first times a model relied on using microdata to simulate the welfare distribution, which allowed the calculation of numerous indicators beyond just area aggregates.[^7] The methodology quickly gained traction within the World Bank, as well as among National Statistical Offices around the world, and has been one of the most applied methods to obtain small area estimates. Since ELL's publication, however, there have been considerable advances in the literature, including Molina and Rao's ({cite:t}`molina2010small`) Empirical Best (EB) method.\n",
    "\n",
    "When deciding which small area estimation method is preferable, there are many considerations the practitioner should take into account, but ultimately, the method chosen is often driven by the data at hand. When the practitioner has access to census data and a contemporaneous household survey, it is nearly always advisable to apply a unit-level model (**Chapter 4: {ref}`unit-level`**), because they often yield the most significant gains in precision. However, the data requirements for these models are considerable, and these data need to be checked to ensure the two data sources are also comparable beyond the temporal aspect. Potential variables need to be defined similarly in both data sources and must have similar distributions, as differences may lead to biased estimators. When choosing a unit-level model-based procedure, the next decision is often the aggregation level at which estimates will be reported. If there is a need for estimates at two different levels, then two-fold nested-error models may be used; otherwise one-fold nested-error models are adequate.\n",
    "\n",
    "When unit-level models are not possible, area-level models may be a viable alternative (**Chapter 3: {ref}`area-level`**). Area-level models are often easier to implement than unit-level models since data requirements are minimal and may be used when census data and survey data are not contemporaneous or incongruous. Also, area-level models rely on aggregated data, which is often not subject to confidentiality. In addition, if the most recent census is too old for a unit-level model, the recommended approach is to consider an area-level model. The most popular area-level model for small area estimation is the Fay-Herriot (FH) model, introduced by {cite:t}`fay1979estimates`, to estimate the per capita income of small areas in the United States. The U.S. Census Bureau has used area-level models within the Small Area Income and Poverty Estimates (SAIPE) project to inform the allocation of federal funds to school districts. The Fay-Herriot method, discussed in the area-level model chapter, will often require a separate model for each indicator, implying that area-level covariates are linearly related to the indicator of interest. If there is data at different aggregation levels, it may be possible to implement a two-fold area-level model introduced by {cite:t}`torabi2014small`, although no software implementation is currently available. Alternatively, it is possible to perform an FH model at the lowest aggregation level, and aggregate these FH estimates to a higher level (see **{numref}`area-level:annex:aggregation`**). Although area-level models predate ELL and in principle, should be simpler to execute, they have not been as commonly implemented by World Bank teams.\n",
    "\n",
    "In addition to unit- and area-level models, unit-context models have been proposed in the context of SAE for poverty during off-census years (**Chapter 5: {ref}`off-census`**). Unit-context models (**{numref}`off-census:unit-context`**) attempt to model the population's welfare distribution by using only area-level covariates. This method may be attractive because it can rely on easily accessible aggregate data and may benefit from the larger sample size obtained via household-level welfare distribution and thus appears to combine the best features of both area-level and unit-level methodologies. Nevertheless, simulated data and real-world data have shown that unit-context models yield biased poverty estimates and, therefore, based on the literature to date, are discouraged and not considered preferable over estimators based on FH area-level models. Additionally, unit-context models rely on a parametric bootstrap procedure to estimate Mean Square Error (MSE). Given the assumptions of the unit-context model, that household-level welfare distribution does not depend on household-specific characteristics, it is unlikely that the MSE can be accurately estimated following a parametric bootstrap, making it difficult to evaluate the resulting small area estimates properly.\n",
    "\n",
    "```{figure} /figures/01_intro/SAE_Decision_tree.png\n",
    "---\n",
    "name: SAE-Decision-tree\n",
    "---\n",
    "_SAE Decision tree_\n",
    "\n",
    "```\n",
    "\n",
    "Machine learning methods have also been proposed to obtain poverty maps in off-census years or when census data is unavailable. The methods often combine household survey data with ancillary Geo-coded (publicly available and proprietary) data to present local estimates of welfare. These methods have gained popularity among academia and policy circles since the publication of {cite:t}`jean2016combining`. For example, during the COVID-19 pandemic, cash transfers in Nigeria were informed by poverty estimates obtained from a machine learning approach by {cite:t}`chi2021micro`. However, these methods lack an accurate estimate of the method's noise and, to date, have not been submitted to a rigorous statistical validation. The Guidelines present a brief look into how these machine learning methods compare to other available small area estimation approaches. Although much work remains to be done regarding machine learning methods, the Guidelines posit that these methods are promising (see **{numref}`off-census:gradient-boosting`**).\n",
    "\n",
    "As the reader delves into the Guidelines and cited literature, the complexity of which method to choose becomes apparent. Despite this caveat, a simple decision tree on method availability is presented in **{numref}`SAE-Decision-tree`**. This decision tree can be used to assist practitioners in choosing which model is the best route for their context. The decision tree simplifies the process by directing readers to specific chapters in the Guidelines relevant to their particular situation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb822b6-484b-416c-a9d3-36ebf0c06aaf",
   "metadata": {},
   "source": [
    "(intro:about)=\n",
    "## About the Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea38bdaa-c21a-4f5e-b3df-dafa9b57dee4",
   "metadata": {},
   "source": [
    "The Guidelines are meant as a practical guide for readers. Stata scripts are provided throughout the chapters. These scripts allow replicating most sections and figures, which hopefully can assist new and more experienced practitioners in their SAE applications. Readers may download the latest Stata (SAE) packages used throughout the Guidelines from:\n",
    "\n",
    "1.  Unit-level models: <https://github.com/pcorralrodas/SAE-Stata-Package>\n",
    "\n",
    "2.  Area-level models: <https://github.com/jpazvd/fhsae>\n",
    "\n",
    "Although R offers a wide variety of packages for poverty-related small area estimation these are described in other sources: \n",
    "{cite:t}`rao2015small`, \n",
    "{cite:t}`book`,\n",
    "{cite:t}`molina2019desagregacion`, and \n",
    "{cite:t}`morales2021course`, for example.\n",
    "\n",
    "To assist readers throughout the text, simulated data (created following an assumed model), as well as real-world data are used. These data are used for method comparisons. Simulated data follow an assumed model and data generating process and are used for model-based simulations. Scripts are provided in the case of simulated data which can assist readers to replicate many of the analyses in the text. These data assist in illustrating the application of the different methods discussed and are used to make salient the advantages and disadvantages of the methods discussed.[^8] In addition to simulated data, the Guidelines use the *Mexican Intercensal survey* for design-based validations where methods are compared using real world-data and the real data generating process is unknown.[^9] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fdd10c-889f-4c14-8641-603d98451b98",
   "metadata": {},
   "source": [
    "(intro:ref)=\n",
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89b8139-3d93-4382-8bb9-6593b5cff714",
   "metadata": {},
   "source": [
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43b9298-7eeb-4530-be71-8453cf7f0308",
   "metadata": {},
   "source": [
    "(intro:notes)=\n",
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b258561-c883-46db-a761-0535fafa8d0f",
   "metadata": {},
   "source": [
    "[^1]: There is no universal threshold used to define a small area; every NSO establishes its own limit of what is an acceptable coefficient of variation (CV). Anything above the threshold is unlikely to be published by the NSO. Moreover, there is also no defined sample size that can determine if a group can be considered a small area since this is also dependent on the indicator one wishes to estimate. For poverty, for example, the magnitude of the poverty rate is also related to the necessary sample size for its accurate estimation, with higher proportions requiring smaller sample sizes.\n",
    "\n",
    "[^2]: {cite:t}`demombynes2002manual` presents earlier work of a module in SAS of the methodology.\n",
    "\n",
    "[^3]: Although `sae` was initially created to replicate many of the features and methods implemented in `PovMap`, the package has undergone many updates. {cite:t}`corral2020pull` detail the main updates and the reasons behind these.\n",
    "\n",
    "[^4]: For a more thorough discussion on small area estimation, including applications for other indicators of interest, readers should refer to {cite:t}`rao2015small`.\n",
    "\n",
    "[^5]: Note that simulations are not required when using analytical formulas to obtain poverty estimates. When assuming normality, the expected value of the poverty headcount and gap can be calculated without resorting to Monte Carlo simulations ({cite:t}`molina2019desagregacion`).\n",
    "\n",
    "[^6]: Early applications were in the area of animal and plant breeding to estimate genetic merits ({cite:t}`robinson1991blup`).\n",
    "\n",
    "[^7]: ELL follows and builds upon the work of {cite:t}`jesko1998`.\n",
    "\n",
    "[^8]: See {cite:t}`tzavidis2018start` for more details.\n",
    "\n",
    "[^9]: The *Mexican Intercensal survey* contains a welfare measure and is modified to mimic a census of 3.9 million households and 1,865 municipalities to allow for a design-based validation. From the created census, 500 survey samples were drawn for validations shown throughout the document (see {cite:t}`corral2021map` for more details on the modifications to the *Mexican Intercensal survey* and the sampling approach taken).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
